[
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nIf you use idealstan, please cite:\n\n  Kubinec, Robert. 2018. Generalized Ideal Point Models for Time-Varying and Missing-Data\n  Inference. Working Paper.\n\nA BibTeX entry for LaTeX users is\n\n  @Misc{,\n    title = {Generalized Ideal Point Models for Time-Varying and Missing-Data Inference},\n    author = {Robert Kubinec},\n    note = {Working Paper},\n    year = {2018},\n  }",
    "crumbs": [
      "Citation"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "Release v0.2.2",
    "section": "",
    "text": "#Release v0.7.2 * Updated to be compatible with most recent rstan (version 2.19.2). * Added id_plot_cov function for marginal effects plotting of covariates. * Added id_plot_irf for calculating impulse-response functions for AR(1) models covariates.\n#Release v0.7.1 * Fixed bug where time series vignette did not show on CRAN screen\n#Release v0.7.0 * Implement a Gaussian process prior for ideal points to permit semi-parametric inference * Update id_plot_legis_dyn to allow for overlay plots comparing different time series models * Strength over-time model identification using variational inference fits\n#Release v0.6.0 * Set a stricter threshold for vb to 1e-04 to promote more robust variational inference\n#Release v0.5.1 * Fixed bugs in plotting functions related to plotting two groups. * Fixed bug in AR(1) model with restricted time variance. * Updated dependencies to rstan 2.18.2. * Added error-catching in covariate creation.\n#Release v0.5.0 * New models for Poisson, ordinal-graded response, Normal and Log-normal outcomes. * Time-varying ideal point processes: random-walks and auto-regressive priors. * Time-varying plot functions for ideal points. * Hierarchical covariates for ideal points and item/bill discrimination. * Switched from matrix data input to long data frames.\n#Release v0.2.9.1 * Fixed bugs in id_extract and id_make functions.\n#Release v0.2.9 * Fixed a bug in the ideal point plot function, and also in the auto_id option in id_estimate.\n\nRelease v0.2.2\n\nFirst release on CRAN.\nFixed documentation issues from v0.2.1\nAll vignettes now building properly.",
    "crumbs": [
      "News"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html",
    "href": "vignettes/Package_Introduction.html",
    "title": "Introduction to Idealstan",
    "section": "",
    "text": "Note: To report bugs with the package, please file an issue on the Github page.\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Time-Varying and Missing-Data Inference”. Working Paper. https://doi.org/10.31219/osf.io/8j2bt.\nNote: At present, idealstan uses the cmdstanr package, which is not on CRAN and must be installed separately. Please see below for instructions.\nThis package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics, disagreement over product design in consumer choice, or psychometric scales in which the direction that items load on the latent scale is unknown. Compared to traditional IRT, ideal point models examine the polarizing influence of a set of items on a set of persons, and has similarities to models based on Euclidean latent spaces, such as multi-dimensional scaling. In fact, this package also implements a version of the latent space model for binary outcomes, which is an alternate formulation of an ideal point model.\nThe goal of idealstan is to offer a wide variety of ideal point models that can model missing-data, time-varying ideal points, and incorporate a range of outcomes, including binary outcomes, counts, continuous and ordinal responses. In addition, idealstan uses the Stan estimation engine to offer full and variational Bayesian inference for all models so that every model is estimated with uncertainty. Variational inference–specifically the Pathfinder algorithm–provides informative starting values to ensure convergence, and for very large models, the possibility of estimating ideal points when full MCMC is impractical. However, the MCMC algorithm has the ability to parallelize within chains using multiple cores, which makes it possible to estimate much larger models with full Bayesian inference than was previously possible.\nThe approach to handling missing data in this package is to model cases where missing data is a function of a person’s ideal point. In other words, the package will adjust estimates if missingness appears to be correlated with either high or low values of the latent trait. This general missing data adjustment can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point). If missingness does not appear to arise as a function of ideal points, the models will still incorporate missing data but will assume it is random conditional on each item.\nThe package includes the following models:\nIn addition, all of these models can be estimated with either time-varying or static ideal points if a column of dates for each item is passed to the model function (see the Time Series vignette). This package implements a range of time series processes (random walk, AR(1), Gaussian processes, and splines). The package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).\nThis vignette demonstrates how to load data into the package, estimate static ideal points, and also calculate ideal point marginal effects for hierarchical predictors of ideal points.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#installation-instructions",
    "href": "vignettes/Package_Introduction.html#installation-instructions",
    "title": "Introduction to Idealstan",
    "section": "Installation Instructions",
    "text": "Installation Instructions\nTo use idealstan, you first have to have both cmdstanr, an R package, installed and cmdstan, the underlying MCMC library. Unfortunately, cmdstanr is not yet available on CRAN. Simply use the following command to install the package:\n# we recommend running this in a fresh R session or restarting your current session\ninstall.packages(\"cmdstanr\", repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\")))\nThen you will need to install cmdstan, which is the Stan engine. You can do so by loading cmdstanr and using the function install_cmdstan:\nlibrary(cmdstanr)\ninstall_cmdstan()\nThere are some pre-requisites to using cmdstan as you need to be able to compile models on your machine. For example, with Mac OS X you will first need to install Xcode from the Apple App Store. For more details, see complete installation instructions on this page: https://mc-stan.org/cmdstanr/articles/cmdstanr.html.\nAssuming you install cmdstan using the functions provided in the package, please allow it to install in the default location.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#simulation-of-ordinal-irt-with-missing-data",
    "href": "vignettes/Package_Introduction.html#simulation-of-ordinal-irt-with-missing-data",
    "title": "Introduction to Idealstan",
    "section": "Simulation of Ordinal IRT with Missing Data",
    "text": "Simulation of Ordinal IRT with Missing Data\nTo begin with, we can simulate data from an ordinal ideal-point model in which there are three possible responses corresponding to a legislator voting: yes, abstain and no. An additional category is also simulated that indicates whether a legislator shows up to vote or is absent, which traditional IRT models would record as missing data and would drop from the estimation. This package can instead utilize missing data via a hurdle model in which the censoring of the vote/score data is estimated as a function of individual item/bill intercepts and discrimination parameters for the decision to be absent or present. In other words, if the missing data is a reflection of the person’s ideal point, such as more conservative legislators refusing to show up to vote, than the model will make use of this missing data to infer additional information about the legislators’ ideal points.\nThe function id_sim_gen() allows you to simulate data from any of the sixteen models currently implemented in idealstan (see previous list). To include missing data, specify the inflate option as TRUE. For example, here we sample data from an ordinal graded response model:\n\nord_ideal_sim &lt;- id_sim_gen(model='ordinal_grm',inflate = T)\n\ntt(head(ord_ideal_sim@score_matrix))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                item_id\n                person_id\n                model_id\n                group_id\n                time_id\n                outcome_disc\n                ordered_id\n                personcov0\n                itemcov0\n                itemcovmiss0\n                discrete\n              \n        \n        \n        \n                \n                  1\n                  1\n                  missing\n                  G\n                  1\n                  Missing\n                  3\n                  0\n                  0\n                  0\n                  0\n                \n                \n                  2\n                  1\n                  missing\n                  G\n                  1\n                  Missing\n                  3\n                  0\n                  0\n                  0\n                  0\n                \n                \n                  3\n                  1\n                  missing\n                  G\n                  1\n                  1      \n                  3\n                  0\n                  0\n                  0\n                  0\n                \n                \n                  4\n                  1\n                  missing\n                  G\n                  1\n                  2      \n                  3\n                  0\n                  0\n                  0\n                  0\n                \n                \n                  5\n                  1\n                  missing\n                  G\n                  1\n                  1      \n                  3\n                  0\n                  0\n                  0\n                  0\n                \n                \n                  6\n                  1\n                  missing\n                  G\n                  1\n                  3      \n                  3\n                  0\n                  0\n                  0\n                  0\n                \n        \n      \n    \n\n\n\nThe vote/score matrix in the idealdata object ord_ideal_sim has legislators/persons in the rows and bills/items in the columns. The outcome_disc column has the simulated 3-category ordered outcome.\nThe function id_estimate will take this processed data and run an IRT ideal point model with the model ID . To specify the model type, either include the model ID from Table 1 as the model_id argument in the id_estimate function or, in the case of multiple models/item types, pass a column model_id to the id_make function that specifies the model ID for each row in the data. This latter option is useful when you have items of mixed types, such as binary, ordinal and/or continuous items. The function id_make also includes the ability to incorporate hierarchical (person or item-level) covariates, as discussed below.\nTo speed up processing, all of the models shown in Table 1 make use of multiple core parallel computation. To use this option, the specified number of available cores in the ncores option must exceed the number of MCMC chains nchains. cmdstanr will automatically assign cores by dividing the number of chains by the number of cores. In all of the examples in this vignette, I use a machine with 8 cores and estimate 2 chains, so there are 4 cores per chain. By default, id_estimate parallelizes over persons, although that can be changed to items with the map_over_id option (only works with static models).\nThe package has options for identification that are similar to other IRT packages in which the IDs of legislators/persons to constrain are specified to the id_estimate function. For example, we can use the true values of the simulated legislators to constrain one legislator/person with the highest simulated ideal point and one legislator/person with the lowest ideal point. Each constrained parameter must be fixed to a specific value, preferably at either end of the ideal point spectrum, to identify the model. In particular, two pieces of information are necessary: a value for the high ideal point, and the difference between the high and low points. In this example I pre-specify which parameters to constrain based on the simulated data as restrict_ind_high and restrict_ind_low, and use the actual values to pin the parameters to specific values with fix_high and fix_low.\n\ntrue_legis &lt;- ord_ideal_sim@simul_data$true_person\nhigh_leg &lt;- sort(true_legis,decreasing = TRUE,index.return=TRUE)\nlow_leg &lt;- sort(true_legis,index.return=TRUE)\n\nord_ideal_est &lt;- id_estimate(idealdata=ord_ideal_sim,\n                             model_type=6,\n                             fixtype='prefix',\n                             restrict_ind_high = as.character(high_leg$ix[1]),\n                             restrict_ind_low=as.character(low_leg$ix[1]),\n                             fix_high = sort(true_legis,decreasing = TRUE)[1],\n                             fix_low = sort(true_legis,decreasing = FALSE)[1],\n                             id_refresh=500,\n                             ncores=8,\n                             nchains=2)\n\n[1] \"Running pathfinder to find starting values\"\nPath [1] :Initial log joint density = -1577.176212 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n             87      -8.501e+02      4.265e-04   3.971e-03    7.494e-01  7.494e-01      2176 -1.065e+03 -1.065e+03                   \nPath [1] :Best Iter: [85] ELBO (-1059.338643) evaluations: (2176) \nFinished in  0.5 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -11.3421, but should be greater than the previous element, -11.3421 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 1 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 408, column 0, included from\n\n\nChain 1 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 44, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 639, column 2 to line 745, column 21)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -163.557, but should be greater than the previous element, -163.557 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 408, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 44, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 639, column 2 to line 745, column 21)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -14.201, but should be greater than the previous element, -14.201 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 408, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 44, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 639, column 2 to line 745, column 21)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 21.8 seconds.\nChain 2 finished in 21.7 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 21.8 seconds.\nTotal execution time: 21.9 seconds.\n\n\nWe can then check and see how well the Stan estimation engine was able to capture the “true” values used in the simulation by plotting the true ideal points relative to the estimated ones:\n\nid_plot_legis(ord_ideal_est,show_true = TRUE)\n\nJoining with `by = join_by(id_num)`\nJoining with `by = join_by(id_num)`\n\n\n\n\n\n\n\n\n\nGiven the small amount of data used to estimate the model, the imprecision with which the ideal points were recovered is not surprising. However, the uncertainty intervals generally include the true values, indicating a model that is functioning correctly at recovering estimates even with substantial measurement error.\nTo automatically identify the model (that is, identify people to fix high or low), simply change the fixtype option to 'vb_full'. By default, the model will select the highest and lowest ideal points to constrain by running an approximation to the full posterior using cmdstanr’s pathfinder() function. While this method works, the exact rotation is not known a priori, and so it may produce a different result with multiple runs. Note that there will be two pathfinder runs as the first run identifies the parameters to constrain and the second is used to create starting values for the Hamiltonian Monte Carlo estimation.\nFor example, using our simulated data and identifying the model automatically with 'vb_full':\n\nord_ideal_est &lt;- id_estimate(idealdata=ord_ideal_sim,\n                             model_type=6,\n                             id_refresh=2000,fixtype=\"vb_full\",\n                             ncores=8,\n                           nchains=2)\n\n[1] \"(First Step): Estimating model with Pathfinder (variational inference) to identify modes to constrain.\"\nPath [1] :Initial log joint density = -1927.222174 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n             98      -8.586e+02      1.010e-03   4.650e-03    1.000e+00  1.000e+00      2451 -1.074e+03 -1.074e+03                   \nPath [1] :Best Iter: [95] ELBO (-1068.256459) evaluations: (2451) \nFinished in  0.5 seconds.\n\n\n[1] \"Running pathfinder to find starting values\"\nPath [1] :Initial log joint density = -1533.547548 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n            107      -8.459e+02      6.874e-04   2.590e-03    1.000e+00  1.000e+00      2676 -1.071e+03 -1.071e+03                   \nPath [1] :Best Iter: [101] ELBO (-1052.747760) evaluations: (2676) \nFinished in  0.5 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -261.141, but should be greater than the previous element, -261.141 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 408, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 44, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 639, column 2 to line 745, column 21)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -11.4019, but should be greater than the previous element, -11.4019 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 408, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 44, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/RtmpSSVA47/model-dd1a1549e887.stan', line 639, column 2 to line 745, column 21)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 25.7 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 26.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 26.1 seconds.\nTotal execution time: 26.7 seconds.\n\n\nWe can see from the plot of the Rhats, which is an MCMC convergence diagnostic, that all the Rhats are below 1.1, which is a good (though not perfect) sign that the model is fully identified:\n\nid_plot_rhats(ord_ideal_est)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nid_plot_legis(ord_ideal_est,show_true = T)\n\nJoining with `by = join_by(id_num)`\nJoining with `by = join_by(id_num)`\n\n\n\n\n\n\n\n\n\nIn general, it is always a good idea to check the Rhats before proceeding with further analysis. Identification of time-varying ideal point models can be more complicated and is discussed in the accompanying vignette. As can be seen above, while the Pathfinder algorithm will usually identify a unique rotation of the ideal points without using any other prior information, it may not be the rotation that is theoretically interesting. For that reason, I recommend specifying persons or items to pin to specific values for applied use of the package as I show in the next section.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#parameter-values",
    "href": "vignettes/Package_Introduction.html#parameter-values",
    "title": "Introduction to Idealstan",
    "section": "Parameter Values",
    "text": "Parameter Values\nWe can obtain summary estimates of all the ideal points and item/bill discrimination/difficulty parameters using the summary function that provides the median value of the parameters in addition to a specified posterior density interval (i.e., 5%-95%). For example, we can extract summaries for the ideal points:\n\nideal_pts_sum &lt;- summary(sen_est,pars='ideal_pts')\n\nJoining with `by = join_by(id_num)`\n\ntt(head(ideal_pts_sum))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Person\n                Group\n                Time_Point\n                Low Posterior Interval\n                Posterior Median\n                High Posterior Interval\n                Parameter Name\n              \n        \n        \n        \n                \n                  WYDEN, Ronald Lee    \n                  D\n                  1\n                   5.908937\n                   7.201095\n                   8.719860\n                  L_full[100]\n                \n                \n                  BOXER, Barbara       \n                  D\n                  1\n                   6.780327\n                   8.465760\n                  10.712110\n                  L_full[10] \n                \n                \n                  BROWN, Sherrod       \n                  D\n                  1\n                   7.289706\n                   9.221625\n                  11.874305\n                  L_full[11] \n                \n                \n                  BURR, Richard M.     \n                  R\n                  1\n                  -6.645283\n                  -5.665140\n                  -4.792147\n                  L_full[12] \n                \n                \n                  CANTWELL, Maria E.   \n                  D\n                  1\n                   6.941406\n                   8.661010\n                  10.781860\n                  L_full[13] \n                \n                \n                  CAPITO, Shelley Moore\n                  R\n                  1\n                  -5.783458\n                  -4.992145\n                  -4.276122\n                  L_full[14] \n                \n        \n      \n    \n\n\n\nParameter Name is the name of the parameter in the underlying Stan code, which can be useful f you want to peruse the fitted Stan model (and can be accessed as given in the code below). The name of the parameters for ideal points in the Stan model is L_full (as seen in the summary from above).\n\nstan_obj &lt;- sen_est@stan_samples\n# show the \nstan_obj$draws(c(\"L_full[1]\",\n                        'L_full[2]',\n                        'L_full[3]'))\n\n# A draws_array: 1000 iterations, 2 chains, and 3 variables\n, , variable = L_full[1]\n\n         chain\niteration    1    2\n        1 -4.0 -4.3\n        2 -4.3 -4.1\n        3 -4.1 -3.8\n        4 -4.6 -4.0\n        5 -3.9 -3.7\n\n, , variable = L_full[2]\n\n         chain\niteration    1    2\n        1 -2.3 -1.6\n        2 -2.2 -1.9\n        3 -2.5 -2.9\n        4 -2.5 -1.4\n        5 -2.5 -3.1\n\n, , variable = L_full[3]\n\n         chain\niteration    1    2\n        1  5.8  8.8\n        2 11.3  8.3\n        3  7.6 10.2\n        4  7.6  6.8\n        5  8.0  9.1\n\n# ... with 995 more iterations\n\n\nIf we know the name of the Stan parameter, we can look at the trace plot to see how the quality of the Markov Chain Monte Carlo (MCMC) sampling used to fit the model. A good trace plot shows a bouncy line that is stable around an average value. For more info, see the Stan documentation.\n\nstan_trace(sen_est,par='L_full[1]')\n\n\n\n\n\n\n\n\nFinally we can also extract all of the posterior iterations to do additional calculations that average over posterior uncertainty by changing the aggregate option in summary. In the following code, I access the individual posterior iterations for the item/bill parameters, including difficulty (average probability of voting yes), discrimination (how strongly the item/bill loads on either end of the ideal point scale) and the midpoints (position where someone with that ideal point would be indifferent to voting yes/no).\n\nitem_all &lt;- summary(sen_est,pars='items', aggregate=F)\ntt(head(item_all))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Posterior_Sample\n                Item Name\n                Item Type\n                Predicted Outcome\n                Parameter\n                Iteration\n              \n        \n        \n        \n                \n                  1.606639\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  1\n                \n                \n                  1.511766\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  2\n                \n                \n                  1.028057\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  3\n                \n                \n                  1.976161\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  4\n                \n                \n                  1.550986\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  5\n                \n                \n                  1.377775\n                  4\n                  Non-Inflated Item Midpoint\n                  1\n                  A function of other parameters\n                  6",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#hierarchical-covariates",
    "href": "vignettes/Package_Introduction.html#hierarchical-covariates",
    "title": "Introduction to Idealstan",
    "section": "Hierarchical Covariates",
    "text": "Hierarchical Covariates\nNote: ideal point marginal effects have yet to be implemented as a separate function. In this section I demonstrate how to estimate these effects using R code.\nFinally, we can also fit a model where we include a covariate that varies by person/legislator. To do so, we need to pass a one-sided formula to the id_make function to prepare the data accordingly. By way of example, we will include a model where we include an interaction between party ID (party_code) and the legislator’s age to see if younger/older legislators are more or less conservative. Because this is a static model, the effect of the covariate is averaged over all of the bills in the dataset and all the legislators in the dataset without taking into account the order or time period of the bills.\nIt is important to note that for static ideal point models, covariates are only defined over the legislators/persons who are not being used as constraints in the model, such as John Barasso and Elizabeth Warren in this model.\n\nsenate114$age &lt;- 2018 - senate114$born\n# center the variable\nsenate114$age &lt;- senate114$age - mean(senate114$age)\n# put in units of 10 years\nsenate114$age &lt;- senate114$age / 10\n\n# doing this will improve estimation speed (variables mean-centered and with an SD\n# not much bigger than 1 or 2)\n\nsenate_data &lt;- id_make(senate114,outcome_disc = 'cast_code',\n                       person_id = 'bioname',\n                       item_id = 'rollnumber',\n                       group_id= 'party_code',\n                       time_id='date',\n                       person_cov = ~party_code*age)\n\nsen_est_cov &lt;- id_estimate(senate_data,\n                model_type = 1,\n                fixtype='prefix',\n                nchains=2,\n                ncores=8,\n                 restrict_ind_high = \"BARRASSO, John A.\",\n                 restrict_ind_low=\"WARREN, Elizabeth\",\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  5.5 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 2 finished in 256.4 seconds.\nChain 1 finished in 256.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 256.5 seconds.\nTotal execution time: 256.8 seconds.\n\n\nAs discussed in the associated working paper (https://osf.io/preprints/osf/8j2bt), ideal point marginal effects can be derived from idealstan models in which the raw relationship between the hierarchical covariates and the actual outcomes (in this case, votes) can be shown at the item (vote) level. There are two functions that can be used to calculate and display ideal point marginal effects. The first, id_me, shown in the chunks, below, will produce data frames with summaries ideal point marginal effects given a covariate and also data frames with one row per posterior draw that are useful for further analysis or aggregation.\nIn the example below, ideal point marginal effects are calculated for the \"age\" covariate, first for the whole dataset and then for all distinct values of \"group_id\", which is party ID in our data. This latter calculation is especially useful as we interaction age with group_id, and by calculating marginal effects for each distinct subset of group_id we can learn what the conditional marginal effect is by party ID.\n\n  # calculate marginal effects for age subset by item\n\n  marg_effs &lt;- id_me(sen_est_cov,covariate=\"age\")\n\nCreating predictions\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\nDifferencing\n\n\nJoining with `by = join_by(item_id)`\n\n  head(marg_effs$ideal_effects) %&gt;% \n    tt\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                draws\n                item_id\n                person_id\n                estimate\n                group_id\n                item_orig\n                person_orig\n                model_id\n              \n        \n        \n        \n                \n                  1\n                  1\n                  1\n                  3.050097e-05\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n                \n                  2\n                  1\n                  1\n                  3.113286e-04\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n                \n                  3\n                  1\n                  1\n                  6.084729e-03\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n                \n                  4\n                  1\n                  1\n                  8.515025e-04\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n                \n                  5\n                  1\n                  1\n                  3.301149e-03\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n                \n                  6\n                  1\n                  1\n                  4.367442e-04\n                  R\n                  4\n                  ALEXANDER, Lamar\n                  1\n                \n        \n      \n    \n\n\n  head(marg_effs$sum_ideal_effects) %&gt;% \n    tt\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                item_id\n                item_orig\n                model_id\n                mean_est\n                low_est\n                high_est\n                item_discrimination\n              \n        \n        \n        \n                \n                  1\n                  4 \n                  1\n                  -0.027324609\n                  -0.19376592\n                  0.005557074\n                  -0.6573580\n                \n                \n                  2\n                  5 \n                  1\n                  -0.003546904\n                  -0.05185579\n                  0.037121004\n                  -0.5594220\n                \n                \n                  3\n                  7 \n                  1\n                  -0.008581398\n                  -0.05267362\n                  0.016401029\n                  -0.7241575\n                \n                \n                  4\n                  8 \n                  1\n                   0.030378577\n                  -0.00656919\n                  0.203952527\n                   0.5657380\n                \n                \n                  5\n                  9 \n                  1\n                  -0.010908422\n                  -0.09720920\n                  0.034804994\n                  -0.4180350\n                \n                \n                  6\n                  11\n                  1\n                  -0.020290320\n                  -0.09146070\n                  0.023107847\n                   0.3245960\n                \n        \n      \n    \n\n\n\n\n  # now group marginal effects by group_id (party ID)\n\n  marg_effs_grouped &lt;- id_me(sen_est_cov,covariate=\"age\",\n                     group_effects=\"group_id\")\n\nCreating predictions\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\nDifferencing\n\n\nGrouping marginal effect summaries by group_id\n\n\nJoining with `by = join_by(item_id)`\n\n  marg_effs_grouped$sum_ideal_effects %&gt;% \n    arrange(item_id, group_id) %&gt;% \n    slice(1:10) %&gt;% \n    tt\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                group_id\n                item_id\n                item_orig\n                model_id\n                mean_est\n                low_est\n                high_est\n                item_discrimination\n              \n        \n        \n        \n                \n                  D\n                  1\n                  4\n                  1\n                  -0.059669410\n                  -0.1061344485\n                  -0.030980545\n                  -0.6573580\n                \n                \n                  R\n                  1\n                  4\n                  1\n                   0.001842369\n                   0.0001115782\n                   0.004954489\n                  -0.6573580\n                \n                \n                  I\n                  1\n                  4\n                  1\n                  -0.175759403\n                  -0.5527863128\n                   0.097773912\n                  -0.6573580\n                \n                \n                  D\n                  2\n                  5\n                  1\n                  -0.021396470\n                  -0.0445927354\n                  -0.004632567\n                  -0.5594220\n                \n                \n                  R\n                  2\n                  5\n                  1\n                   0.011258984\n                   0.0015062504\n                   0.023842689\n                  -0.5594220\n                \n                \n                  I\n                  2\n                  5\n                  1\n                  -0.040033881\n                  -0.1370294461\n                   0.012257794\n                  -0.5594220\n                \n                \n                  D\n                  3\n                  7\n                  1\n                  -0.028223857\n                  -0.0536652758\n                  -0.007861273\n                  -0.7241575\n                \n                \n                  R\n                  3\n                  7\n                  1\n                   0.005514060\n                   0.0004894154\n                   0.014164724\n                  -0.7241575\n                \n                \n                  I\n                  3\n                  7\n                  1\n                  -0.043940857\n                  -0.1725620105\n                   0.016527400\n                  -0.7241575\n                \n                \n                  D\n                  4\n                  8\n                  1\n                   0.070496166\n                   0.0377855263\n                   0.104861559\n                   0.5657380\n                \n        \n      \n    \n\n\n\nIn addition to the data frames of the results, the id_plot_cov can take the same arguments, calculate the ideal point marginal effects and then plot them. If we pass a grouping variable, the id_plot_cov function will plot marginal effects in distinct facets for each level of the grouping variable. If there are multiple model ID types, the function will produce distinct facets for each model ID type (note that only one kind of facetting can be used for a given plot).\n\n   # plot the result\n   \n   sen_est_cov %&gt;% \n     id_plot_cov(calc_param=\"age\",group_effects=\"group_id\",\n                 label_high=\"Conservative\",\n                 label_low=\"Liberal\")\n\nCreating predictions\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\n[1] \"Processing posterior replications for 23352 scores using 100 posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n\nDifferencing\n\n\nGrouping marginal effect summaries by group_id\n\n\nJoining with `by = join_by(item_id)`\n\n\n\n\n\n\n\n\n\nBecause these covariates are on the ideal point scale, the meaning of the scale in terms of party ideology must be kept in mind in order to interpret the plot. The way to interpret these plots is that older Democrats tend to be more likely to vote for conservative bills, while younger Democrats vote more for liberal bills. The relationship does not hold true for Republicans, who are roughly equally as likely to vote for liberal or conservative bills regardless of age. Keeping the direction of the scale in mind–which is shown on the plot as the colour of the item discrimination for each vote–is crucial for understanding hierarchical covariates in ideal point models.\nWe can also extract the covariate summary values using the summary function:\n\ncov_sum &lt;- summary(sen_est_cov,pars='person_cov')\ntt(cov_sum)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Covariate\n                Posterior Median\n                Posterior High Interval\n                Posterior Low Interval\n                Parameter\n              \n        \n        \n        \n                \n                  party_codeR    \n                  -15.5384000\n                  -14.451030\n                  -16.697360\n                  legis_x\n                \n                \n                  party_codeI    \n                   -0.6862375\n                    5.981570\n                   -6.834136\n                  legis_x\n                \n                \n                  age            \n                    2.3011950\n                    3.067987\n                    1.463249\n                  legis_x\n                \n                \n                  party_codeR:age\n                   -3.2372250\n                   -2.184633\n                   -4.234465\n                  legis_x\n                \n                \n                  party_codeI:age\n                    1.1277700\n                    6.660751\n                   -5.019880\n                  legis_x",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "man/id_plot_all_hist.html",
    "href": "man/id_plot_all_hist.html",
    "title": "idealstan",
    "section": "",
    "text": "This function produces density plots of the different types of parameters in an idealstan model: item (bill) difficulty and discrimination parameters, and person (legislator) ideal points.\n\n\n\nid_plot_all_hist(\n  object,\n  params = \"person\",\n  param_labels = NULL,\n  dens_type = \"all\",\n  return_data = FALSE,\n  func = median,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nparams\n\n\nSelect the type of parameter from the model to plot. ‘person’ for person/legislator ideal points, ‘miss_diff’ and ‘miss_discrim’ for difficulty and discrimination parameters from the missing/inflated item/bill parameters, and ‘obs_diff’ and ‘obs_discrim’ for difficulty and discrimination parameters from the non-missing/non-inflated item/bill parameters.\n\n\n\n\nparam_labels\n\n\nA vector of labels equal to the number of parameters. Primarily useful if return_data is TRUE.\n\n\n\n\ndens_type\n\n\nCan be ‘all’ for showing 90 Or to show one of those posterior estimates at a time, use ‘high’ for 90 ‘low’ for 10 in func (median by default).\n\n\n\n\nreturn_data\n\n\nWhether or not to return the plot as a ggplot2 object and the data together in a list instead of plotting.\n\n\n\n\nfunc\n\n\nThe function to use if ‘dens_type’ is set to ‘function’.\n\n\n\n\n…\n\n\nOther options passed on to the plotting function, currently ignored.",
    "crumbs": [
      "Reference",
      "id_plot_all_hist"
    ]
  },
  {
    "objectID": "man/id_plot_all_hist.html#density-plots-of-posterior-parameters",
    "href": "man/id_plot_all_hist.html#density-plots-of-posterior-parameters",
    "title": "idealstan",
    "section": "",
    "text": "This function produces density plots of the different types of parameters in an idealstan model: item (bill) difficulty and discrimination parameters, and person (legislator) ideal points.\n\n\n\nid_plot_all_hist(\n  object,\n  params = \"person\",\n  param_labels = NULL,\n  dens_type = \"all\",\n  return_data = FALSE,\n  func = median,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nparams\n\n\nSelect the type of parameter from the model to plot. ‘person’ for person/legislator ideal points, ‘miss_diff’ and ‘miss_discrim’ for difficulty and discrimination parameters from the missing/inflated item/bill parameters, and ‘obs_diff’ and ‘obs_discrim’ for difficulty and discrimination parameters from the non-missing/non-inflated item/bill parameters.\n\n\n\n\nparam_labels\n\n\nA vector of labels equal to the number of parameters. Primarily useful if return_data is TRUE.\n\n\n\n\ndens_type\n\n\nCan be ‘all’ for showing 90 Or to show one of those posterior estimates at a time, use ‘high’ for 90 ‘low’ for 10 in func (median by default).\n\n\n\n\nreturn_data\n\n\nWhether or not to return the plot as a ggplot2 object and the data together in a list instead of plotting.\n\n\n\n\nfunc\n\n\nThe function to use if ‘dens_type’ is set to ‘function’.\n\n\n\n\n…\n\n\nOther options passed on to the plotting function, currently ignored.",
    "crumbs": [
      "Reference",
      "id_plot_all_hist"
    ]
  },
  {
    "objectID": "man/id_extract-idealstan-method.html",
    "href": "man/id_extract-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function allows you to extract the underlying rstan posterior estimates for the full parameters estimates of the idealstan model object. See extract for the underlying function and more options.\nYou can use this function to access a matrix or array of the full posterior estimates of each of the parameters in an idealstan object. There are available options to pick certain parameters of the model, such as the person (legislator) ideal points or item (bill) discrimination scores. Alternatively, you can leave the extract_type option blank and receive a list of all of the available parameters. Please note that the list of parameters do not have particularly informative names.\nAll parameters are returned in the order in which they were input into the id_make function.\n\n\n\n## S4 method for signature 'idealstan'\nid_extract(object, extract_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\nextract_type\n\n\nCan be one of ‘persons’ for person/legislator ideal points, ‘obs_discrim’ for non-inflated item (bill) discrimination scores, ‘obs_diff’ for non-inflated item (bill) difficulty scores, ‘miss_discrim’ for inflated item (bill) discrimination scores, and ‘miss_diff’ for inflated item (bill) difficulty scores.\n\n\n\n\n…\n\n\nAny additional arguments passed on to the extract function.",
    "crumbs": [
      "Reference",
      "id_extract-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_extract-idealstan-method.html#extract-stan-joint-posterior-distribution-from-idealstan-object",
    "href": "man/id_extract-idealstan-method.html#extract-stan-joint-posterior-distribution-from-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function allows you to extract the underlying rstan posterior estimates for the full parameters estimates of the idealstan model object. See extract for the underlying function and more options.\nYou can use this function to access a matrix or array of the full posterior estimates of each of the parameters in an idealstan object. There are available options to pick certain parameters of the model, such as the person (legislator) ideal points or item (bill) discrimination scores. Alternatively, you can leave the extract_type option blank and receive a list of all of the available parameters. Please note that the list of parameters do not have particularly informative names.\nAll parameters are returned in the order in which they were input into the id_make function.\n\n\n\n## S4 method for signature 'idealstan'\nid_extract(object, extract_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\nextract_type\n\n\nCan be one of ‘persons’ for person/legislator ideal points, ‘obs_discrim’ for non-inflated item (bill) discrimination scores, ‘obs_diff’ for non-inflated item (bill) difficulty scores, ‘miss_discrim’ for inflated item (bill) discrimination scores, and ‘miss_diff’ for inflated item (bill) difficulty scores.\n\n\n\n\n…\n\n\nAny additional arguments passed on to the extract function.",
    "crumbs": [
      "Reference",
      "id_extract-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_sim_gen.html",
    "href": "man/id_sim_gen.html",
    "title": "idealstan",
    "section": "",
    "text": "A function designed to simulate IRT ideal point data.\n\n\n\nid_sim_gen(\n  num_person = 20,\n  num_items = 50,\n  cov_effect = NULL,\n  model_type = \"binary\",\n  latent_space = FALSE,\n  absence_discrim_sd = 3,\n  absence_diff_mean = 0,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  diff_sd = 3,\n  time_points = 1,\n  time_process = \"random\",\n  time_sd = 0.1,\n  ideal_pts_sd = 3,\n  prior_type = \"gaussian\",\n  ordinal_outcomes = 3,\n  inflate = FALSE,\n  sigma_sd = 1,\n  phi = 1\n)\n\n\n\n\n\n\n\nnum_person\n\n\nThe number of persons/persons\n\n\n\n\nnum_items\n\n\nThe number of items (bills in the canonical ideal point model)\n\n\n\n\ncov_effect\n\n\nThe effect of a hierarchical/external covariate on the person ideal points. The covariate will be a uniformly-distributed random variable on the [0,1] scale, so covariate effects in the [-2,2] approximate range would result in noticeable effects on the ideal point scale.\n\n\n\n\nmodel_type\n\n\nOne of ‘binary’, ‘ordinal_rating’, ‘ordinal_grm’, ‘poisson’ ‘normal’, or ‘lognormal’\n\n\n\n\nlatent_space\n\n\nWhether to use the latent space formulation of the ideal point model FALSE by default. NOTE: currently, the package only has estimation for a binary response with the latent space formulation.\n\n\n\n\nabsence_discrim_sd\n\n\nThe SD of the discrimination parameters for the inflated model\n\n\n\n\nabsence_diff_mean\n\n\nThe mean intercept for the inflated model; increasing it will lower the total number of missing data\n\n\n\n\ndiscrim_reg_upb\n\n\nThe upper bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_lb\n\n\nThe lower bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_upb\n\n\nThe upper bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_lb\n\n\nThe lower bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_reg_scale\n\n\nThe scale parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_shape\n\n\nThe shape parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_scale\n\n\nThe scale parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_shape\n\n\nThe shape parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiff_sd\n\n\nThe SD of the difficulty parameters (bill/item intercepts) for both missing and observed parameters (beta and omega)\n\n\n\n\ntime_points\n\n\nThe number of time points for time-varying legislator/person parameters\n\n\n\n\ntime_process\n\n\nThe process used to generate the ideal points: either ‘random’ for a random walk, ‘AR’ for an AR1 process, or ‘GP’ for a Gaussian process.\n\n\n\n\ntime_sd\n\n\nThe standard deviation of the change in ideal points over time (should be low relative to ideal_pts_sd)\n\n\n\n\nideal_pts_sd\n\n\nThe SD for the person/person ideal points\n\n\n\n\nprior_type\n\n\nThe statistical distribution that generates the data for ideal point parameters (alpha) and difficulty intercepts (beta and omega). Currently only ‘gaussian’ is supported.\n\n\n\n\nordinal_outcomes\n\n\nIf model is ‘ordinal’, an integer giving the total number of categories\n\n\n\n\ninflate\n\n\nIf TRUE, an missing-data-inflated dataset is produced.\n\n\n\n\nsigma_sd\n\n\nIf a normal or log-normal distribution is being fitted, this parameter gives the standard\n\n\n\n\nphi\n\n\nThe phi (dispersion) parameter for the ordered beta distribution deviation of the outcome (i.e. the square root of the variance).\n\n\n\n\n\n\nThis function produces simulated data that matches (as closely as possible) the models used in the underlying Stan code. Currently the simulation can produce inflated and non-inflated models with binary, ordinal (GRM and rating-scale), Poisson, Normal and Log-Normal responses.\n\n\n\nThe results is a idealdata object that can be used in the id_estimate function to run a model. It can also be used in the simulation plotting functions.\n\n\n\nid_plot_sims for plotting fitted models versus true values.",
    "crumbs": [
      "Reference",
      "id_sim_gen"
    ]
  },
  {
    "objectID": "man/id_sim_gen.html#simulate-irt-ideal-point-data",
    "href": "man/id_sim_gen.html#simulate-irt-ideal-point-data",
    "title": "idealstan",
    "section": "",
    "text": "A function designed to simulate IRT ideal point data.\n\n\n\nid_sim_gen(\n  num_person = 20,\n  num_items = 50,\n  cov_effect = NULL,\n  model_type = \"binary\",\n  latent_space = FALSE,\n  absence_discrim_sd = 3,\n  absence_diff_mean = 0,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  diff_sd = 3,\n  time_points = 1,\n  time_process = \"random\",\n  time_sd = 0.1,\n  ideal_pts_sd = 3,\n  prior_type = \"gaussian\",\n  ordinal_outcomes = 3,\n  inflate = FALSE,\n  sigma_sd = 1,\n  phi = 1\n)\n\n\n\n\n\n\n\nnum_person\n\n\nThe number of persons/persons\n\n\n\n\nnum_items\n\n\nThe number of items (bills in the canonical ideal point model)\n\n\n\n\ncov_effect\n\n\nThe effect of a hierarchical/external covariate on the person ideal points. The covariate will be a uniformly-distributed random variable on the [0,1] scale, so covariate effects in the [-2,2] approximate range would result in noticeable effects on the ideal point scale.\n\n\n\n\nmodel_type\n\n\nOne of ‘binary’, ‘ordinal_rating’, ‘ordinal_grm’, ‘poisson’ ‘normal’, or ‘lognormal’\n\n\n\n\nlatent_space\n\n\nWhether to use the latent space formulation of the ideal point model FALSE by default. NOTE: currently, the package only has estimation for a binary response with the latent space formulation.\n\n\n\n\nabsence_discrim_sd\n\n\nThe SD of the discrimination parameters for the inflated model\n\n\n\n\nabsence_diff_mean\n\n\nThe mean intercept for the inflated model; increasing it will lower the total number of missing data\n\n\n\n\ndiscrim_reg_upb\n\n\nThe upper bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_lb\n\n\nThe lower bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_upb\n\n\nThe upper bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_lb\n\n\nThe lower bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_reg_scale\n\n\nThe scale parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_shape\n\n\nThe shape parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_scale\n\n\nThe scale parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_shape\n\n\nThe shape parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiff_sd\n\n\nThe SD of the difficulty parameters (bill/item intercepts) for both missing and observed parameters (beta and omega)\n\n\n\n\ntime_points\n\n\nThe number of time points for time-varying legislator/person parameters\n\n\n\n\ntime_process\n\n\nThe process used to generate the ideal points: either ‘random’ for a random walk, ‘AR’ for an AR1 process, or ‘GP’ for a Gaussian process.\n\n\n\n\ntime_sd\n\n\nThe standard deviation of the change in ideal points over time (should be low relative to ideal_pts_sd)\n\n\n\n\nideal_pts_sd\n\n\nThe SD for the person/person ideal points\n\n\n\n\nprior_type\n\n\nThe statistical distribution that generates the data for ideal point parameters (alpha) and difficulty intercepts (beta and omega). Currently only ‘gaussian’ is supported.\n\n\n\n\nordinal_outcomes\n\n\nIf model is ‘ordinal’, an integer giving the total number of categories\n\n\n\n\ninflate\n\n\nIf TRUE, an missing-data-inflated dataset is produced.\n\n\n\n\nsigma_sd\n\n\nIf a normal or log-normal distribution is being fitted, this parameter gives the standard\n\n\n\n\nphi\n\n\nThe phi (dispersion) parameter for the ordered beta distribution deviation of the outcome (i.e. the square root of the variance).\n\n\n\n\n\n\nThis function produces simulated data that matches (as closely as possible) the models used in the underlying Stan code. Currently the simulation can produce inflated and non-inflated models with binary, ordinal (GRM and rating-scale), Poisson, Normal and Log-Normal responses.\n\n\n\nThe results is a idealdata object that can be used in the id_estimate function to run a model. It can also be used in the simulation plotting functions.\n\n\n\nid_plot_sims for plotting fitted models versus true values.",
    "crumbs": [
      "Reference",
      "id_sim_gen"
    ]
  },
  {
    "objectID": "man/id_plot_rhats.html",
    "href": "man/id_plot_rhats.html",
    "title": "idealstan",
    "section": "",
    "text": "This plotting function displays a histogram of the Rhat values of all parameters in an idealstan model.\n\n\n\nid_plot_rhats(obj)\n\n\n\n\n\n\n\nobj\n\n\nA fitted idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot_rhats"
    ]
  },
  {
    "objectID": "man/id_plot_rhats.html#plotting-function-to-display-rhat-distribution",
    "href": "man/id_plot_rhats.html#plotting-function-to-display-rhat-distribution",
    "title": "idealstan",
    "section": "",
    "text": "This plotting function displays a histogram of the Rhat values of all parameters in an idealstan model.\n\n\n\nid_plot_rhats(obj)\n\n\n\n\n\n\n\nobj\n\n\nA fitted idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot_rhats"
    ]
  },
  {
    "objectID": "man/idealdata-class.html",
    "href": "man/idealdata-class.html",
    "title": "idealstan",
    "section": "",
    "text": "idealdata objects contain the relevant legislator/bill (person/item) matrix of data along with slots containing information about the kind of identification used in the estimation.\n\n\n\nid_make to create an idealdata object suitable for estimation with id_estimate.",
    "crumbs": [
      "Reference",
      "idealdata-class"
    ]
  },
  {
    "objectID": "man/idealdata-class.html#data-and-identification-for-id_estimate",
    "href": "man/idealdata-class.html#data-and-identification-for-id_estimate",
    "title": "idealstan",
    "section": "",
    "text": "idealdata objects contain the relevant legislator/bill (person/item) matrix of data along with slots containing information about the kind of identification used in the estimation.\n\n\n\nid_make to create an idealdata object suitable for estimation with id_estimate.",
    "crumbs": [
      "Reference",
      "idealdata-class"
    ]
  },
  {
    "objectID": "man/id_plot_legis_var.html",
    "href": "man/id_plot_legis_var.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the over-time variances (average rates of change in ideal points) for all the persons/legislators in the model.\n\n\n\nid_plot_legis_var(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.1,\n  group_color = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis function will plot the person/legislator over-time variances as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options).\n\n\n\n\nlibrary(idealstan)\n\n\n# To demonstrate, we load the 114th Senate data and fit a time-varying model\n\ndata('senate114_fit')\n\nsenate_data &lt;- id_make(senate114,outcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nmiss_val='Absent')\n\n senate114_time_fit &lt;- id_estimate(senate_data,\n model_type = 2,\n use_vb = T,\n fixtype='vb_partial',\n vary_ideal_pts='random_walk',\n restrict_ind_high = \"WARREN, Elizabeth\",\n restrict_ind_low=\"BARRASSO, John A.\",\n seed=84520)\n# We plot the variances for all the Senators\n\nid_plot_legis_var(senate114_fit)",
    "crumbs": [
      "Reference",
      "id_plot_legis_var"
    ]
  },
  {
    "objectID": "man/id_plot_legis_var.html#plot-legislatorperson-over-time-variances",
    "href": "man/id_plot_legis_var.html#plot-legislatorperson-over-time-variances",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the over-time variances (average rates of change in ideal points) for all the persons/legislators in the model.\n\n\n\nid_plot_legis_var(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.1,\n  group_color = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis function will plot the person/legislator over-time variances as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options).\n\n\n\n\nlibrary(idealstan)\n\n\n# To demonstrate, we load the 114th Senate data and fit a time-varying model\n\ndata('senate114_fit')\n\nsenate_data &lt;- id_make(senate114,outcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nmiss_val='Absent')\n\n senate114_time_fit &lt;- id_estimate(senate_data,\n model_type = 2,\n use_vb = T,\n fixtype='vb_partial',\n vary_ideal_pts='random_walk',\n restrict_ind_high = \"WARREN, Elizabeth\",\n restrict_ind_low=\"BARRASSO, John A.\",\n seed=84520)\n# We plot the variances for all the Senators\n\nid_plot_legis_var(senate114_fit)",
    "crumbs": [
      "Reference",
      "id_plot_legis_var"
    ]
  },
  {
    "objectID": "man/senate114.html",
    "href": "man/senate114.html",
    "title": "idealstan",
    "section": "",
    "text": "This rollcall vote object (see rollcall) contains voting records for the 114th Senate in the US Congress. Not all rollcalls are included, only those that had a 70-30 or closer split in the vote. The data can be pre-processed via the id_make function for estimation. See package vignette for details.\n\n\n\nsenate114\n\n\n\n\nA long data frame with one row for every vote cast by a Senator.\n\n\n\nhttp://www.voteview.com/",
    "crumbs": [
      "Reference",
      "senate114"
    ]
  },
  {
    "objectID": "man/senate114.html#rollcall-vote-data-for-114th-senate",
    "href": "man/senate114.html#rollcall-vote-data-for-114th-senate",
    "title": "idealstan",
    "section": "",
    "text": "This rollcall vote object (see rollcall) contains voting records for the 114th Senate in the US Congress. Not all rollcalls are included, only those that had a 70-30 or closer split in the vote. The data can be pre-processed via the id_make function for estimation. See package vignette for details.\n\n\n\nsenate114\n\n\n\n\nA long data frame with one row for every vote cast by a Senator.\n\n\n\nhttp://www.voteview.com/",
    "crumbs": [
      "Reference",
      "senate114"
    ]
  },
  {
    "objectID": "man/summary-idealstan-method.html",
    "href": "man/summary-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function produces quantiles and standard deviations for the posterior samples of idealstan objects.\n\n\n\n## S4 method for signature 'idealstan'\nsummary(\n  object,\n  pars = \"ideal_pts\",\n  high_limit = 0.95,\n  low_limit = 0.05,\n  aggregated = TRUE,\n  use_chain = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object fitted by id_estimate\n\n\n\n\npars\n\n\nEither ‘ideal_pts’ for person ideal points, ‘items’ for items/bills difficulty and discrimination parameters, and ‘all’ for all parameters in the model, including incidental parameters.\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 reflecting the upper limit of the uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 reflecting the lower limit of the uncertainty interval (defaults to 0.05).\n\n\n\n\naggregated\n\n\nWhether to return summaries of the posterior values or the full posterior samples. Defaults to TRUE.\n\n\n\n\nuse_chain\n\n\nID of a specific MCMC chain to use. Default (NULL) is all the chains and is recommended.\n\n\n\n\n\n\nA tibble data frame with parameters as rows and descriptive statistics as columns",
    "crumbs": [
      "Reference",
      "summary-idealstan-method"
    ]
  },
  {
    "objectID": "man/summary-idealstan-method.html#posterior-summaries-for-fitted-idealstan-object",
    "href": "man/summary-idealstan-method.html#posterior-summaries-for-fitted-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This function produces quantiles and standard deviations for the posterior samples of idealstan objects.\n\n\n\n## S4 method for signature 'idealstan'\nsummary(\n  object,\n  pars = \"ideal_pts\",\n  high_limit = 0.95,\n  low_limit = 0.05,\n  aggregated = TRUE,\n  use_chain = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object fitted by id_estimate\n\n\n\n\npars\n\n\nEither ‘ideal_pts’ for person ideal points, ‘items’ for items/bills difficulty and discrimination parameters, and ‘all’ for all parameters in the model, including incidental parameters.\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 reflecting the upper limit of the uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 reflecting the lower limit of the uncertainty interval (defaults to 0.05).\n\n\n\n\naggregated\n\n\nWhether to return summaries of the posterior values or the full posterior samples. Defaults to TRUE.\n\n\n\n\nuse_chain\n\n\nID of a specific MCMC chain to use. Default (NULL) is all the chains and is recommended.\n\n\n\n\n\n\nA tibble data frame with parameters as rows and descriptive statistics as columns",
    "crumbs": [
      "Reference",
      "summary-idealstan-method"
    ]
  },
  {
    "objectID": "man/launch_shinystan.html",
    "href": "man/launch_shinystan.html",
    "title": "idealstan",
    "section": "",
    "text": "A generic function for launching launch_shinystan.\n\n\n\nlaunch_shinystan(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object.\n\n\n\n\n…\n\n\nOther arguments passed on to underlying function",
    "crumbs": [
      "Reference",
      "launch_shinystan"
    ]
  },
  {
    "objectID": "man/launch_shinystan.html#generic-method-to-use-shinystan-with-idealstan",
    "href": "man/launch_shinystan.html#generic-method-to-use-shinystan-with-idealstan",
    "title": "idealstan",
    "section": "",
    "text": "A generic function for launching launch_shinystan.\n\n\n\nlaunch_shinystan(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object.\n\n\n\n\n…\n\n\nOther arguments passed on to underlying function",
    "crumbs": [
      "Reference",
      "launch_shinystan"
    ]
  },
  {
    "objectID": "man/id_me.html",
    "href": "man/id_me.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to calculate ideal point marginal effects for a given person-level hierarchical covariate.\n\n\n\nid_me(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\ncovariate\n\n\nThe character value for a covariate passed to the ‘id_make’ function before model fitting. Only one covariate can be processed at a time.\n\n\n\n\neps\n\n\nThe value used for numerical differentiation. Default is 1e-4. Usually does not need to be changed.\n\n\n\n\n\n\nThis function will calculate item-level ideal point marginal effects for a given covariate that was passed to the ‘id_make’ function using the ‘person_cov’ option. The function will iterate over all items in the model and use numerical differentiation to calculate responses in the scale of the outcome for each item. Note: if the covariate is binary (i.e., only has two values), then the function will calculate the difference between these two values instead of using numerical differentation.\n\n\n\nReturns a tibble that has one row per posterior draw per item-specific marginal effect in the scale of th eoutcome.",
    "crumbs": [
      "Reference",
      "id_me"
    ]
  },
  {
    "objectID": "man/id_me.html#calculate-ideal-point-marginal-effects",
    "href": "man/id_me.html#calculate-ideal-point-marginal-effects",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to calculate ideal point marginal effects for a given person-level hierarchical covariate.\n\n\n\nid_me(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\ncovariate\n\n\nThe character value for a covariate passed to the ‘id_make’ function before model fitting. Only one covariate can be processed at a time.\n\n\n\n\neps\n\n\nThe value used for numerical differentiation. Default is 1e-4. Usually does not need to be changed.\n\n\n\n\n\n\nThis function will calculate item-level ideal point marginal effects for a given covariate that was passed to the ‘id_make’ function using the ‘person_cov’ option. The function will iterate over all items in the model and use numerical differentiation to calculate responses in the scale of the outcome for each item. Note: if the covariate is binary (i.e., only has two values), then the function will calculate the difference between these two values instead of using numerical differentation.\n\n\n\nReturns a tibble that has one row per posterior draw per item-specific marginal effect in the scale of th eoutcome.",
    "crumbs": [
      "Reference",
      "id_me"
    ]
  },
  {
    "objectID": "man/derive_chain.html",
    "href": "man/derive_chain.html",
    "title": "idealstan",
    "section": "",
    "text": "This function accepts a log-likelihood matrix produced by ‘id_post_pred’ and extracts the IDs of the MCMC chains. It is necessary to use this function as the second argument to the ‘loo’ function along with an exponentiated log-likelihood matrix. See the package vignette How to Evaluate Models for more details.\n\n\n\nderive_chain(ll_matrix = NULL)\n\n\n\n\n\n\n\nll_matrix\n\n\nA log-likelihood matrix as produced by the id_post_pred function",
    "crumbs": [
      "Reference",
      "derive_chain"
    ]
  },
  {
    "objectID": "man/derive_chain.html#helper-function-for-loo-calculation",
    "href": "man/derive_chain.html#helper-function-for-loo-calculation",
    "title": "idealstan",
    "section": "",
    "text": "This function accepts a log-likelihood matrix produced by ‘id_post_pred’ and extracts the IDs of the MCMC chains. It is necessary to use this function as the second argument to the ‘loo’ function along with an exponentiated log-likelihood matrix. See the package vignette How to Evaluate Models for more details.\n\n\n\nderive_chain(ll_matrix = NULL)\n\n\n\n\n\n\n\nll_matrix\n\n\nA log-likelihood matrix as produced by the id_post_pred function",
    "crumbs": [
      "Reference",
      "derive_chain"
    ]
  },
  {
    "objectID": "man/id_sim_resid.html",
    "href": "man/id_sim_resid.html",
    "title": "idealstan",
    "section": "",
    "text": "Residual function for checking estimated samples compared to true simulation scores Returns a data frame with residuals plus quantiles.\n\nDescription\nResidual function for checking estimated samples compared to true simulation scores Returns a data frame with residuals plus quantiles.\n\n\nUsage\nid_sim_resid(obj, rep = 1)\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data from id_sim_gen\n\n\n\n\nrep\n\n\nOver how many replicates to calculate residuals? Currently can only be 1",
    "crumbs": [
      "Reference",
      "id_sim_resid"
    ]
  },
  {
    "objectID": "man/id_make.html",
    "href": "man/id_make.html",
    "title": "idealstan",
    "section": "",
    "text": "To run an IRT model using idealstan, you must first process your data using the id_make function.\n\n\n\nid_make(\n  score_data = NULL,\n  outcome_disc = \"outcome_disc\",\n  outcome_cont = \"outcome_cont\",\n  person_id = \"person_id\",\n  item_id = \"item_id\",\n  time_id = \"time_id\",\n  group_id = \"group_id\",\n  model_id = \"model_id\",\n  ordered_id = \"ordered_id\",\n  ignore_id = \"ignore_id\",\n  simul_data = NULL,\n  person_cov = NULL,\n  item_cov = NULL,\n  item_cov_miss = NULL,\n  remove_cov_int = FALSE,\n  unbounded = FALSE,\n  exclude_level = NA,\n  simulation = FALSE\n)\n\n\n\n\n\n\n\nscore_data\n\n\nA data frame in long form, i.e., one row in the data for each measured score or vote in the data or a rollcall data object from package pscl.\n\n\n\n\noutcome_disc\n\n\nColumn name of the outcome with discrete values in score_data, default is “outcome_disc”\n\n\n\n\noutcome_cont\n\n\nColumn name of the outcome with discrete values in score_data, default is “outcome_disc”\n\n\n\n\nperson_id\n\n\nColumn name of the person/legislator ID index in score_data, default is ‘person_id’. Should be integer, character or factor.\n\n\n\n\nitem_id\n\n\nColumn name of the item/bill ID index in score_data, default is ‘item_id’. Should be integer, character or factor.\n\n\n\n\ntime_id\n\n\nColumn name of the time values in score_data: optional, default is ‘time_id’. Should be a date or date-time class, but can be an integer (i.e., years in whole numbers).\n\n\n\n\ngroup_id\n\n\nOptional column name of a person/legislator group IDs (i.e., parties) in score_data. Optional, default is ‘group_id’. Should be integer, character or factor.\n\n\n\n\nmodel_id\n\n\nColumn name of the model/response types in the data. Default is “model_id”. Only necessary if a model with multiple response types (i.e., binary + continuous outcomes). Must be a column with a series of integers matching the model types in id_estimate showing which row of the data matches which outcome.\n\n\n\n\nordered_id\n\n\nColumn name of the variable showing the count of categories for ordinal/categorical items (must be at least 3 categories)\n\n\n\n\nignore_id\n\n\nOptional column for identifying observations that should not be modeled (i.e., not just treated as missing, rather removed during estimation). Should be a binary vector (0 for remove and 1 for include). Useful for time-varying models where persons may not be present during particular periods and missing data is ignorable.\n\n\n\n\nsimul_data\n\n\nOptionally, data that has been generated by the id_sim_gen function.\n\n\n\n\nperson_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the person/legislator ideal points\n\n\n\n\nitem_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the item/bill discrimination parameters for the regular model\n\n\n\n\nitem_cov_miss\n\n\nA one-sided formula that specifies the covariates in the dataset that will be used to hierarchically model the item/bill discrimination parameters for the missing data model.\n\n\n\n\nremove_cov_int\n\n\nWhether to remove constituent terms from hierarchical covariates that interact covariates with IDs like person_id or item_id. Set to TRUE if including these constituent terms would cause multi-collinearity with other terms in the model (such as running a group-level model with a group-level interaction or a person-level model with a person-level interaction).\n\n\n\n\nunbounded\n\n\nWhether or not the outcome/response is unbounded (i.e., continuous or Poisson). If it is, missing value is recoded as the maximum of the outcome + 1.\n\n\n\n\nexclude_level\n\n\nA vector of any values that should be treated as NA in the response matrix. Unlike missing values, these values will be dropped from the data before estimation rather than modeled explicitly.\n\n\n\n\nsimulation\n\n\nIf TRUE, simulated values are saved in the idealdata object for later plotting with the id_plot_sims function\n\n\n\n\n\n\nThis function accepts a long data frame where one row equals one item-person (bill-legislator) observation with associated continuous or discrete outcomes/responses. You either need to include columns with specific names as required by the id_make function such as person_id for person IDs and item_id for item IDs or specify the names of the columns containing the IDs to the id_make function for each column name (see examples). The only required columns are the item/bill ID and the person/legislator ID along with an outcome column, outcome_disc for discrete variables and outcome_cont for continuous variables. If both columns are included, then any value can be included for outcome_disc if there are values for outcome_cont and vice versa.\nIf items of multiple types are included, a column model_id must be included with the model type (see id_estimate function documentation for list of model IDs) for the response distribution, such as 1 for binary non-inflated, etc. If an ordinal outcome is included, an additional column ordered_id must be included that has the total count of categories for that ordinal variable (i.e., 3 for 3 categories).\nFor discrete data, it is recommended to include a numeric variable that starts at 0, such as values of 0 and 1 for binary data and 0,1,2 for ordinal/categorical data. For continuous (unbounded) data, it is recommended to standardize the outcome to improve model convergence and fit.\nMissing data should be passed as NA values in either outcome_disc or outcome_cont and will be processed internally.\n\n\n\nA idealdata object that can then be used in the id_estimate function to fit a model.\n\n\n\nTo run a time-varying model, you need to include the name of a column with dates (or integers) that is passed to the time_id option.\n\n\n\nIf the outcome is continuous, you need to pass a dataframe with one column named \"outcome_disc\" or pass the name of the column with the continuous data to the outcome_disc argument.\n\n\n\nCovariates can be fit on the person-level ideal point parameters as well as item discrimination parameters for either the inflated (missing) or non-inflated (observed) models. These covariates must be columns that were included with the data fed to the id_make function. The covariate relationships are specified as one-sided formulas, i.e. ~cov1 + cov2 + cov1cov2. To interact covariates with the person-level ideal points you can use ~cov1 + person_id + cov1person_id and for group-level ideal poins you can use ~cov1 + group_id + cov1*group_id where group_id or person_id is the same name as the name of the column for these options that you passed to id_make (i.e., the names of the columns in the original data). If you are also going to model these intercepts–i.e. you are interacting the covariate with person_id and the model is estimating ideal points at the person level–then set remove_cov_int to TRUE to avoid multicollinearity with the ideal point intercepts.\n\n\n\n\nlibrary(idealstan)\n\n# You can either use a pscl rollcall object or a vote/score matrix \n# where persons/legislators are in the rows\n# and items/bills are in the columns\n\nlibrary(dplyr)\n\n# First, using a rollcall object with the 114th Senate's rollcall votes:\n\ndata('senate114')\n\nto_idealstan &lt;-   id_make(score_data = senate114,\n               outcome_disc = 'cast_code',\n               person_id = 'bioname',\n               item_id = 'rollnumber',\n               group_id= 'party_code',\n               time_id='date')",
    "crumbs": [
      "Reference",
      "id_make"
    ]
  },
  {
    "objectID": "man/id_make.html#create-data-to-run-irt-model",
    "href": "man/id_make.html#create-data-to-run-irt-model",
    "title": "idealstan",
    "section": "",
    "text": "To run an IRT model using idealstan, you must first process your data using the id_make function.\n\n\n\nid_make(\n  score_data = NULL,\n  outcome_disc = \"outcome_disc\",\n  outcome_cont = \"outcome_cont\",\n  person_id = \"person_id\",\n  item_id = \"item_id\",\n  time_id = \"time_id\",\n  group_id = \"group_id\",\n  model_id = \"model_id\",\n  ordered_id = \"ordered_id\",\n  ignore_id = \"ignore_id\",\n  simul_data = NULL,\n  person_cov = NULL,\n  item_cov = NULL,\n  item_cov_miss = NULL,\n  remove_cov_int = FALSE,\n  unbounded = FALSE,\n  exclude_level = NA,\n  simulation = FALSE\n)\n\n\n\n\n\n\n\nscore_data\n\n\nA data frame in long form, i.e., one row in the data for each measured score or vote in the data or a rollcall data object from package pscl.\n\n\n\n\noutcome_disc\n\n\nColumn name of the outcome with discrete values in score_data, default is “outcome_disc”\n\n\n\n\noutcome_cont\n\n\nColumn name of the outcome with discrete values in score_data, default is “outcome_disc”\n\n\n\n\nperson_id\n\n\nColumn name of the person/legislator ID index in score_data, default is ‘person_id’. Should be integer, character or factor.\n\n\n\n\nitem_id\n\n\nColumn name of the item/bill ID index in score_data, default is ‘item_id’. Should be integer, character or factor.\n\n\n\n\ntime_id\n\n\nColumn name of the time values in score_data: optional, default is ‘time_id’. Should be a date or date-time class, but can be an integer (i.e., years in whole numbers).\n\n\n\n\ngroup_id\n\n\nOptional column name of a person/legislator group IDs (i.e., parties) in score_data. Optional, default is ‘group_id’. Should be integer, character or factor.\n\n\n\n\nmodel_id\n\n\nColumn name of the model/response types in the data. Default is “model_id”. Only necessary if a model with multiple response types (i.e., binary + continuous outcomes). Must be a column with a series of integers matching the model types in id_estimate showing which row of the data matches which outcome.\n\n\n\n\nordered_id\n\n\nColumn name of the variable showing the count of categories for ordinal/categorical items (must be at least 3 categories)\n\n\n\n\nignore_id\n\n\nOptional column for identifying observations that should not be modeled (i.e., not just treated as missing, rather removed during estimation). Should be a binary vector (0 for remove and 1 for include). Useful for time-varying models where persons may not be present during particular periods and missing data is ignorable.\n\n\n\n\nsimul_data\n\n\nOptionally, data that has been generated by the id_sim_gen function.\n\n\n\n\nperson_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the person/legislator ideal points\n\n\n\n\nitem_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the item/bill discrimination parameters for the regular model\n\n\n\n\nitem_cov_miss\n\n\nA one-sided formula that specifies the covariates in the dataset that will be used to hierarchically model the item/bill discrimination parameters for the missing data model.\n\n\n\n\nremove_cov_int\n\n\nWhether to remove constituent terms from hierarchical covariates that interact covariates with IDs like person_id or item_id. Set to TRUE if including these constituent terms would cause multi-collinearity with other terms in the model (such as running a group-level model with a group-level interaction or a person-level model with a person-level interaction).\n\n\n\n\nunbounded\n\n\nWhether or not the outcome/response is unbounded (i.e., continuous or Poisson). If it is, missing value is recoded as the maximum of the outcome + 1.\n\n\n\n\nexclude_level\n\n\nA vector of any values that should be treated as NA in the response matrix. Unlike missing values, these values will be dropped from the data before estimation rather than modeled explicitly.\n\n\n\n\nsimulation\n\n\nIf TRUE, simulated values are saved in the idealdata object for later plotting with the id_plot_sims function\n\n\n\n\n\n\nThis function accepts a long data frame where one row equals one item-person (bill-legislator) observation with associated continuous or discrete outcomes/responses. You either need to include columns with specific names as required by the id_make function such as person_id for person IDs and item_id for item IDs or specify the names of the columns containing the IDs to the id_make function for each column name (see examples). The only required columns are the item/bill ID and the person/legislator ID along with an outcome column, outcome_disc for discrete variables and outcome_cont for continuous variables. If both columns are included, then any value can be included for outcome_disc if there are values for outcome_cont and vice versa.\nIf items of multiple types are included, a column model_id must be included with the model type (see id_estimate function documentation for list of model IDs) for the response distribution, such as 1 for binary non-inflated, etc. If an ordinal outcome is included, an additional column ordered_id must be included that has the total count of categories for that ordinal variable (i.e., 3 for 3 categories).\nFor discrete data, it is recommended to include a numeric variable that starts at 0, such as values of 0 and 1 for binary data and 0,1,2 for ordinal/categorical data. For continuous (unbounded) data, it is recommended to standardize the outcome to improve model convergence and fit.\nMissing data should be passed as NA values in either outcome_disc or outcome_cont and will be processed internally.\n\n\n\nA idealdata object that can then be used in the id_estimate function to fit a model.\n\n\n\nTo run a time-varying model, you need to include the name of a column with dates (or integers) that is passed to the time_id option.\n\n\n\nIf the outcome is continuous, you need to pass a dataframe with one column named \"outcome_disc\" or pass the name of the column with the continuous data to the outcome_disc argument.\n\n\n\nCovariates can be fit on the person-level ideal point parameters as well as item discrimination parameters for either the inflated (missing) or non-inflated (observed) models. These covariates must be columns that were included with the data fed to the id_make function. The covariate relationships are specified as one-sided formulas, i.e. ~cov1 + cov2 + cov1cov2. To interact covariates with the person-level ideal points you can use ~cov1 + person_id + cov1person_id and for group-level ideal poins you can use ~cov1 + group_id + cov1*group_id where group_id or person_id is the same name as the name of the column for these options that you passed to id_make (i.e., the names of the columns in the original data). If you are also going to model these intercepts–i.e. you are interacting the covariate with person_id and the model is estimating ideal points at the person level–then set remove_cov_int to TRUE to avoid multicollinearity with the ideal point intercepts.\n\n\n\n\nlibrary(idealstan)\n\n# You can either use a pscl rollcall object or a vote/score matrix \n# where persons/legislators are in the rows\n# and items/bills are in the columns\n\nlibrary(dplyr)\n\n# First, using a rollcall object with the 114th Senate's rollcall votes:\n\ndata('senate114')\n\nto_idealstan &lt;-   id_make(score_data = senate114,\n               outcome_disc = 'cast_code',\n               person_id = 'bioname',\n               item_id = 'rollnumber',\n               group_id= 'party_code',\n               time_id='date')",
    "crumbs": [
      "Reference",
      "id_make"
    ]
  },
  {
    "objectID": "man/id_post_pred-idealstan-method.html",
    "href": "man/id_post_pred-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will draw from the posterior distribution, whether in terms of the outcome (prediction) or to produce the log-likelihood values.\nThis function can also produce either distribution of the outcomes (i.e., predictions) or the log-likelihood values of the posterior (set option type to ‘log_lik’. For more information, see the package vignette How to Evaluate Models.\nYou can then use functions such as id_plot_ppc to see how well the model does returning the correct number of categories in the score/vote matrix. Also see help(“posterior_predict”, package = “rstanarm”)\n\n\n\n## S4 method for signature 'idealstan'\nid_post_pred(\n  object,\n  newdata = NULL,\n  draws = 100,\n  output = \"observed\",\n  type = \"predict\",\n  covar = \"person\",\n  sample_scores = NULL,\n  item_subset = NULL,\n  pred_outcome = NULL,\n  use_cores = 1,\n  use_chain = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nnewdata\n\n\nOptional: pass a data frame that must have all of the predictors that were given to the id_make function. Used to generate predictions from person or item covariates on to items.\n\n\n\n\ndraws\n\n\nThe number of draws to use from the total number of posterior draws (default is 100). Set to \"all\" to use all draws in the chains. For reproducibility, you can also pass a vector of specific draws to use.\n\n\n\n\noutput\n\n\nIf the model has an unbounded outcome (Poisson, continuous, etc.), then specify whether to show the ‘observed’ data (the default) or the binary output ‘missing’ showing whether an observation was predicted as missing or not\n\n\n\n\ntype\n\n\nWhether to produce posterior predictive values (‘predict’, the default), the posterior expected (average) values (‘epred’), or log-likelihood values (‘log_lik’). See the How to Evaluate Models vignette for more info.\n\n\n\n\ncovar\n\n\nWhat kind of covariates to include as part of the prediction – either \"person\" (the default) or \"items\" if you included predictors for item discriminations.\n\n\n\n\nsample_scores\n\n\nIn addition to reducing the number of posterior draws used to calculate the posterior predictive distribution, which will reduce computational overhead. Only available for calculating predictive distributions, not log-likelihood values.\n\n\n\n\nitem_subset\n\n\nWhether to calculate marginal effects for only a subset of items. Should be item IDs that match the item_id column passed to the id_make function.\n\n\n\n\npred_outcome\n\n\nIn the case of ordinal responses, the number of the category to predict. Defaults to top category.\n\n\n\n\nuse_cores\n\n\nNumber of cores to use for multicore parallel processing with the base R parallel package\n\n\n\n\nuse_chain\n\n\nID of MCMC chain to use rather than all chains (the default).\n\n\n\n\n…\n\n\nAny other arguments passed on to posterior_predict (currently none available)",
    "crumbs": [
      "Reference",
      "id_post_pred-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_post_pred-idealstan-method.html#posterior-prediction-for-idealstan-objects",
    "href": "man/id_post_pred-idealstan-method.html#posterior-prediction-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function will draw from the posterior distribution, whether in terms of the outcome (prediction) or to produce the log-likelihood values.\nThis function can also produce either distribution of the outcomes (i.e., predictions) or the log-likelihood values of the posterior (set option type to ‘log_lik’. For more information, see the package vignette How to Evaluate Models.\nYou can then use functions such as id_plot_ppc to see how well the model does returning the correct number of categories in the score/vote matrix. Also see help(“posterior_predict”, package = “rstanarm”)\n\n\n\n## S4 method for signature 'idealstan'\nid_post_pred(\n  object,\n  newdata = NULL,\n  draws = 100,\n  output = \"observed\",\n  type = \"predict\",\n  covar = \"person\",\n  sample_scores = NULL,\n  item_subset = NULL,\n  pred_outcome = NULL,\n  use_cores = 1,\n  use_chain = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nnewdata\n\n\nOptional: pass a data frame that must have all of the predictors that were given to the id_make function. Used to generate predictions from person or item covariates on to items.\n\n\n\n\ndraws\n\n\nThe number of draws to use from the total number of posterior draws (default is 100). Set to \"all\" to use all draws in the chains. For reproducibility, you can also pass a vector of specific draws to use.\n\n\n\n\noutput\n\n\nIf the model has an unbounded outcome (Poisson, continuous, etc.), then specify whether to show the ‘observed’ data (the default) or the binary output ‘missing’ showing whether an observation was predicted as missing or not\n\n\n\n\ntype\n\n\nWhether to produce posterior predictive values (‘predict’, the default), the posterior expected (average) values (‘epred’), or log-likelihood values (‘log_lik’). See the How to Evaluate Models vignette for more info.\n\n\n\n\ncovar\n\n\nWhat kind of covariates to include as part of the prediction – either \"person\" (the default) or \"items\" if you included predictors for item discriminations.\n\n\n\n\nsample_scores\n\n\nIn addition to reducing the number of posterior draws used to calculate the posterior predictive distribution, which will reduce computational overhead. Only available for calculating predictive distributions, not log-likelihood values.\n\n\n\n\nitem_subset\n\n\nWhether to calculate marginal effects for only a subset of items. Should be item IDs that match the item_id column passed to the id_make function.\n\n\n\n\npred_outcome\n\n\nIn the case of ordinal responses, the number of the category to predict. Defaults to top category.\n\n\n\n\nuse_cores\n\n\nNumber of cores to use for multicore parallel processing with the base R parallel package\n\n\n\n\nuse_chain\n\n\nID of MCMC chain to use rather than all chains (the default).\n\n\n\n\n…\n\n\nAny other arguments passed on to posterior_predict (currently none available)",
    "crumbs": [
      "Reference",
      "id_post_pred-idealstan-method"
    ]
  },
  {
    "objectID": "man/release_questions.html",
    "href": "man/release_questions.html",
    "title": "idealstan",
    "section": "",
    "text": "Function that provides additional check questions for package release\n\n\n\nrelease_questions()",
    "crumbs": [
      "Reference",
      "release_questions"
    ]
  },
  {
    "objectID": "man/release_questions.html#function-that-provides-additional-check-questions-for-package-release",
    "href": "man/release_questions.html#function-that-provides-additional-check-questions-for-package-release",
    "title": "idealstan",
    "section": "",
    "text": "Function that provides additional check questions for package release\n\n\n\nrelease_questions()",
    "crumbs": [
      "Reference",
      "release_questions"
    ]
  },
  {
    "objectID": "man/idealstan-class.html",
    "href": "man/idealstan-class.html",
    "title": "idealstan",
    "section": "",
    "text": "The idealstan objects store the results of estimations carried out by the id_estimate function. These objects include the full results of Bayesian sampling performed by the stan function in the rstan package.",
    "crumbs": [
      "Reference",
      "idealstan-class"
    ]
  },
  {
    "objectID": "man/idealstan-class.html#results-of-id_estimate-function",
    "href": "man/idealstan-class.html#results-of-id_estimate-function",
    "title": "idealstan",
    "section": "",
    "text": "The idealstan objects store the results of estimations carried out by the id_estimate function. These objects include the full results of Bayesian sampling performed by the stan function in the rstan package.",
    "crumbs": [
      "Reference",
      "idealstan-class"
    ]
  },
  {
    "objectID": "man/id_plot_sims.html",
    "href": "man/id_plot_sims.html",
    "title": "idealstan",
    "section": "",
    "text": "This function plots the results from a simulation generated by id_sim_gen.\n\n\n\nid_plot_sims(sims, type = \"RMSE\")\n\n\n\n\n\n\n\nsims\n\n\nA fitted idealstan object that has true data generated by id_sim_gen\n\n\n\n\ntype\n\n\nType of analysis of true versus fitted values, can be ‘RMSE’, ‘Residuals’ or ‘Coverage’",
    "crumbs": [
      "Reference",
      "id_plot_sims"
    ]
  },
  {
    "objectID": "man/id_plot_sims.html#this-function-plots-the-results-from-a-simulation-generated-by-id_sim_gen.",
    "href": "man/id_plot_sims.html#this-function-plots-the-results-from-a-simulation-generated-by-id_sim_gen.",
    "title": "idealstan",
    "section": "",
    "text": "This function plots the results from a simulation generated by id_sim_gen.\n\n\n\nid_plot_sims(sims, type = \"RMSE\")\n\n\n\n\n\n\n\nsims\n\n\nA fitted idealstan object that has true data generated by id_sim_gen\n\n\n\n\ntype\n\n\nType of analysis of true versus fitted values, can be ‘RMSE’, ‘Residuals’ or ‘Coverage’",
    "crumbs": [
      "Reference",
      "id_plot_sims"
    ]
  },
  {
    "objectID": "man/id_plot_compare.html",
    "href": "man/id_plot_compare.html",
    "title": "idealstan",
    "section": "",
    "text": "Function to compare two fitted idealstan models by plotting ideal points. Assumes that underlying data is the same for both models.\n\nDescription\nFunction to compare two fitted idealstan models by plotting ideal points. Assumes that underlying data is the same for both models.\n\n\nUsage\nid_plot_compare(\n  model1 = NULL,\n  model2 = NULL,\n  scale_flip = FALSE,\n  return_data = FALSE,\n  labels = NULL,\n  hjust = -0.1,\n  palette = \"Set1\",\n  color_direction = 1,\n  text_size_label = 2,\n  rescale = FALSE\n)\n\n\n\nArguments\n\n\n\nmodel1\n\n\nThe first model to compare\n\n\n\n\nmodel2\n\n\nThe second model to compare\n\n\n\n\nscale_flip\n\n\nThis parameter is set to true if you have two models that are reflected around the ideal point axis. This can happen as a result of identification and is harmless.\n\n\n\n\nreturn_data\n\n\nWhether to return the underlying data\n\n\n\n\nlabels\n\n\nTRUE or FALSE, whether to use labels for points\n\n\n\n\nhjust\n\n\nThe horizontal adjustment of point labels\n\n\n\n\npalette\n\n\ncolorbrewer palette name\n\n\n\n\ncolor_direction\n\n\nWhether to reverse the color scale\n\n\n\n\ntext_size_label\n\n\nSize of point labels\n\n\n\n\nrescale\n\n\nWhether to rescale the estimates from two models so they will match regardless of arbitrary scale shifts in the ideal points",
    "crumbs": [
      "Reference",
      "id_plot_compare"
    ]
  },
  {
    "objectID": "man/id_plot_cov.html",
    "href": "man/id_plot_cov.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will calculate and plot the ideal point marginal effects, or the first derivative of the IRT/ideal point model with respect to the hierarchical covariate, for each item in the model. The function id_me is used to first calculate the ideal point marginal effects.\n\n\n\nid_plot_cov(\n  object,\n  calc_param = NULL,\n  label_high = \"High\",\n  label_low = \"Low\",\n  group_effects = NULL,\n  plot_model_id = NULL,\n  pred_outcome = NULL,\n  lb = 0.05,\n  upb = 0.95,\n  facet_ncol = 2,\n  cov_type = \"person_cov\",\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncalc_param\n\n\nWhether to calculate ideal point marginal effects for a given covariate. If NULL, the default, the function will instead produce a plot of the raw coefficients from the ideal point model. If passing the name of a covariate, should be a character value of a column in the data passed to the id_make function.\n\n\n\n\nlabel_high\n\n\nWhat label to use on the plot for the high end of the latent scale\n\n\n\n\nlabel_low\n\n\nWhat label to use on the plot for the low end of the latent scale\n\n\n\n\nplot_model_id\n\n\nThe integer of the model ID to plot. If NULL and there are multiple model types, facet_wrap will be used to produce multiple plots with one for each model type.\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be the value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nlb\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\nupb\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nfacet_ncol\n\n\nIf facetting by multiple models or grouped factors, sets the number of columns in the multiple plots\n\n\n\n\ncov_type\n\n\nEither ‘person_cov’ for person or group-level hierarchical parameters, ‘discrim_reg_cov’ for bill/item discrimination parameters from regular (non-inflated) model, and ‘discrim_infl_cov’ for bill/item discrimination parameters from inflated model.\n\n\n\n\n…\n\n\nAdditional argument passed on to id_me\n\n\n\n\n\n\nThe ends of the latent variable can be specified via the label_low and label_high options, which will use those labels for item discrimination.\nNote that the function produces a ggplot2 object, which can be further modified with ggplot2 functions.\n\n\n\nA ggplot2 plot that can be further customized with ggplot2 functions if need be.",
    "crumbs": [
      "Reference",
      "id_plot_cov"
    ]
  },
  {
    "objectID": "man/id_plot_cov.html#marginal-effects-plot-for-hierarchical-covariates",
    "href": "man/id_plot_cov.html#marginal-effects-plot-for-hierarchical-covariates",
    "title": "idealstan",
    "section": "",
    "text": "This function will calculate and plot the ideal point marginal effects, or the first derivative of the IRT/ideal point model with respect to the hierarchical covariate, for each item in the model. The function id_me is used to first calculate the ideal point marginal effects.\n\n\n\nid_plot_cov(\n  object,\n  calc_param = NULL,\n  label_high = \"High\",\n  label_low = \"Low\",\n  group_effects = NULL,\n  plot_model_id = NULL,\n  pred_outcome = NULL,\n  lb = 0.05,\n  upb = 0.95,\n  facet_ncol = 2,\n  cov_type = \"person_cov\",\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncalc_param\n\n\nWhether to calculate ideal point marginal effects for a given covariate. If NULL, the default, the function will instead produce a plot of the raw coefficients from the ideal point model. If passing the name of a covariate, should be a character value of a column in the data passed to the id_make function.\n\n\n\n\nlabel_high\n\n\nWhat label to use on the plot for the high end of the latent scale\n\n\n\n\nlabel_low\n\n\nWhat label to use on the plot for the low end of the latent scale\n\n\n\n\nplot_model_id\n\n\nThe integer of the model ID to plot. If NULL and there are multiple model types, facet_wrap will be used to produce multiple plots with one for each model type.\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be the value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nlb\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\nupb\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nfacet_ncol\n\n\nIf facetting by multiple models or grouped factors, sets the number of columns in the multiple plots\n\n\n\n\ncov_type\n\n\nEither ‘person_cov’ for person or group-level hierarchical parameters, ‘discrim_reg_cov’ for bill/item discrimination parameters from regular (non-inflated) model, and ‘discrim_infl_cov’ for bill/item discrimination parameters from inflated model.\n\n\n\n\n…\n\n\nAdditional argument passed on to id_me\n\n\n\n\n\n\nThe ends of the latent variable can be specified via the label_low and label_high options, which will use those labels for item discrimination.\nNote that the function produces a ggplot2 object, which can be further modified with ggplot2 functions.\n\n\n\nA ggplot2 plot that can be further customized with ggplot2 functions if need be.",
    "crumbs": [
      "Reference",
      "id_plot_cov"
    ]
  },
  {
    "objectID": "man/launch_shinystan-idealstan-method.html",
    "href": "man/launch_shinystan-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This wrapper will pull the rstan samples out of a fitted idealstan model and then launch launch_shinystan. This function is useful for examining convergence statistics of the underlying MCMC sampling.\n\n\n\n## S4 method for signature 'idealstan'\nlaunch_shinystan(\n  object,\n  pars = c(\"L_full\", \"sigma_reg_full\", \"sigma_abs_free\", \"A_int_free\", \"B_int_free\",\n    \"steps_votes\", \"steps_votes_grm\"),\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\npars\n\n\nA character vector of parameters to select from the underlying rstan model object\n\n\n\n\n…\n\n\nOther parameters passed on to shinystan\n\n\n\n\n\n\nshinystan",
    "crumbs": [
      "Reference",
      "launch_shinystan-idealstan-method"
    ]
  },
  {
    "objectID": "man/launch_shinystan-idealstan-method.html#function-to-launch-shinystan-with-an-idealstan-object",
    "href": "man/launch_shinystan-idealstan-method.html#function-to-launch-shinystan-with-an-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This wrapper will pull the rstan samples out of a fitted idealstan model and then launch launch_shinystan. This function is useful for examining convergence statistics of the underlying MCMC sampling.\n\n\n\n## S4 method for signature 'idealstan'\nlaunch_shinystan(\n  object,\n  pars = c(\"L_full\", \"sigma_reg_full\", \"sigma_abs_free\", \"A_int_free\", \"B_int_free\",\n    \"steps_votes\", \"steps_votes_grm\"),\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\npars\n\n\nA character vector of parameters to select from the underlying rstan model object\n\n\n\n\n…\n\n\nOther parameters passed on to shinystan\n\n\n\n\n\n\nshinystan",
    "crumbs": [
      "Reference",
      "launch_shinystan-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_sim_coverage.html",
    "href": "man/id_sim_coverage.html",
    "title": "idealstan",
    "section": "",
    "text": "Function that computes how often the true value of the parameter is included within the 95/5 high posterior density interval\n\nDescription\nFunction that computes how often the true value of the parameter is included within the 95/5 high posterior density interval\n\n\nUsage\nid_sim_coverage(obj, rep = 1, quantiles = c(0.95, 0.05))\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data generated by id_sim_gen\n\n\n\n\nrep\n\n\nHow many times the models were fitted on new data, currently can only be 1\n\n\n\n\nquantiles\n\n\nWhat the quantile coverage of the high posterior density interval should be",
    "crumbs": [
      "Reference",
      "id_sim_coverage"
    ]
  },
  {
    "objectID": "man/delaware.html",
    "href": "man/delaware.html",
    "title": "idealstan",
    "section": "",
    "text": "This data frame contains the rollcall voting data for the Delaware state legislature from 1995 to present. The data is in long format so that each row is one vote cast by a legislator. It includes a column, ‘group_id’, that lists a party for each legislator (D=Democrat, R=Republican,X=Independent).\n\n\n\ndelaware\n\n\n\n\nA long data frame with one row for every vote cast by a legislator.\n\n\n\nThe original data come from Boris Shor and Nolan McCarty (2002), \"The Ideological Mapping of American Legislatures\", American Political Science Review.\n\n\n\nhttps://www.cambridge.org/core/journals/american-political-science-review/article/ideological-mapping-of-american-legislatures/8E1192C22AA0B9F9B56167998A41CAB0",
    "crumbs": [
      "Reference",
      "delaware"
    ]
  },
  {
    "objectID": "man/delaware.html#rollcall-vote-data-for-delaware-state-legislature",
    "href": "man/delaware.html#rollcall-vote-data-for-delaware-state-legislature",
    "title": "idealstan",
    "section": "",
    "text": "This data frame contains the rollcall voting data for the Delaware state legislature from 1995 to present. The data is in long format so that each row is one vote cast by a legislator. It includes a column, ‘group_id’, that lists a party for each legislator (D=Democrat, R=Republican,X=Independent).\n\n\n\ndelaware\n\n\n\n\nA long data frame with one row for every vote cast by a legislator.\n\n\n\nThe original data come from Boris Shor and Nolan McCarty (2002), \"The Ideological Mapping of American Legislatures\", American Political Science Review.\n\n\n\nhttps://www.cambridge.org/core/journals/american-political-science-review/article/ideological-mapping-of-american-legislatures/8E1192C22AA0B9F9B56167998A41CAB0",
    "crumbs": [
      "Reference",
      "delaware"
    ]
  },
  {
    "objectID": "man/id_extract.html",
    "href": "man/id_extract.html",
    "title": "idealstan",
    "section": "",
    "text": "This is a generic function.\n\n\n\nid_extract(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to underlying functions\n\n\n\n\n\n\nThis generic will extract the full stan posterior samples from idealstan objects.\nSee the corresponding method definition for more information about what you can acccess with this generic.",
    "crumbs": [
      "Reference",
      "id_extract"
    ]
  },
  {
    "objectID": "man/id_extract.html#generic-method-for-extracting-posterior-samples",
    "href": "man/id_extract.html#generic-method-for-extracting-posterior-samples",
    "title": "idealstan",
    "section": "",
    "text": "This is a generic function.\n\n\n\nid_extract(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to underlying functions\n\n\n\n\n\n\nThis generic will extract the full stan posterior samples from idealstan objects.\nSee the corresponding method definition for more information about what you can acccess with this generic.",
    "crumbs": [
      "Reference",
      "id_extract"
    ]
  },
  {
    "objectID": "man/id_plot_ppc-idealstan-method.html",
    "href": "man/id_plot_ppc-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is the actual method for generating posterior distributions from a fitted idealstan model.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot_ppc(\n  object,\n  ppc_pred = NULL,\n  group = NULL,\n  item = NULL,\n  combine_item = TRUE,\n  type = NULL,\n  which_mod = NULL,\n  prompt_plot = TRUE,\n  observed_only = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nppc_pred\n\n\nThe output of the id_post_pred function on a fitted idealstan object\n\n\n\n\ngroup\n\n\nA character vector of the person or group IDs over which to subset the predictive distribution\n\n\n\n\nitem\n\n\nA character vector of the item IDs over which to subset the predictive distribution\n\n\n\n\ncombine_item\n\n\nWhether to combine all items together (TRUE) or create one plot for each item (FALSE)\n\n\n\n\ntype\n\n\nWhether to plot \"continuous\" or \"discrete\" responses\n\n\n\n\nwhich_mod\n\n\nIf you are producing one plot aggregating data across multiple items and you have different item distributions, then you need to specify the item type number to plot (see function documentation in id_estimate).\n\n\n\n\nprompt_plot\n\n\nWhether to expect a user prompt for each plot if multiple plots are produced (defaults to TRUE) If NULL (default), will use the type specified in the data. However, if both continuous and discrete items are present, will throw an error if NULL.\n\n\n\n\nobserved_only\n\n\nIf the outcome is discrete and has missing data inflation, set to TRUE to only see the observed responses in the plot or FALSE to see all of the responses (missing data category will be the largest).\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars\n\n\n\n\n\n\nThis function is a wrapper around ppc_bars, ppc_dens_overlay and ppc_violin_grouped that plots the posterior predictive distribution derived from id_post_pred against the original data. Because idealstan allows for different distributions for each item, this function can either produce one predictive distribution for all items (the default) or it can produce one distribution for each item (set combine_item to FALSE). The latter is helpful if you have mixed distributions between items, such as continuous and dichotomous values. You can also subset the posterior predictions over legislators/persons or bills/item sby specifying the ID of each in the original data as a character vector. Only persons or items can be specified, not both.\nIf you specify a value for group that is either a person ID or a group ID (depending on whether a person or group-level model was fit), then you can see the posterior distributions for those specific persons. Similarly, if an item ID is passed to item, you can see how well the model predictions compare to the true values for that specific item.",
    "crumbs": [
      "Reference",
      "id_plot_ppc-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot_ppc-idealstan-method.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "href": "man/id_plot_ppc-idealstan-method.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is the actual method for generating posterior distributions from a fitted idealstan model.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot_ppc(\n  object,\n  ppc_pred = NULL,\n  group = NULL,\n  item = NULL,\n  combine_item = TRUE,\n  type = NULL,\n  which_mod = NULL,\n  prompt_plot = TRUE,\n  observed_only = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nppc_pred\n\n\nThe output of the id_post_pred function on a fitted idealstan object\n\n\n\n\ngroup\n\n\nA character vector of the person or group IDs over which to subset the predictive distribution\n\n\n\n\nitem\n\n\nA character vector of the item IDs over which to subset the predictive distribution\n\n\n\n\ncombine_item\n\n\nWhether to combine all items together (TRUE) or create one plot for each item (FALSE)\n\n\n\n\ntype\n\n\nWhether to plot \"continuous\" or \"discrete\" responses\n\n\n\n\nwhich_mod\n\n\nIf you are producing one plot aggregating data across multiple items and you have different item distributions, then you need to specify the item type number to plot (see function documentation in id_estimate).\n\n\n\n\nprompt_plot\n\n\nWhether to expect a user prompt for each plot if multiple plots are produced (defaults to TRUE) If NULL (default), will use the type specified in the data. However, if both continuous and discrete items are present, will throw an error if NULL.\n\n\n\n\nobserved_only\n\n\nIf the outcome is discrete and has missing data inflation, set to TRUE to only see the observed responses in the plot or FALSE to see all of the responses (missing data category will be the largest).\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars\n\n\n\n\n\n\nThis function is a wrapper around ppc_bars, ppc_dens_overlay and ppc_violin_grouped that plots the posterior predictive distribution derived from id_post_pred against the original data. Because idealstan allows for different distributions for each item, this function can either produce one predictive distribution for all items (the default) or it can produce one distribution for each item (set combine_item to FALSE). The latter is helpful if you have mixed distributions between items, such as continuous and dichotomous values. You can also subset the posterior predictions over legislators/persons or bills/item sby specifying the ID of each in the original data as a character vector. Only persons or items can be specified, not both.\nIf you specify a value for group that is either a person ID or a group ID (depending on whether a person or group-level model was fit), then you can see the posterior distributions for those specific persons. Similarly, if an item ID is passed to item, you can see how well the model predictions compare to the true values for that specific item.",
    "crumbs": [
      "Reference",
      "id_plot_ppc-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_me-idealstan-method.html",
    "href": "man/id_me-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to calculate ideal point marginal effects for a given person-level hierarchical covariate.\n\n\n\n## S4 method for signature 'idealstan'\nid_me(\n  object,\n  covariate = NULL,\n  group_effects = NULL,\n  pred_outcome = NULL,\n  eps = 1e-04,\n  draws = 100,\n  cores = 1,\n  lb = 0.05,\n  upb = 0.95\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\ncovariate\n\n\nThe character value for a covariate passed to the ‘id_make’ function before model fitting. Only one covariate can be processed at a time.\n\n\n\n\ngroup_effects\n\n\ncharacter value of a covariate included in the formula passed to ‘id_make’ for which marginal effect summaries should be grouped by. Useful when looking at the marginal effect of an interaction. Note that grouping by a covariate with many values will result in slow performance.\n\n\n\n\npred_outcome\n\n\nNumeric value for level of outcome to predict for ordinal responses. Defaults to top level.\n\n\n\n\neps\n\n\nThe value used for numerical differentiation. Default is 1e-4. Usually does not need to be changed.\n\n\n\n\ndraws\n\n\nThe total number of draws to use when calculating the marginal effects. Defaults to 100. Use option \"all\" to use all available MCMC draws.\n\n\n\n\ncores\n\n\nThe total number of cores to use when calculating the marginal effects. Defaults to 1.\n\n\n\n\nlb\n\n\nThe quantile for the lower bound of the aggregated effects (default is 0.05)\n\n\n\n\nupb\n\n\nThe quantile for the upper bound of the aggregated effects (default is 0.95)\n\n\n\n\n\n\nThis function will calculate item-level ideal point marginal effects for a given covariate that was passed to the ‘id_make’ function using the ‘person_cov’ option. The function will iterate over all items in the model and use numerical differentiation to calculate responses in the scale of the outcome for each item. Note: if the covariate is binary (i.e., only has two values), then the function will calculate the difference between these two values instead of using numerical differentation.\n\n\n\nA list with two objects, ideal_effects with one estimate of the marginal effect per item and posterior draw and sum_ideal_effects with one row per item with that item’s median ideal point marginal effect with the quantiles defined by the upb and lb parameters.",
    "crumbs": [
      "Reference",
      "id_me-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_me-idealstan-method.html#calculate-ideal-point-marginal-effects",
    "href": "man/id_me-idealstan-method.html#calculate-ideal-point-marginal-effects",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to calculate ideal point marginal effects for a given person-level hierarchical covariate.\n\n\n\n## S4 method for signature 'idealstan'\nid_me(\n  object,\n  covariate = NULL,\n  group_effects = NULL,\n  pred_outcome = NULL,\n  eps = 1e-04,\n  draws = 100,\n  cores = 1,\n  lb = 0.05,\n  upb = 0.95\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\ncovariate\n\n\nThe character value for a covariate passed to the ‘id_make’ function before model fitting. Only one covariate can be processed at a time.\n\n\n\n\ngroup_effects\n\n\ncharacter value of a covariate included in the formula passed to ‘id_make’ for which marginal effect summaries should be grouped by. Useful when looking at the marginal effect of an interaction. Note that grouping by a covariate with many values will result in slow performance.\n\n\n\n\npred_outcome\n\n\nNumeric value for level of outcome to predict for ordinal responses. Defaults to top level.\n\n\n\n\neps\n\n\nThe value used for numerical differentiation. Default is 1e-4. Usually does not need to be changed.\n\n\n\n\ndraws\n\n\nThe total number of draws to use when calculating the marginal effects. Defaults to 100. Use option \"all\" to use all available MCMC draws.\n\n\n\n\ncores\n\n\nThe total number of cores to use when calculating the marginal effects. Defaults to 1.\n\n\n\n\nlb\n\n\nThe quantile for the lower bound of the aggregated effects (default is 0.05)\n\n\n\n\nupb\n\n\nThe quantile for the upper bound of the aggregated effects (default is 0.95)\n\n\n\n\n\n\nThis function will calculate item-level ideal point marginal effects for a given covariate that was passed to the ‘id_make’ function using the ‘person_cov’ option. The function will iterate over all items in the model and use numerical differentiation to calculate responses in the scale of the outcome for each item. Note: if the covariate is binary (i.e., only has two values), then the function will calculate the difference between these two values instead of using numerical differentation.\n\n\n\nA list with two objects, ideal_effects with one estimate of the marginal effect per item and posterior draw and sum_ideal_effects with one row per item with that item’s median ideal point marginal effect with the quantiles defined by the upb and lb parameters.",
    "crumbs": [
      "Reference",
      "id_me-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_post_pred.html",
    "href": "man/id_post_pred.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is a generic that is used to match the functions used with ppc_bars to calculate the posterior predictive distribution of the data given the model.\n\n\n\nid_post_pred(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nAll other parameters passed on to the underlying function.\n\n\n\n\n\n\nposterior_predict methods should return a \\(D\\) by \\(N\\) matrix, where \\(D\\) is the number of draws from the posterior predictive distribution and \\(N\\) is the number of data points being predicted per draw.",
    "crumbs": [
      "Reference",
      "id_post_pred"
    ]
  },
  {
    "objectID": "man/id_post_pred.html#generic-method-for-obtaining-posterior-predictive-distribution-from-stan-objects",
    "href": "man/id_post_pred.html#generic-method-for-obtaining-posterior-predictive-distribution-from-stan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is a generic that is used to match the functions used with ppc_bars to calculate the posterior predictive distribution of the data given the model.\n\n\n\nid_post_pred(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nAll other parameters passed on to the underlying function.\n\n\n\n\n\n\nposterior_predict methods should return a \\(D\\) by \\(N\\) matrix, where \\(D\\) is the number of draws from the posterior predictive distribution and \\(N\\) is the number of data points being predicted per draw.",
    "crumbs": [
      "Reference",
      "id_post_pred"
    ]
  },
  {
    "objectID": "man/id_plot_ppc.html",
    "href": "man/id_plot_ppc.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is the generic method for generating posterior distributions from a fitted idealstan model. Functions are documented in the actual method.\n\n\n\nid_plot_ppc(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars\n\n\n\n\n\n\nThis function is a wrapper around ppc_bars, ppc_dens_overlay and ppc_violin_grouped that plots the posterior predictive distribution derived from id_post_pred against the original data. You can also subset the posterior predictions over legislators/persons or bills/item sby specifying the ID of each in the original data as a character vector. Only persons or items can be specified, not both.\nIf you specify a value for group that is either a person ID or a group ID (depending on whether a person or group-level model was fit), then you can see the posterior distributions for those specific persons. Similarly, if an item ID is passed to item, you can see how well the model predictions compare to the true values for that specific item.",
    "crumbs": [
      "Reference",
      "id_plot_ppc"
    ]
  },
  {
    "objectID": "man/id_plot_ppc.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "href": "man/id_plot_ppc.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is the generic method for generating posterior distributions from a fitted idealstan model. Functions are documented in the actual method.\n\n\n\nid_plot_ppc(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars\n\n\n\n\n\n\nThis function is a wrapper around ppc_bars, ppc_dens_overlay and ppc_violin_grouped that plots the posterior predictive distribution derived from id_post_pred against the original data. You can also subset the posterior predictions over legislators/persons or bills/item sby specifying the ID of each in the original data as a character vector. Only persons or items can be specified, not both.\nIf you specify a value for group that is either a person ID or a group ID (depending on whether a person or group-level model was fit), then you can see the posterior distributions for those specific persons. Similarly, if an item ID is passed to item, you can see how well the model predictions compare to the true values for that specific item.",
    "crumbs": [
      "Reference",
      "id_plot_ppc"
    ]
  },
  {
    "objectID": "man/stan_trace.html",
    "href": "man/stan_trace.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\nstan_trace(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\n…\n\n\nOther options passed on to stan_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace"
    ]
  },
  {
    "objectID": "man/stan_trace.html#plot-the-mcmc-posterior-draws-by-chain",
    "href": "man/stan_trace.html#plot-the-mcmc-posterior-draws-by-chain",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\nstan_trace(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\n…\n\n\nOther options passed on to stan_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace"
    ]
  },
  {
    "objectID": "man/stan_trace-idealstan-method.html",
    "href": "man/stan_trace-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\n## S4 method for signature 'idealstan'\nstan_trace(object, par = \"L_full[1]\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\npar\n\n\nThe character string name of a parameter in the model\n\n\n\n\n…\n\n\nOther options passed on to mcmc_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace-idealstan-method"
    ]
  },
  {
    "objectID": "man/stan_trace-idealstan-method.html#plot-the-mcmc-posterior-draws-by-chain",
    "href": "man/stan_trace-idealstan-method.html#plot-the-mcmc-posterior-draws-by-chain",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\n## S4 method for signature 'idealstan'\nstan_trace(object, par = \"L_full[1]\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\npar\n\n\nThe character string name of a parameter in the model\n\n\n\n\n…\n\n\nOther options passed on to mcmc_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_sim_rmse.html",
    "href": "man/id_sim_rmse.html",
    "title": "idealstan",
    "section": "",
    "text": "RMSE function for calculating individual RMSE values compared to true simulation scores Returns a data frame with RMSE plus quantiles.\n\nDescription\nRMSE function for calculating individual RMSE values compared to true simulation scores Returns a data frame with RMSE plus quantiles.\n\n\nUsage\nid_sim_rmse(obj, rep = 1)\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data from id_sim_gen\n\n\n\n\nrep\n\n\nOver how many replicates to calculate RMSE? Currently can only be 1",
    "crumbs": [
      "Reference",
      "id_sim_rmse"
    ]
  },
  {
    "objectID": "man/id_estimate.html",
    "href": "man/id_estimate.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will take a pre-processed idealdata vote/score dataframe and run one of the available IRT/latent space ideal point models on the data using Stan’s MCMC engine.\n\n\n\nid_estimate(\n  idealdata = NULL,\n  model_type = 2,\n  inflate_zero = FALSE,\n  vary_ideal_pts = \"none\",\n  keep_param = NULL,\n  grainsize = 1,\n  mpi_export = NULL,\n  use_subset = FALSE,\n  sample_it = FALSE,\n  subset_group = NULL,\n  subset_person = NULL,\n  sample_size = 20,\n  nchains = 4,\n  niters = 1000,\n  use_vb = FALSE,\n  ignore_db = NULL,\n  restrict_ind_high = NULL,\n  fix_high = 1,\n  fix_low = (-1),\n  restrict_ind_low = NULL,\n  num_restrict_high = 1,\n  num_restrict_low = 1,\n  fixtype = \"prefix\",\n  const_type = \"persons\",\n  id_refresh = 0,\n  prior_only = FALSE,\n  warmup = 1000,\n  ncores = 4,\n  use_groups = FALSE,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  person_sd = 3,\n  time_fix_sd = 0.1,\n  time_var = 10,\n  spline_knots = NULL,\n  spline_degree = 2,\n  ar1_up = 1,\n  ar1_down = 0,\n  boundary_prior = NULL,\n  time_center_cutoff = 50,\n  restrict_var = FALSE,\n  sample_stationary = FALSE,\n  ar_sd = 1,\n  diff_reg_sd = 3,\n  diff_miss_sd = 3,\n  restrict_sd_high = NULL,\n  restrict_sd_low = NULL,\n  restrict_N_high = 1000,\n  restrict_N_low = 1000,\n  ordbeta_phi_mean = 1,\n  ordbeta_cut_alpha = c(1, 1, 1),\n  ordbeta_cut_phi = 0,\n  gp_sd_par = 0.025,\n  gp_num_diff = 3,\n  gp_m_sd_par = 0.3,\n  gp_min_length = 0,\n  cmdstan_path_user = NULL,\n  map_over_id = \"persons\",\n  save_files = NULL,\n  compile_optim = FALSE,\n  debug = FALSE,\n  init_pathfinder = TRUE,\n  debug_mode = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nidealdata\n\n\nAn object produced by the id_make containing a score/vote matrix for use for estimation & plotting\n\n\n\n\nmodel_type\n\n\nAn integer reflecting the kind of model to be estimated. See below.\n\n\n\n\ninflate_zero\n\n\nIf the outcome is distributed as Poisson (count/unbounded integer), setting this to TRUE will fit a traditional zero-inflated model. To use correctly, the value for zero must be passed as the miss_val option to id_make before running a model so that zeroes are coded as missing data.\n\n\n\n\nvary_ideal_pts\n\n\nDefault ‘none’. If ‘random_walk’, ‘AR1’, ‘GP’, or ‘splines’, a time-varying ideal point model will be fit with either a random-walk process, an AR1 process, a Gaussian process or a spline. Note that the spline is the easiest time-varying model to fit so long as the number of knots (option spline_knots) is significantly less than the number of time points in the data. See documentation for more info.\n\n\n\n\nkeep_param\n\n\nA list with logical values for different categories of paremeters which should/should not be kept following estimation. Can be any/all of person_int for the person-level intercepts (static ideal points), person_vary for person-varying ideal points, item for observed item parameters (discriminations/intercepts), item_miss for missing item parameters (discriminations/intercepts), and extra for other parameters (hierarchical covariates, ordinal intercepts, etc.). Takes the form list(person_int=TRUE,person_vary=TRUE,item=TRUE,item_miss=TRUE,extra=TRUE). If any are missing in the list, it is assumed that those parameters will be excluded. If NULL (default), will save all parameters in output.\n\n\n\n\ngrainsize\n\n\nThe grainsize parameter for the reduce_sum function used for within-chain parallelization. The default is 1, which means 1 chunk (item or person) per core. Set to -1. to use\n\n\n\n\nmpi_export\n\n\nIf within_chains=“mpi”, this parameter should refer to the directory where the necessary data and Stan code will be exported to. If missing, an interactive dialogue will prompt the user for a directory.\n\n\n\n\nuse_subset\n\n\nWhether a subset of the legislators/persons should be used instead of the full response matrix\n\n\n\n\nsample_it\n\n\nWhether or not to use a random subsample of the response matrix. Useful for testing.\n\n\n\n\nsubset_group\n\n\nIf person/legislative data was included in the id_make function, then you can subset by any value in the $group column of that data if use_subset is TRUE.\n\n\n\n\nsubset_person\n\n\nA list of character values of names of persons/legislators to use to subset if use_subset is TRUE and person/legislative data was included in the id_make function with the required $person.names column\n\n\n\n\nsample_size\n\n\nIf sample_it is TRUE, this value reflects how many legislators/persons will be sampled from the response matrix\n\n\n\n\nnchains\n\n\nThe number of chains to use in Stan’s sampler. Minimum is one. See stan for more info. If use_vb=TRUE, this parameter will determine the number of Pathfinder paths to estimate.\n\n\n\n\nniters\n\n\nThe number of iterations to run Stan’s sampler. Shouldn’t be set much lower than 500. See stan for more info.\n\n\n\n\nuse_vb\n\n\nWhether or not to use Stan’s Pathfinder algorithm instead of full Bayesian inference. Pros: it’s much faster but can be much less accurate. Note that Pathfinder is also used by default for finding initial starting values for sfull HMC sampling.\n\n\n\n\nignore_db\n\n\nIf there are multiple time periods (particularly when there are very many time periods), you can pass in a data frame (or tibble) with one row per person per time period and an indicator column ignore that is equal to 1 for periods that should be considered in sample and 0 for periods for periods that should be considered out of sample. This is useful for excluding time periods from estimation for persons when they could not be present, i.e. such as before entrance into an organization or following death. If ignore equals 0, the person’s ideal point is estimated as a standard Normal draw rather than an auto-correlated parameter, reducing computational burden substantially. Note that there can only be one pre-sample period of 0s, one in-sample period of 1s, and one post-sample period of 0s. Multiple in-sample periods cannot be interspersed with out of sample periods. The columns must be labeled as person_id, time_id and ignore and must match the formatting of the columns fed to the id_make function.\n\n\n\n\nrestrict_ind_high\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a high value (default +1).\n\n\n\n\nfix_high\n\n\nA vector of length restrict_ind_high with values that the high fixed person ideal point(s) should be fixed to. Default is +1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nfix_low\n\n\nA vector of length restrict_ind_low with values that the high fixed person ideal point(s) should be fixed to. Default is -1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nrestrict_ind_low\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a low value (default -1).\n\n\n\n\nnum_restrict_high\n\n\nIf using variational inference for identification (fixtype=“vb_full”), how many parameters to constraint to positive values? Default is 1.\n\n\n\n\nnum_restrict_low\n\n\nIf using variational inference for identification (ixtype=“vb_full”), how many parameters to constraint to positive negative values? Default is 1.\n\n\n\n\nfixtype\n\n\nSets the particular kind of identification used on the model, could be either ‘vb_full’ (identification provided exclusively by running a variational identification model with no prior info), or ‘prefix’ (two indices of ideal points or items to fix are provided to options restrict_ind_high and restrict_ind_low). See details for more information.\n\n\n\n\nconst_type\n\n\nWhether “persons” are the parameters to be fixed for identification (the default) or “items”. Each of these pinned parameters should be specified to fix_high and fix_low if fixtype equals “prefix”, otherwise the model will select the parameters to pin to fixed values.\n\n\n\n\nid_refresh\n\n\nThe number of times to report iterations from the variational run used to identify models. Default is 0 (nothing output to console).\n\n\n\n\nprior_only\n\n\nWhether to only sample from priors as opposed to the full model with likelihood (the default). Useful for doing posterior predictive checks.\n\n\n\n\nwarmup\n\n\nThe number of iterations to use to calibrate Stan’s sampler on a given model. Shouldn’t be less than 100. See stan for more info.\n\n\n\n\nncores\n\n\nThe number of cores in your computer to use for parallel processing in the Stan engine. See stan for more info. If within_chain is set to “threads”, this parameter will determine the number of threads (independent processes) used for within-chain parallelization.\n\n\n\n\nuse_groups\n\n\nIf TRUE, group parameters from the person/legis data given in id_make will be estimated instead of individual parameters.\n\n\n\n\ndiscrim_reg_upb\n\n\nUpper bound of the rescaled Beta distribution for observed discrimination parameters (default is +1)\n\n\n\n\ndiscrim_reg_lb\n\n\nLower bound of the rescaled Beta distribution for observed discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_miss_upb\n\n\nUpper bound of the rescaled Beta distribution for missing discrimination parameters (default is +1)\n\n\n\n\ndiscrim_miss_lb\n\n\nLower bound of the rescaled Beta distribution for missing discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_reg_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_reg_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_miss_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ndiscrim_miss_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\nperson_sd\n\n\nThe standard deviation of the Normal distribution prior for persons (all non-constrained person ideal point parameters). Default is weakly informative (3) on the logit scale.\n\n\n\n\ntime_fix_sd\n\n\nThe variance of the over-time component of the first person/legislator is fixed to this value as a reference. Default is 0.1.\n\n\n\n\ntime_var\n\n\nThe mean of the exponential distribution for over-time variances for ideal point parameters. Default (10) is weakly informative on the logit scale.\n\n\n\n\nspline_knots\n\n\nNumber of knots (essentially, number of points at which to calculate time-varying ideal points given T time points). Default is NULL, which means that the spline is equivalent to polynomial time trend of degree spline_degree. Note that the spline number (if not null) must be equal or less than the number of time points–and there is no reason to have it equal to the number of time points as that will likely over-fit the data.\n\n\n\n\nspline_degree\n\n\nThe degree of the spline polynomial. The default is 2 which is a quadratic polynomial. A value of 1 will result in independent knots (essentially pooled across time points T). A higher value will result in wigglier time series. There is no \"correct\" value but lower values are likely more stable and easier to identify.\n\n\n\n\nar1_up\n\n\nThe upper bound of the AR(1) parameter, default is +1.\n\n\n\n\nar1_down\n\n\nThe lower bound of the AR(1) parameter, default is 0. Set to -1 to allow for inverse responses to time shocks.\n\n\n\n\nboundary_prior\n\n\nIf your time series has very low variance (change over time), you may want to use this option to put a boundary-avoiding inverse gamma prior on the time series variance parameters if your model has a lot of divergent transitions. To do so, pass a list with a element called beta that signifies the rate parameter of the inverse-gamma distribution. For example, try boundary_prior=list(beta=1). Increasing the value of beta will increase the \"push\" away from zero. Setting it too high will result in time series that exhibit a lot of \"wiggle\" without much need.\n\n\n\n\ntime_center_cutoff\n\n\nThe number of time points above which the model will employ a centered time series approach for AR(1) and random walk models. Below this number the model will employ a non-centered approach. The default is 50 time points, which is relatively arbitrary and higher values may be better if sampling quality is poor above the threshold.\n\n\n\n\nrestrict_var\n\n\nWhether to fix the variance parameter for the first person trajectory. Default is FALSE (usually not necessary).\n\n\n\n\nsample_stationary\n\n\nIf TRUE, the AR(1) coefficients in a time-varying model will be sampled from an unconstrained space and then mapped back to a stationary space. Leaving this TRUE is slower but will work better when there is limited information to identify a model. If used, the ar_sd parameter should be increased to 5 to allow for wider sampling in the unconstrained space.\n\n\n\n\nar_sd\n\n\nIf an AR(1) model is used, this defines the prior scale of the Normal distribution. A lower number can help identify the model when there are few time points.\n\n\n\n\ndiff_reg_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the non-inflated model.\n\n\n\n\ndiff_miss_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the inflated model.\n\n\n\n\nrestrict_sd_high\n\n\nSet the level of tightness for high fixed parameters (top/positive end of scale). If NULL, the default, will set to .1 if const_type=“persons” and 10 if const_type=“items”. For const_type=“persons”, value is the SD of normal distribution centered around fix_high. For const_type=“items”, parameter is equal to the prior shape for high pinned parameters (divide by restrict_N_high + restrict_sd_high) to get expected value.\n\n\n\n\nrestrict_sd_low\n\n\nSet the level of tightness for low fixed parameters (low/negative end of scale). If NULL, the default, will set to .1 if const_type=“persons” and 10 if const_type=“items”. For const_type=“persons”, value is the SD of normal distribution centered around fix_low. For const_type=“items”, parameter is equal to the prior shape for high pinned parameters (divide by restrict_N_low + restrict_sd_low) to get expected value.\n\n\n\n\nrestrict_N_high\n\n\nSet the prior scale for high/positive pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nrestrict_N_low\n\n\nSet the prior shape for low/negative pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nordbeta_phi_mean\n\n\nThe mean of the prior for phi, the dispersion parameter in the ordered beta distribution. Value of this parameter (default is 1) is given as the mean of the exponential distribution for prior values of phi.\n\n\n\n\nordbeta_cut_alpha\n\n\nA length 2 vector of positive continuous values for alpha in the induced dirichlet distribution. This distribution is used for the cutpoints of the ordered beta distribution. Default is c(1,1), which is uninformative.\n\n\n\n\nordbeta_cut_phi\n\n\nA value for the phi paremeter of the induced dirichlet distribution used for ordered beta cutpoint priors. Default is 0, which is weakly informative.\n\n\n\n\ngp_sd_par\n\n\nThe upper limit on allowed residual variation of the Gaussian process prior. Increasing the limit will permit the GP to more closely follow the time points, resulting in much sharper bends in the function and potentially oscillation.\n\n\n\n\ngp_num_diff\n\n\nThe number of time points to use to calculate the length-scale prior that determines the level of smoothness of the GP time process. Increasing this value will result in greater smoothness/autocorrelation over time by selecting a greater number of time points over which to calculate the length-scale prior.\n\n\n\n\ngp_m_sd_par\n\n\nThe upper limit of the marginal standard deviation of the GP time process. Decreasing this value will result in smoother fits.\n\n\n\n\ngp_min_length\n\n\nThe minimum value of the GP length-scale parameter. This is a hard lower limit. Increasing this value will force a smoother GP fit. It should always be less than gp_num_diff.\n\n\n\n\ncmdstan_path_user\n\n\nDefault is NULL, and so will default to whatever is set in cmdstanr package. Specify a file path here to use a different cmdtstan installation.\n\n\n\n\nmap_over_id\n\n\nThis parameter identifies which ID variable to use to construct the shards for within-chain parallelization. It defaults to “persons” but can also take a value of “items”. It is recommended to select whichever variable has more distinct values to improve parallelization.\n\n\n\n\nsave_files\n\n\nThe location to save CSV files with MCMC draws from cmdstanr. The default is NULL, which will use a folder in the package directory.\n\n\n\n\ncompile_optim\n\n\nWhether to use Stan compile optimization flags (off by default)\n\n\n\n\ndebug\n\n\nFor debugging purposes, turns off threading to enable more informative error messages from Stan. Also recompiles model objects.\n\n\n\n\ninit_pathfinder\n\n\nWhether to generate initial values from the Pathfinder algorithm (see Stan documentation). If FALSE, will generate random start values..\n\n\n\n\ndebug_mode\n\n\nWhether to print valuesof all parameters for debugging purposes. If this is used, only one iteration should be used as it generates a lot of console output.\n\n\n\n\n…\n\n\nAdditional parameters passed on to Stan’s sampling engine. See stan for more information.\n\n\n\n\n\n\nTo run an IRT ideal point model, you must first pre-process your data using the id_make function. Be sure to specify the correct options for the kind of model you are going to run: if you want to run an unbounded outcome (i.e. Poisson or continuous), the data needs to be processed differently. Also any hierarchical covariates at the person or item level need to be specified in id_make. If they are specified in id_make, than all subsequent models fit by this function will have these covariates.\nNote that for static ideal point models, the covariates are only defined for those persons who are not being used as constraints.\nAs of this version of idealstan, the following model types are available. Simply pass the number of the model in the list to the model_type option to fit the model.\n\n\nIRT 2-PL (binary response) ideal point model, no missing-data inflation\n\n\nIRT 2-PL ideal point model (binary response) with missing- inflation\n\n\nOrdinal IRT (rating scale) ideal point model no missing-data inflation\n\n\nOrdinal IRT (rating scale) ideal point model with missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model no missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model with missing-data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with no missing data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with missing-data inflation\n\n\nunbounded (Gaussian) IRT ideal point model with no missing data\n\n\nunbounded (Gaussian) IRT ideal point model with missing-data inflation\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with no missing data\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with missing-data inflation\n\n\nLatent Space (binary response) ideal point model with no missing data\n\n\nLatent Space (binary response) ideal point model with missing-data inflation\n\n\nOrdered Beta (proportion/percentage) with no missing data\n\n\nOrdered Beta (proportion/percentage) with missing-data inflation\n\n\n\n\n\nA fitted idealstan object that contains posterior samples of all parameters either via full Bayesian inference or a variational approximation if use_vb is set to TRUE. This object can then be passed to the plotting functions for further analysis.\n\n\n\nIn addition, each of these models can have time-varying ideal point (person) parameters if a column of dates is fed to the id_make function. If the option vary_ideal_pts is set to ‘random_walk’, id_estimate will estimate a random-walk ideal point model where ideal points move in a random direction. If vary_ideal_pts is set to ‘AR1’, a stationary ideal point model is estimated where ideal points fluctuate around long-term mean. If vary_ideal_pts is set to ‘GP’, then a semi-parametric Gaussian process time-series prior will be put around the ideal points. If vary_ideal_pts is set to ‘splines’, then the ideal point trajectories will be a basis spline defined by the parameters spline_knots and spline_degree. Please see the package vignette and associated paper for more detail about these time-varying models.\n\n\n\nThe inflation model used to account for missing data assumes that missingness is a function of the persons’ (legislators’) ideal points. In other words,the model will take into account if people with high or low ideal points tend to have more/less missing data on a specific item/bill. Missing data should be coded as NA when it is passed to the id_make function. If there isn’t any relationship between missing data and ideal points, then the model assumes that the missingness is ignorable conditional on each item, but it will still adjust the results to reflect these ignorable (random) missing values. The inflation is designed to be general enough to handle a wide array of potential situations where strategic social choices make missing data important to take into account.\nTo leave missing data out of the model, simply choose a version of the model in the list above that is non-inflated.\nModels can be either fit on the person/legislator IDs or on group-level IDs (as specified to the id_make function). If group-level parameters should be fit, set use_groups to TRUE.\n\n\n\nCovariates are included in the model if they were specified as options to the id_make function. The covariate plots can be accessed with id_plot_cov on a fitted idealstan model object.\n\n\n\nIdentifying IRT models is challenging, and ideal point models are still more challenging because the discrimination parameters are not constrained. As a result, more care must be taken to obtain estimates that are the same regardless of starting values. The parameter fixtype enables you to change the type of identification used. The default, ‘vb_full’, does not require any further information from you in order for the model to be fit. In this version of identification, an unidentified model is run using variational Bayesian inference (see vb). The function will then select two persons/legislators or items/bills that end up on either end of the ideal point spectrum, and pin their ideal points to those specific values. To control whether persons/legislator or items/bills are constrained, the const_type can be set to either “persons” or “items” respectively. In many situations, it is prudent to select those persons or items ahead of time to pin to specific values. This allows the analyst to be more specific about what type of latent dimension is to be estimated. To do so, the fixtype option should be set to “prefix”. The values of the persons/items to be pinned can be passed as character values to restrict_ind_high and restrict_ind_low to pin the high/low ends of the latent scale respectively. Note that these should be the actual data values passed to the id_make function. If you don’t pass any values, you will see a prompt asking you to select certain values of persons/items.\nThe pinned values for persons/items are set by default to +1/-1, though this can be changed using the fix_high and fix_low options. This pinned range is sufficient to identify all of the models implemented in idealstan, though fiddling with some parameters may be necessary in difficult cases. For time-series models, one of the person ideal point over-time variances is also fixed to .1, a value that can be changed using the option time_fix_sd.\n\n\n\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\nKubinec, R. \"Generalized Ideal Point Models for Time-Varying and Missing-Data Inference\". Working Paper.\n\n\nBetancourt, Michael. \"Robust Gaussian Processes in Stan\". (October 2017). Case Study.\n\n\n\n\n\nid_make for pre-processing data, id_plot_legis for plotting results, summary for obtaining posterior quantiles, id_post_pred for producing predictive replications.\n\n\n\n\nlibrary(idealstan)\n\n# First we can simulate data for an IRT 2-PL model that is inflated for missing data\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# This code will take at least a few minutes to run \nbin_irt_2pl_abs_sim &lt;- id_sim_gen(model_type='binary',inflate=T)\n\n# Now we can put that directly into the id_estimate function \n# to get full Bayesian posterior estimates\n# We will constrain discrimination parameters \n# for identification purposes based on the true simulated values\n\nbin_irt_2pl_abs_est &lt;- id_estimate(bin_irt_2pl_abs_sim,\n                       model_type=2,\n                       restrict_ind_high = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=TRUE,\n                       index=TRUE)$ix[1],\n                       restrict_ind_low = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=FALSE,\n                       index=TRUE)$ix[1],\n                       fixtype='prefix',\n                       ncores=2,\n                       nchains=2)\n                                   \n# We can now see how well the model recovered the true parameters\n\nid_sim_coverage(bin_irt_2pl_abs_est) %&gt;% \n         bind_rows(.id='Parameter') %&gt;% \n         ggplot(aes(y=avg,x=Parameter)) +\n           stat_summary(fun.args=list(mult=1.96)) + \n           theme_minimal()\n \n\n# In most cases, we will use pre-existing data \n# and we will need to use the id_make function first\n# We will use the full rollcall voting data \n# from the 114th Senate as a rollcall object\n\ndata('senate114')\n\n# Running this model will take at least a few minutes, even with \n# variational inference (use_vb=T) turned on\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(to_idealstan,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='prefix',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_estimate"
    ]
  },
  {
    "objectID": "man/id_estimate.html#estimate-an-idealstan-model",
    "href": "man/id_estimate.html#estimate-an-idealstan-model",
    "title": "idealstan",
    "section": "",
    "text": "This function will take a pre-processed idealdata vote/score dataframe and run one of the available IRT/latent space ideal point models on the data using Stan’s MCMC engine.\n\n\n\nid_estimate(\n  idealdata = NULL,\n  model_type = 2,\n  inflate_zero = FALSE,\n  vary_ideal_pts = \"none\",\n  keep_param = NULL,\n  grainsize = 1,\n  mpi_export = NULL,\n  use_subset = FALSE,\n  sample_it = FALSE,\n  subset_group = NULL,\n  subset_person = NULL,\n  sample_size = 20,\n  nchains = 4,\n  niters = 1000,\n  use_vb = FALSE,\n  ignore_db = NULL,\n  restrict_ind_high = NULL,\n  fix_high = 1,\n  fix_low = (-1),\n  restrict_ind_low = NULL,\n  num_restrict_high = 1,\n  num_restrict_low = 1,\n  fixtype = \"prefix\",\n  const_type = \"persons\",\n  id_refresh = 0,\n  prior_only = FALSE,\n  warmup = 1000,\n  ncores = 4,\n  use_groups = FALSE,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  person_sd = 3,\n  time_fix_sd = 0.1,\n  time_var = 10,\n  spline_knots = NULL,\n  spline_degree = 2,\n  ar1_up = 1,\n  ar1_down = 0,\n  boundary_prior = NULL,\n  time_center_cutoff = 50,\n  restrict_var = FALSE,\n  sample_stationary = FALSE,\n  ar_sd = 1,\n  diff_reg_sd = 3,\n  diff_miss_sd = 3,\n  restrict_sd_high = NULL,\n  restrict_sd_low = NULL,\n  restrict_N_high = 1000,\n  restrict_N_low = 1000,\n  ordbeta_phi_mean = 1,\n  ordbeta_cut_alpha = c(1, 1, 1),\n  ordbeta_cut_phi = 0,\n  gp_sd_par = 0.025,\n  gp_num_diff = 3,\n  gp_m_sd_par = 0.3,\n  gp_min_length = 0,\n  cmdstan_path_user = NULL,\n  map_over_id = \"persons\",\n  save_files = NULL,\n  compile_optim = FALSE,\n  debug = FALSE,\n  init_pathfinder = TRUE,\n  debug_mode = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nidealdata\n\n\nAn object produced by the id_make containing a score/vote matrix for use for estimation & plotting\n\n\n\n\nmodel_type\n\n\nAn integer reflecting the kind of model to be estimated. See below.\n\n\n\n\ninflate_zero\n\n\nIf the outcome is distributed as Poisson (count/unbounded integer), setting this to TRUE will fit a traditional zero-inflated model. To use correctly, the value for zero must be passed as the miss_val option to id_make before running a model so that zeroes are coded as missing data.\n\n\n\n\nvary_ideal_pts\n\n\nDefault ‘none’. If ‘random_walk’, ‘AR1’, ‘GP’, or ‘splines’, a time-varying ideal point model will be fit with either a random-walk process, an AR1 process, a Gaussian process or a spline. Note that the spline is the easiest time-varying model to fit so long as the number of knots (option spline_knots) is significantly less than the number of time points in the data. See documentation for more info.\n\n\n\n\nkeep_param\n\n\nA list with logical values for different categories of paremeters which should/should not be kept following estimation. Can be any/all of person_int for the person-level intercepts (static ideal points), person_vary for person-varying ideal points, item for observed item parameters (discriminations/intercepts), item_miss for missing item parameters (discriminations/intercepts), and extra for other parameters (hierarchical covariates, ordinal intercepts, etc.). Takes the form list(person_int=TRUE,person_vary=TRUE,item=TRUE,item_miss=TRUE,extra=TRUE). If any are missing in the list, it is assumed that those parameters will be excluded. If NULL (default), will save all parameters in output.\n\n\n\n\ngrainsize\n\n\nThe grainsize parameter for the reduce_sum function used for within-chain parallelization. The default is 1, which means 1 chunk (item or person) per core. Set to -1. to use\n\n\n\n\nmpi_export\n\n\nIf within_chains=“mpi”, this parameter should refer to the directory where the necessary data and Stan code will be exported to. If missing, an interactive dialogue will prompt the user for a directory.\n\n\n\n\nuse_subset\n\n\nWhether a subset of the legislators/persons should be used instead of the full response matrix\n\n\n\n\nsample_it\n\n\nWhether or not to use a random subsample of the response matrix. Useful for testing.\n\n\n\n\nsubset_group\n\n\nIf person/legislative data was included in the id_make function, then you can subset by any value in the $group column of that data if use_subset is TRUE.\n\n\n\n\nsubset_person\n\n\nA list of character values of names of persons/legislators to use to subset if use_subset is TRUE and person/legislative data was included in the id_make function with the required $person.names column\n\n\n\n\nsample_size\n\n\nIf sample_it is TRUE, this value reflects how many legislators/persons will be sampled from the response matrix\n\n\n\n\nnchains\n\n\nThe number of chains to use in Stan’s sampler. Minimum is one. See stan for more info. If use_vb=TRUE, this parameter will determine the number of Pathfinder paths to estimate.\n\n\n\n\nniters\n\n\nThe number of iterations to run Stan’s sampler. Shouldn’t be set much lower than 500. See stan for more info.\n\n\n\n\nuse_vb\n\n\nWhether or not to use Stan’s Pathfinder algorithm instead of full Bayesian inference. Pros: it’s much faster but can be much less accurate. Note that Pathfinder is also used by default for finding initial starting values for sfull HMC sampling.\n\n\n\n\nignore_db\n\n\nIf there are multiple time periods (particularly when there are very many time periods), you can pass in a data frame (or tibble) with one row per person per time period and an indicator column ignore that is equal to 1 for periods that should be considered in sample and 0 for periods for periods that should be considered out of sample. This is useful for excluding time periods from estimation for persons when they could not be present, i.e. such as before entrance into an organization or following death. If ignore equals 0, the person’s ideal point is estimated as a standard Normal draw rather than an auto-correlated parameter, reducing computational burden substantially. Note that there can only be one pre-sample period of 0s, one in-sample period of 1s, and one post-sample period of 0s. Multiple in-sample periods cannot be interspersed with out of sample periods. The columns must be labeled as person_id, time_id and ignore and must match the formatting of the columns fed to the id_make function.\n\n\n\n\nrestrict_ind_high\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a high value (default +1).\n\n\n\n\nfix_high\n\n\nA vector of length restrict_ind_high with values that the high fixed person ideal point(s) should be fixed to. Default is +1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nfix_low\n\n\nA vector of length restrict_ind_low with values that the high fixed person ideal point(s) should be fixed to. Default is -1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nrestrict_ind_low\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a low value (default -1).\n\n\n\n\nnum_restrict_high\n\n\nIf using variational inference for identification (fixtype=“vb_full”), how many parameters to constraint to positive values? Default is 1.\n\n\n\n\nnum_restrict_low\n\n\nIf using variational inference for identification (ixtype=“vb_full”), how many parameters to constraint to positive negative values? Default is 1.\n\n\n\n\nfixtype\n\n\nSets the particular kind of identification used on the model, could be either ‘vb_full’ (identification provided exclusively by running a variational identification model with no prior info), or ‘prefix’ (two indices of ideal points or items to fix are provided to options restrict_ind_high and restrict_ind_low). See details for more information.\n\n\n\n\nconst_type\n\n\nWhether “persons” are the parameters to be fixed for identification (the default) or “items”. Each of these pinned parameters should be specified to fix_high and fix_low if fixtype equals “prefix”, otherwise the model will select the parameters to pin to fixed values.\n\n\n\n\nid_refresh\n\n\nThe number of times to report iterations from the variational run used to identify models. Default is 0 (nothing output to console).\n\n\n\n\nprior_only\n\n\nWhether to only sample from priors as opposed to the full model with likelihood (the default). Useful for doing posterior predictive checks.\n\n\n\n\nwarmup\n\n\nThe number of iterations to use to calibrate Stan’s sampler on a given model. Shouldn’t be less than 100. See stan for more info.\n\n\n\n\nncores\n\n\nThe number of cores in your computer to use for parallel processing in the Stan engine. See stan for more info. If within_chain is set to “threads”, this parameter will determine the number of threads (independent processes) used for within-chain parallelization.\n\n\n\n\nuse_groups\n\n\nIf TRUE, group parameters from the person/legis data given in id_make will be estimated instead of individual parameters.\n\n\n\n\ndiscrim_reg_upb\n\n\nUpper bound of the rescaled Beta distribution for observed discrimination parameters (default is +1)\n\n\n\n\ndiscrim_reg_lb\n\n\nLower bound of the rescaled Beta distribution for observed discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_miss_upb\n\n\nUpper bound of the rescaled Beta distribution for missing discrimination parameters (default is +1)\n\n\n\n\ndiscrim_miss_lb\n\n\nLower bound of the rescaled Beta distribution for missing discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_reg_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_reg_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_miss_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ndiscrim_miss_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\nperson_sd\n\n\nThe standard deviation of the Normal distribution prior for persons (all non-constrained person ideal point parameters). Default is weakly informative (3) on the logit scale.\n\n\n\n\ntime_fix_sd\n\n\nThe variance of the over-time component of the first person/legislator is fixed to this value as a reference. Default is 0.1.\n\n\n\n\ntime_var\n\n\nThe mean of the exponential distribution for over-time variances for ideal point parameters. Default (10) is weakly informative on the logit scale.\n\n\n\n\nspline_knots\n\n\nNumber of knots (essentially, number of points at which to calculate time-varying ideal points given T time points). Default is NULL, which means that the spline is equivalent to polynomial time trend of degree spline_degree. Note that the spline number (if not null) must be equal or less than the number of time points–and there is no reason to have it equal to the number of time points as that will likely over-fit the data.\n\n\n\n\nspline_degree\n\n\nThe degree of the spline polynomial. The default is 2 which is a quadratic polynomial. A value of 1 will result in independent knots (essentially pooled across time points T). A higher value will result in wigglier time series. There is no \"correct\" value but lower values are likely more stable and easier to identify.\n\n\n\n\nar1_up\n\n\nThe upper bound of the AR(1) parameter, default is +1.\n\n\n\n\nar1_down\n\n\nThe lower bound of the AR(1) parameter, default is 0. Set to -1 to allow for inverse responses to time shocks.\n\n\n\n\nboundary_prior\n\n\nIf your time series has very low variance (change over time), you may want to use this option to put a boundary-avoiding inverse gamma prior on the time series variance parameters if your model has a lot of divergent transitions. To do so, pass a list with a element called beta that signifies the rate parameter of the inverse-gamma distribution. For example, try boundary_prior=list(beta=1). Increasing the value of beta will increase the \"push\" away from zero. Setting it too high will result in time series that exhibit a lot of \"wiggle\" without much need.\n\n\n\n\ntime_center_cutoff\n\n\nThe number of time points above which the model will employ a centered time series approach for AR(1) and random walk models. Below this number the model will employ a non-centered approach. The default is 50 time points, which is relatively arbitrary and higher values may be better if sampling quality is poor above the threshold.\n\n\n\n\nrestrict_var\n\n\nWhether to fix the variance parameter for the first person trajectory. Default is FALSE (usually not necessary).\n\n\n\n\nsample_stationary\n\n\nIf TRUE, the AR(1) coefficients in a time-varying model will be sampled from an unconstrained space and then mapped back to a stationary space. Leaving this TRUE is slower but will work better when there is limited information to identify a model. If used, the ar_sd parameter should be increased to 5 to allow for wider sampling in the unconstrained space.\n\n\n\n\nar_sd\n\n\nIf an AR(1) model is used, this defines the prior scale of the Normal distribution. A lower number can help identify the model when there are few time points.\n\n\n\n\ndiff_reg_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the non-inflated model.\n\n\n\n\ndiff_miss_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the inflated model.\n\n\n\n\nrestrict_sd_high\n\n\nSet the level of tightness for high fixed parameters (top/positive end of scale). If NULL, the default, will set to .1 if const_type=“persons” and 10 if const_type=“items”. For const_type=“persons”, value is the SD of normal distribution centered around fix_high. For const_type=“items”, parameter is equal to the prior shape for high pinned parameters (divide by restrict_N_high + restrict_sd_high) to get expected value.\n\n\n\n\nrestrict_sd_low\n\n\nSet the level of tightness for low fixed parameters (low/negative end of scale). If NULL, the default, will set to .1 if const_type=“persons” and 10 if const_type=“items”. For const_type=“persons”, value is the SD of normal distribution centered around fix_low. For const_type=“items”, parameter is equal to the prior shape for high pinned parameters (divide by restrict_N_low + restrict_sd_low) to get expected value.\n\n\n\n\nrestrict_N_high\n\n\nSet the prior scale for high/positive pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nrestrict_N_low\n\n\nSet the prior shape for low/negative pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nordbeta_phi_mean\n\n\nThe mean of the prior for phi, the dispersion parameter in the ordered beta distribution. Value of this parameter (default is 1) is given as the mean of the exponential distribution for prior values of phi.\n\n\n\n\nordbeta_cut_alpha\n\n\nA length 2 vector of positive continuous values for alpha in the induced dirichlet distribution. This distribution is used for the cutpoints of the ordered beta distribution. Default is c(1,1), which is uninformative.\n\n\n\n\nordbeta_cut_phi\n\n\nA value for the phi paremeter of the induced dirichlet distribution used for ordered beta cutpoint priors. Default is 0, which is weakly informative.\n\n\n\n\ngp_sd_par\n\n\nThe upper limit on allowed residual variation of the Gaussian process prior. Increasing the limit will permit the GP to more closely follow the time points, resulting in much sharper bends in the function and potentially oscillation.\n\n\n\n\ngp_num_diff\n\n\nThe number of time points to use to calculate the length-scale prior that determines the level of smoothness of the GP time process. Increasing this value will result in greater smoothness/autocorrelation over time by selecting a greater number of time points over which to calculate the length-scale prior.\n\n\n\n\ngp_m_sd_par\n\n\nThe upper limit of the marginal standard deviation of the GP time process. Decreasing this value will result in smoother fits.\n\n\n\n\ngp_min_length\n\n\nThe minimum value of the GP length-scale parameter. This is a hard lower limit. Increasing this value will force a smoother GP fit. It should always be less than gp_num_diff.\n\n\n\n\ncmdstan_path_user\n\n\nDefault is NULL, and so will default to whatever is set in cmdstanr package. Specify a file path here to use a different cmdtstan installation.\n\n\n\n\nmap_over_id\n\n\nThis parameter identifies which ID variable to use to construct the shards for within-chain parallelization. It defaults to “persons” but can also take a value of “items”. It is recommended to select whichever variable has more distinct values to improve parallelization.\n\n\n\n\nsave_files\n\n\nThe location to save CSV files with MCMC draws from cmdstanr. The default is NULL, which will use a folder in the package directory.\n\n\n\n\ncompile_optim\n\n\nWhether to use Stan compile optimization flags (off by default)\n\n\n\n\ndebug\n\n\nFor debugging purposes, turns off threading to enable more informative error messages from Stan. Also recompiles model objects.\n\n\n\n\ninit_pathfinder\n\n\nWhether to generate initial values from the Pathfinder algorithm (see Stan documentation). If FALSE, will generate random start values..\n\n\n\n\ndebug_mode\n\n\nWhether to print valuesof all parameters for debugging purposes. If this is used, only one iteration should be used as it generates a lot of console output.\n\n\n\n\n…\n\n\nAdditional parameters passed on to Stan’s sampling engine. See stan for more information.\n\n\n\n\n\n\nTo run an IRT ideal point model, you must first pre-process your data using the id_make function. Be sure to specify the correct options for the kind of model you are going to run: if you want to run an unbounded outcome (i.e. Poisson or continuous), the data needs to be processed differently. Also any hierarchical covariates at the person or item level need to be specified in id_make. If they are specified in id_make, than all subsequent models fit by this function will have these covariates.\nNote that for static ideal point models, the covariates are only defined for those persons who are not being used as constraints.\nAs of this version of idealstan, the following model types are available. Simply pass the number of the model in the list to the model_type option to fit the model.\n\n\nIRT 2-PL (binary response) ideal point model, no missing-data inflation\n\n\nIRT 2-PL ideal point model (binary response) with missing- inflation\n\n\nOrdinal IRT (rating scale) ideal point model no missing-data inflation\n\n\nOrdinal IRT (rating scale) ideal point model with missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model no missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model with missing-data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with no missing data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with missing-data inflation\n\n\nunbounded (Gaussian) IRT ideal point model with no missing data\n\n\nunbounded (Gaussian) IRT ideal point model with missing-data inflation\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with no missing data\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with missing-data inflation\n\n\nLatent Space (binary response) ideal point model with no missing data\n\n\nLatent Space (binary response) ideal point model with missing-data inflation\n\n\nOrdered Beta (proportion/percentage) with no missing data\n\n\nOrdered Beta (proportion/percentage) with missing-data inflation\n\n\n\n\n\nA fitted idealstan object that contains posterior samples of all parameters either via full Bayesian inference or a variational approximation if use_vb is set to TRUE. This object can then be passed to the plotting functions for further analysis.\n\n\n\nIn addition, each of these models can have time-varying ideal point (person) parameters if a column of dates is fed to the id_make function. If the option vary_ideal_pts is set to ‘random_walk’, id_estimate will estimate a random-walk ideal point model where ideal points move in a random direction. If vary_ideal_pts is set to ‘AR1’, a stationary ideal point model is estimated where ideal points fluctuate around long-term mean. If vary_ideal_pts is set to ‘GP’, then a semi-parametric Gaussian process time-series prior will be put around the ideal points. If vary_ideal_pts is set to ‘splines’, then the ideal point trajectories will be a basis spline defined by the parameters spline_knots and spline_degree. Please see the package vignette and associated paper for more detail about these time-varying models.\n\n\n\nThe inflation model used to account for missing data assumes that missingness is a function of the persons’ (legislators’) ideal points. In other words,the model will take into account if people with high or low ideal points tend to have more/less missing data on a specific item/bill. Missing data should be coded as NA when it is passed to the id_make function. If there isn’t any relationship between missing data and ideal points, then the model assumes that the missingness is ignorable conditional on each item, but it will still adjust the results to reflect these ignorable (random) missing values. The inflation is designed to be general enough to handle a wide array of potential situations where strategic social choices make missing data important to take into account.\nTo leave missing data out of the model, simply choose a version of the model in the list above that is non-inflated.\nModels can be either fit on the person/legislator IDs or on group-level IDs (as specified to the id_make function). If group-level parameters should be fit, set use_groups to TRUE.\n\n\n\nCovariates are included in the model if they were specified as options to the id_make function. The covariate plots can be accessed with id_plot_cov on a fitted idealstan model object.\n\n\n\nIdentifying IRT models is challenging, and ideal point models are still more challenging because the discrimination parameters are not constrained. As a result, more care must be taken to obtain estimates that are the same regardless of starting values. The parameter fixtype enables you to change the type of identification used. The default, ‘vb_full’, does not require any further information from you in order for the model to be fit. In this version of identification, an unidentified model is run using variational Bayesian inference (see vb). The function will then select two persons/legislators or items/bills that end up on either end of the ideal point spectrum, and pin their ideal points to those specific values. To control whether persons/legislator or items/bills are constrained, the const_type can be set to either “persons” or “items” respectively. In many situations, it is prudent to select those persons or items ahead of time to pin to specific values. This allows the analyst to be more specific about what type of latent dimension is to be estimated. To do so, the fixtype option should be set to “prefix”. The values of the persons/items to be pinned can be passed as character values to restrict_ind_high and restrict_ind_low to pin the high/low ends of the latent scale respectively. Note that these should be the actual data values passed to the id_make function. If you don’t pass any values, you will see a prompt asking you to select certain values of persons/items.\nThe pinned values for persons/items are set by default to +1/-1, though this can be changed using the fix_high and fix_low options. This pinned range is sufficient to identify all of the models implemented in idealstan, though fiddling with some parameters may be necessary in difficult cases. For time-series models, one of the person ideal point over-time variances is also fixed to .1, a value that can be changed using the option time_fix_sd.\n\n\n\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\nKubinec, R. \"Generalized Ideal Point Models for Time-Varying and Missing-Data Inference\". Working Paper.\n\n\nBetancourt, Michael. \"Robust Gaussian Processes in Stan\". (October 2017). Case Study.\n\n\n\n\n\nid_make for pre-processing data, id_plot_legis for plotting results, summary for obtaining posterior quantiles, id_post_pred for producing predictive replications.\n\n\n\n\nlibrary(idealstan)\n\n# First we can simulate data for an IRT 2-PL model that is inflated for missing data\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# This code will take at least a few minutes to run \nbin_irt_2pl_abs_sim &lt;- id_sim_gen(model_type='binary',inflate=T)\n\n# Now we can put that directly into the id_estimate function \n# to get full Bayesian posterior estimates\n# We will constrain discrimination parameters \n# for identification purposes based on the true simulated values\n\nbin_irt_2pl_abs_est &lt;- id_estimate(bin_irt_2pl_abs_sim,\n                       model_type=2,\n                       restrict_ind_high = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=TRUE,\n                       index=TRUE)$ix[1],\n                       restrict_ind_low = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=FALSE,\n                       index=TRUE)$ix[1],\n                       fixtype='prefix',\n                       ncores=2,\n                       nchains=2)\n                                   \n# We can now see how well the model recovered the true parameters\n\nid_sim_coverage(bin_irt_2pl_abs_est) %&gt;% \n         bind_rows(.id='Parameter') %&gt;% \n         ggplot(aes(y=avg,x=Parameter)) +\n           stat_summary(fun.args=list(mult=1.96)) + \n           theme_minimal()\n \n\n# In most cases, we will use pre-existing data \n# and we will need to use the id_make function first\n# We will use the full rollcall voting data \n# from the 114th Senate as a rollcall object\n\ndata('senate114')\n\n# Running this model will take at least a few minutes, even with \n# variational inference (use_vb=T) turned on\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(to_idealstan,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='prefix',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_estimate"
    ]
  },
  {
    "objectID": "man/id_plot_legis.html",
    "href": "man/id_plot_legis.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items.\n\n\n\nid_plot_legis(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  item_plot = NULL,\n  item_plot_type = \"non-inflated\",\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.2,\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = NULL,\n  sample_persons = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects to compare across models\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\nitem_plot\n\n\nThe IDs (character vector) of the bill/item midpoints to overlay on the plot\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Default is NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model. It will plot them as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options). In addition, if item/bill IDs as a character vector is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\nTo compare across multiple idealstan models, pass a named list list(model1=model1,model2=model2,etc) to the object option. Note that these comparisons will done by individual persons/groups, so if there are a lot of persons/groups, consider using the include option to only compare a specific set of persons/groups.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis"
    ]
  },
  {
    "objectID": "man/id_plot_legis.html#plot-legislatorperson-and-billitem-ideal-points",
    "href": "man/id_plot_legis.html#plot-legislatorperson-and-billitem-ideal-points",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items.\n\n\n\nid_plot_legis(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  item_plot = NULL,\n  item_plot_type = \"non-inflated\",\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.2,\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = NULL,\n  sample_persons = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects to compare across models\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\nitem_plot\n\n\nThe IDs (character vector) of the bill/item midpoints to overlay on the plot\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Default is NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model. It will plot them as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options). In addition, if item/bill IDs as a character vector is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\nTo compare across multiple idealstan models, pass a named list list(model1=model1,model2=model2,etc) to the object option. Note that these comparisons will done by individual persons/groups, so if there are a lot of persons/groups, consider using the include option to only compare a specific set of persons/groups.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis"
    ]
  },
  {
    "objectID": "man/id_plot_legis_dyn.html",
    "href": "man/id_plot_legis_dyn.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items when the legislator/person ideal points are allowed to vary over time.\n\n\n\nid_plot_legis_dyn(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  item_plot = NULL,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  line_size = 1,\n  highlight = NULL,\n  plot_text = TRUE,\n  use_ci = TRUE,\n  plot_lines = 0,\n  draw_line_alpha = 0.5,\n  person_line_alpha = 0.3,\n  person_ci_alpha = 0.8,\n  item_plot_type = \"non-inflated\",\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  plot_sim = FALSE,\n  use_chain = NULL,\n  add_cov = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects if the plot is supposed to show a comparison of different fitted idealstan models (see Time Series vignette)\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nitem_plot\n\n\nThe value of the item/bill for which to plot its midpoint (character value)\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 showing the upper limit to compute the posterior uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 showing the lower limit to compute the posterior uncertainty interval (defaults to 0.05).\n\n\n\n\nline_size\n\n\nSets the size of the line of the time-varying ideal points.\n\n\n\n\nhighlight\n\n\nA character referring to one of the persons in person_labels that the plot can highlight relative to other persons\n\n\n\n\nplot_text\n\n\nIf TRUE, will plot person_labels over the lines.\n\n\n\n\nuse_ci\n\n\nWhether or not high-posterior density intervals (credible intervals) should be plotted over the estimates (turn off if the plot is too busy)\n\n\n\n\nplot_lines\n\n\nThe number of lines of actual draws of time-varying ideal points to draw on the plot. Note that these are grouped by persons. Specific draws selected at random from total number of draws of the estimation. Default is 0.\n\n\n\n\ndraw_line_alpha\n\n\nThe opacity of lines plotted over the distribution (should be between 0 and 1, default is 0.5).\n\n\n\n\nperson_line_alpha\n\n\nThe transparency level of the time-varying ideal point line\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of ribbon confidence interval around the time-varying ideal points\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, use the groups instead of individuals to plot colours\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\nplot_sim\n\n\nWhether to plot the true values of parameters if a simulation was used to generate data (see id_sim_gen)\n\n\n\n\nuse_chain\n\n\nID of MCMC chain to use rather than combining all chains. Default is NULL which will use all chains and is recommended.\n\n\n\n\nadd_cov\n\n\nWhether to add values of hierarchical person-level covariates to the time trends (defaults to TRUE).\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model, and also traces the path of these ideal points over time. It will plot them as a vertical line with associated high-density posterior interval (10% to 90%). In addition, if the column index for a bill/item from the response matrix is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nvary_ideal_pts='random_walk',\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis_dyn(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis_dyn"
    ]
  },
  {
    "objectID": "man/id_plot_legis_dyn.html#function-to-plot-dynamic-ideal-point-models",
    "href": "man/id_plot_legis_dyn.html#function-to-plot-dynamic-ideal-point-models",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items when the legislator/person ideal points are allowed to vary over time.\n\n\n\nid_plot_legis_dyn(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  item_plot = NULL,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  line_size = 1,\n  highlight = NULL,\n  plot_text = TRUE,\n  use_ci = TRUE,\n  plot_lines = 0,\n  draw_line_alpha = 0.5,\n  person_line_alpha = 0.3,\n  person_ci_alpha = 0.8,\n  item_plot_type = \"non-inflated\",\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  plot_sim = FALSE,\n  use_chain = NULL,\n  add_cov = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects if the plot is supposed to show a comparison of different fitted idealstan models (see Time Series vignette)\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nitem_plot\n\n\nThe value of the item/bill for which to plot its midpoint (character value)\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 showing the upper limit to compute the posterior uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 showing the lower limit to compute the posterior uncertainty interval (defaults to 0.05).\n\n\n\n\nline_size\n\n\nSets the size of the line of the time-varying ideal points.\n\n\n\n\nhighlight\n\n\nA character referring to one of the persons in person_labels that the plot can highlight relative to other persons\n\n\n\n\nplot_text\n\n\nIf TRUE, will plot person_labels over the lines.\n\n\n\n\nuse_ci\n\n\nWhether or not high-posterior density intervals (credible intervals) should be plotted over the estimates (turn off if the plot is too busy)\n\n\n\n\nplot_lines\n\n\nThe number of lines of actual draws of time-varying ideal points to draw on the plot. Note that these are grouped by persons. Specific draws selected at random from total number of draws of the estimation. Default is 0.\n\n\n\n\ndraw_line_alpha\n\n\nThe opacity of lines plotted over the distribution (should be between 0 and 1, default is 0.5).\n\n\n\n\nperson_line_alpha\n\n\nThe transparency level of the time-varying ideal point line\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of ribbon confidence interval around the time-varying ideal points\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, use the groups instead of individuals to plot colours\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\nplot_sim\n\n\nWhether to plot the true values of parameters if a simulation was used to generate data (see id_sim_gen)\n\n\n\n\nuse_chain\n\n\nID of MCMC chain to use rather than combining all chains. Default is NULL which will use all chains and is recommended.\n\n\n\n\nadd_cov\n\n\nWhether to add values of hierarchical person-level covariates to the time trends (defaults to TRUE).\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model, and also traces the path of these ideal points over time. It will plot them as a vertical line with associated high-density posterior interval (10% to 90%). In addition, if the column index for a bill/item from the response matrix is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nvary_ideal_pts='random_walk',\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis_dyn(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis_dyn"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html",
    "href": "vignettes/Time_Series.html",
    "title": "Time-Varying Ideal Points",
    "section": "",
    "text": "Note: To report bugs with the package, please file an issue on the Github page.\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Robust Measurement with Dirty Data in the Social Sciences.”\nThis package implements to kinds of time-varying ideal point models. Because these time-varying models are independent of the specific outcome used, time-varying ideal point models can be fit with any outcome/response supported by the package, including binary, ordinal, counts, continuous and positive-continuous data, in addition to the latent space model for binary data. This vignette demonstrates the use of the two time-varying ideal point models and how to decide between them with example data drawn from Delaware’s state legislature.\ndata('delaware')\nknitr::kable(slice(delaware,1:10))\n\n\n\n\noutcome\nitem_id\nperson_id\ngroup_id\ntime_id\n\n\n\n\nNA\n1\nAtkins, John 1\nR\n1995-01-01\n\n\nNA\n1\nAtkins, John 2\nD\n1995-01-01\n\n\nYes\n1\nBanning 3\nD\n1995-01-01\n\n\nNA\n1\nBarbieri, Michael A. 4\nD\n1995-01-01\n\n\nNA\n1\nBaumbach, Paul S. 5\nD\n1995-01-01\n\n\nNA\n1\nBennett, Andria 6\nD\n1995-01-01\n\n\nNA\n1\nBennett, E. 7\nD\n1995-01-01\n\n\nNA\n1\nBentz, David 8\nD\n1995-01-01\n\n\nNA\n1\nBlakey, Donald 9\nR\n1995-01-01\n\n\nNA\n1\nBolden, Stephanie 10\nD\n1995-01-01\nThe process to create a time-varying ideal point model is no different than that for creating a static model, except that a column should exist in the data with dates, preferably in date or date-time format. If you have a character vector of dates that you need to convert to R’s date format, check out the excellent lubridate package.\nThere are four time-varying models included in idealstan package, each of which makes different assumptions about how ideal points change over time. It is important to note that none of these models is superior to the other. Ideal points do not have any natural time process as they are a latent, unobserved construct, so the question is more about which time process is most relevant to the social or physical process being studied. The models can be differentiated by whether they permit general description of time series versus inference on specific aspects, and also in terms of complexity.\nThe first kind of model included in idealstan is known as a random-walk process (also known as non-stationary time-series, Brownian motion and I(1)). This simple model of time implies that the location of an ideal point in the current time point is equal to the position of the ideal point in the prior time point plus some random noise. A helpful analogy is to imagine a frog hopping around a room. It could head in virtually any direction.\nThe advantage of the random-walk model is that it allows ideal points to move in any direction. The downside is that it can assume too much change in the ideal point process. It also does not provide a great deal of information about the time series other than the variance parameter of the time series that indicate the average rate of change over time (i.e., how bouncy the time series is). Furthermore, random-walk models change significantly when other covariates are included in the model, as an additional covariate that has a constant effect over time will push the time-series in a single direction, making it less than ideal for testing the effect of time-varying covariates.\nDespite these limitations, this model is still useful, especially in two situations. First, when little is known about the time process/social situation, this model makes the most minimal assumptions about how ideal points change. Second, when the time series is of a relatively long time period, then the time series is likely to have some kind of random-walk nature, especially if there is no natural limit. For example, when looking at legislature voting data, ideal points may follow a random-walk pattern when looking at a legislator’s entire career over decades. In general, a random walk provides a good descriptive inference of where the ideal points are moving; it just won’t tell you a lot about why.\nThe second model included in idealstan is a stationary time series model (also called an AR(1) or first-order autoregressive time series). A stationary time-series is so called because it must return over time to a long-term average or mean. Change over time is conceived of as shocks that push the time series away from its long-term average. The AR(1) model includes additional parameters that measure how fast a time-series will return to its long-term average. A good empirical example for this model is economic growth over time. There are periods when “growth shocks” occur, such as recessions and boom times. Overall, though, economic growth for a specific country will tend towards some long-term average rate of growth. Economic growth can’t simply move off in any direction, especially in an upward direction, as that would over-heat the economy and result in massive inflation.\nThe third model is known as a Gaussian process. Fully explaining how Gaussian processes work is beyond the scope of this vignette, but I refer readers to this case study as a very helpful introduction. A Gaussian process is similar to a random walk in that it can in principle move in any direction. Unlike a random walk, the prior position of the time series doesn’t necessarily constrain the position of the time series in the present position. Rather, a Gaussian process is a generalized smoother: it will find a smooth path between the points, but can take any shape in principle.\nOne major advantage of the Gaussian process is that it is a so-called continuous time series model. In practice this means that the time series does not have to be sequential. For example, if legislators only vote at irregular intervals, and the fact that some bills are separated than more time than others is important, then a Gaussian process will take into account the actual length of time between each vote. Random walks and stationary models, on the other hand, consider each time point to be sequential to the previous time point, effectively ignoring any big gaps.\nThe main disadvantage of the Gaussian process is that the power and flexbility require a lot more data. It is not a useful model unless you have considerable numbers of bills/items. The model can handle additional time-varying covariates although their meaning is not as precise as the stationary model.\nThe stationary model, by contrast, assumes that ideal points have a single long-term average. The ideal points may receive “shocks” that force them away from the long-term mean, but they will inevitably return. While this is a more specific set of assumptions than the random walk or Gaussian process, stationary models have the significant advantage of allowing us to fit covariates that have a more meaningful interpretation: the estimates of covariates represent shocks to the ideal points away from their long-term average.\nA simpler kind of time series model is also available in idealstan known as splines. Splines are combinations of polynomial functions; the more combinations, the more flexible splines become. idealstan includes splines primarily because it is easy to estimate relatively simple time series functions that are useful when there is only a limited amount of data per time point and when the latent trait is unlikely change very quickly. In these cases, a spline can help estimate a latent trait that varies over time but only within certain bounds defined by the complexity of the polynomial function.\nTo show what these models look like, we will fit each model to the delaware data in turn. We use the use_vb option to produce variational estimates of the true posterior; these approximations are much faster to fit than the full model but usually have some distortions. For finished analysis we would want to use the full sampler (use_vb=FALSE), unless we have so much data that processing time for the full model is infeasible.\nThe models will be fit with parallel processing over the persons in the model (i.e. more ncores than nchains specified in id_estimate). Parallel processing is only possible for persons as time series model introduce dependence between time points. As such do not change the map_over_id option for dynamic models or you will get incorrect results.",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#random-walk-model",
    "href": "vignettes/Time_Series.html#random-walk-model",
    "title": "Time-Varying Ideal Points",
    "section": "Random-Walk Model",
    "text": "Random-Walk Model\nTo fit the random walk model, we first create data in which we pass the name of the column of dates for each bill/item to the time_id option of id_make. One important thing to note about this model is that we code missing values as 'Absent', but we leave NA values in the outcome. These NA values will be dropped before running the model. They represent periods of time when legislators were not in office, and hence it is reasonable to exclude these periods of time from analysis.\n\n# Absent to missing\n\ndelaware$outcome[delaware$outcome==\"Absent\"] &lt;- NA\n\n# adjust data to 0/1\n\ndelaware$outcome &lt;- as.numeric(delaware$outcome==\"Yes\")\n\ndelaware_data &lt;- id_make(delaware,outcome_disc = 'outcome',\n                       person_id = 'person_id',\n                       item_id = 'item_id',\n                       group_id= 'group_id',\n                       time_id='time_id')\n\nWe then pass this object to the id_estimate function and specify 'random_walk' in the vary_ideal_pts option. We also use model_type=2 to select a binary model (yes/no votes) that adjust for the missing data (legislator absences). We pass the names of two rollcall votes to restrict their item discrimination parameters for identification (i.e. we constrain one vote with all Republicans voting for to be positive and one vote with all Democrats voting for to be negative). To do so, we need to set the const_type argument to \"items\" and pass the name of bills to the restrict_ind_high and restrict_ind_low options. Using bills (or whatever indicators are in the data) that have a clear split in the votes between parties will help achieve identification, as well as using bills that are far apart in time.\nOne problem with time-varying models is that they introduce additional identification issues with the ideal point scores. Theoretically, if over-time variance is high enough, ideal point scores can oscillate from positive to negative. In these cases, you can add additional items to constrain via the restrict_ind_high and restrict_ind_low options or use a simpler time-series model like a spline with few degrees.\n\n# parallel processing over persons/legislators specified with\n# ncores = 16 and nchains = 2\n# this will equal 8 cores per chain.\n# of course your machine must have 16 cores for \n# that number to be useful\n\ndel_est &lt;- id_estimate(delaware_data,\n                model_type = 1,\n                fixtype='prefix',const_type=\"items\",\n                nchains = 2,use_vb = T,\n                ncores = 8,\n                vary_ideal_pts='random_walk',\n                 restrict_ind_high = 305,\n                 restrict_ind_low=  276,\n            seed=84520,\n            id_refresh=0)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  7.5 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (41) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  8.7 seconds.\n\n\nIt is important to note that the warnings about importance resampling and the approximation do matter and a run with the Hamiltonian Markov Chain sampler should be used before final inferences by setting use_vb=TRUE. The approximation is only useful for exploratory model development.\nGiven the fitted model, we can now plot the ideal points. We will turn off the option for showing the uncertainty interval as there are a lot of lines, one for each legislator:\n\nid_plot_legis_dyn(del_est,use_ci = T) +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'),\n                     name=\"Party\") +\n  ggtitle(\"Yearly Ideal Point Scores for Delaware Legislature\")\n\n\n\n\n\n\n\n\nThis plot does now show very much that is particularly interesting. Most of the ideal points are not changing over time, although it is important to note that polarization is increasing over time–both within parties and between parties as some legislators move to the extremes.\n\nWe can also look at the variance of the ideal points to see which of the legislators had the highest variance in their ideal points:\n\nid_plot_legis_var(del_est) + ggtitle('Variances of Time-Varying Ideal Points in Delaware State Legislature',subtitle='Higher Variances Indicate Less Stable Ideal Points') +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'))\n\n\n\n\n\n\n\n\nWe can access the actual estimates of the variances by passing the return_data=TRUE option to the plot function:\n\nout_d &lt;- id_plot_legis_var(del_est,return_data = T)\nknitr::kable(head(out_d$plot_data))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlegis\nlow_pt\nhigh_pt\nmedian_pt\nid_num\nperson_id\ngroup_id\n\n\n\n\ntime_var_free[100]\n0.6745350\n0.6745350\n0.6745350\n100\nPettyjohn, Brian Guy 137\nR\n\n\ntime_var_free[101]\n0.0536705\n0.0536705\n0.0536705\n101\nPlant, Al Sr. 76\nD\n\n\ntime_var_free[102]\n0.2083990\n0.2083990\n0.2083990\n102\nPlant, Hazel 77\nD\n\n\ntime_var_free[103]\n0.1720390\n0.1720390\n0.1720390\n103\nPoore, Nicole 138\nD\n\n\ntime_var_free[104]\n0.3825970\n0.3825970\n0.3825970\n104\nPostles, Charles S. 78\nR\n\n\ntime_var_free[105]\n0.3129320\n0.3129320\n0.3129320\n105\nPotter, Charles Jr. 79\nD",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#spline-model",
    "href": "vignettes/Time_Series.html#spline-model",
    "title": "Time-Varying Ideal Points",
    "section": "Spline Model",
    "text": "Spline Model\nWe now fit a form of splines for the legislator trajectories by passing 'splines' to vary_ideal_pts. This model has two main control parameters - spline_degree and spline_knots. The first is equal to the number of polynomial coefficients or “bends” in the time series – for a value of 2 the model is quadratic, with 3 it is a sigmoid (three bends), with 4 there is an additional possible bend in the time series, and so on. We will fit a restrictive time-varying model with 0 knots (equivalent to a single polynomial function) and only 2 degrees for the polynomial function:\n\ndel_est_spline &lt;- id_estimate(delaware_data,\n                model_type = 1,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,\n                ncores=8,spline_knots = NULL,spline_degree = 2,\n                vary_ideal_pts='splines',use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  5.8 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (31) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  7.3 seconds.\n\nid_plot_legis_dyn(del_est_spline,use_ci = F) +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'))\n\n\n\n\n\n\n\n\nThese ideal points are similar to the random walk estimates and show the limited variation possible in a 2-degree polynomial function (essentially a quadratic function). For one session, this model would appear adequate at capturing monthly changes in legislator trajectories.\nFinally, we can also examine the individual ideal points by each time point using the summary function:\n\nsummary(del_est_spline,pars='ideal_pts') %&gt;% \n  head %&gt;% \n  knitr::kable(.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerson\nGroup\nTime_Point\nLow Posterior Interval\nPosterior Median\nHigh Posterior Interval\nParameter Name\n\n\n\n\nNA\nNA\nNA\n1.590490\n1.590490\n1.590490\nL_tp1[1,100]\n\n\nPlant, Al Sr. 76\nD\n1995-01-01\n-6.750600\n-6.750600\n-6.750600\nL_tp1[1,101]\n\n\nNA\nNA\nNA\n-5.226830\n-5.226830\n-5.226830\nL_tp1[1,102]\n\n\nNA\nNA\nNA\n-0.341960\n-0.341960\n-0.341960\nL_tp1[1,103]\n\n\nNA\nNA\nNA\n-0.133957\n-0.133957\n-0.133957\nL_tp1[1,104]\n\n\nNA\nNA\nNA\n-0.376860\n-0.376860\n-0.376860\nL_tp1[1,105]",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#group-level-time-varying-ideal-points",
    "href": "vignettes/Time_Series.html#group-level-time-varying-ideal-points",
    "title": "Time-Varying Ideal Points",
    "section": "Group-level Time-varying Ideal Points",
    "text": "Group-level Time-varying Ideal Points\nFinally, we can also change the model’s parameters to look at group-level, i.e. party-level, ideal points. To do so we need to specify the use_groups=T option in the id_estimate function, and we change the restricted parameters to parties:\n\ndel_est_rw3 &lt;- id_estimate(delaware_data,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,use_groups = T,\n                ncores=8,use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n                vary_ideal_pts='random_walk',\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  103.6 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (17) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  101.4 seconds.\n\nid_plot_legis_dyn(del_est_rw3,\n                  include=c('D','R')) + scale_colour_manual(values=c(R='red',\n                                                          D='blue',\n                                                          I='green'),\n                                                 name=\"Parties\")\n\n\n\n\n\n\n\n\nWe can also overlay a bill/item midpoint to see where the line of indifference in voting is relative to party positions. In a dynamic ideal point model, the bill/item midpoint will be a straight line as the bill-item midpoint was only voted on in one time point, and hence has only one parameter:\n\nid_plot_legis_dyn(del_est_rw3,item_plot='342',\n                  text_size_label = 5,\n                  include=c('D','R')) + scale_colour_manual(values=c(R='red',\n                                                          D='blue',\n                                                          I='green'),\n                                                 name=\"Parties\") +\n  ggtitle('Time-Varying Party-level Ideal Points for the Delaware State Legislature',\n          subtitle = 'Midpoint (Line of Indifference to Voting) for 342nd Roll-call Vote as Dotted Line') +\n  guides(color='none') +\n  annotate(geom='text',\n           x = ymd('2016-01-01'),\n           y=-1,\n           label='Confirmation Vote for Wilhelmina Wright as U.S. District Judge')\n\n\n\n\n\n\n\n\nAs this plot shows, the line of indifference is very close to the Republican party, implying that the vote split the Republican party while Democrats voted as a bloc. Empirically that is very close to the observed votes; all 27 Democrats voted to confirm the judge while 7 out of 6 Republicans did so.\nI will now estimate an additional Gaussian process model to use as comparison points to the random-walk model for parties:\n\ndel_est_gp1 &lt;- id_estimate(delaware_data,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,use_groups=T,\n                ncores=8,use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n                vary_ideal_pts='GP',\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  94.2 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (18) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  70.5 seconds.\n\n\nWe can then examine the distributions for both models as plots:\n\nid_plot_legis_dyn(del_est_rw3,include=c('D','R'))\n\n\n\n\n\n\n\nid_plot_legis_dyn(del_est_gp1,include=c('D','R'))\n\n\n\n\n\n\n\n\nThis plot shows that are substantial divergences between the different models (each plot is faceted by group_id). The GP model shows a lot more bounce over time relative to the random walk model, which is implausible given the latent trait we are trying to estimate is legislator ideology. In this case, we should prefer simpler models, such as random walks or splines, to estimate a more slowly-changing latent variable. Estimation with HMC rather than the variational approximation could also help.\nWe could also consider adjusting GP-specific parameters to force a more restrictive fit, though that type of prior adjustment depends on the particular dataset and context. These parameters are given defaults that restrict movement in the ideal points to help ensure identification. As such, they tend to be fairly conservative, but they can be made even more so when necessary. The table below shows these parameters’ values.\n\nParameters in the Gaussian Process Time-Series Model\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\ngp_sd_par\nThis parameter represents residual variation in the series that the GP does not account for. As such, its default is a very low value, as increasing it will generally increase oscillation in the series.\n\n\ngp_num_diff\nThis parameter is a multiplier that is used to set the prior for the length-scale of the GP. Loosely speaking, the length-scale determines the number of times that the time-series can cross zero, and so lowering this parameter will decrease the length-scale and subsequently increase the number of times the series can cross zero. The length-scale is given a prior equal to the difference between the maximum and minimum length of the time series in whatever units it is recorded in (days, weeks, etc) times the parameter gp_num_diff. The second numeric value of this parameter represents the standard deviation of the log-normal prior of the length scale. Increasing the standard deviation will put more weight on the data in determining the amount of flexibility in the time series.\n\n\ngp_m_sd_par\nThis parameter has two values that set the GP’s marginal standard deviation. This parameter loosely represents the amount of time-series variation in the series. The first numeric value represents the hard upper limit for this parameter to prevent the series oscillating. The second numeric value is equal to the shape of an inverse-gamma prior defined over the interval between 0 and the first numeric value (the hard upper limit). It is a weakly informative prior that pulls values away from zero to prevent divergences. Increasing the first numeric value (the upper limit) will increase marginal standard deviation, while the second numeric value can increase marginal standard deviation by decreasing its value, resulting in a flatter inverse-gamma prior.",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024 Robert Kubinec\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "Note: This is a beta release of idealstan v1.0. While most features have been implemented and are stable, there may be bugs that have not been sorted out. To report bugs with the package, please file an issue on the Github page.\nAt present, idealstan is only available on Github as one of its main dependencies, cmdstanr is also not on CRAN. To use the package, cmdstanr must be first be set up with a local installation of cmdstan, which is used for estimation. To see how to install cmdstanr, see this guide. Note that the cmdstanr default installation location should be used when installing cmdstan.\nTo install this package, type the command remotes::install_github('saudiwin/idealstan') at the R console prompt (you first must have the remotes package installed from CRAN for this to work). The best way to learn how the package works is to look at the package vignettes, which can be accessed from the package website, especially Introduction to Idealstan.\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Robust Measurement with Dirty Data in the Social Sciences”. SocArchiv (2024). doi:10.31219/osf.io/8j2bt.\nThe paper is available from this link.\n\n\nThis package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics. Compared to traditional IRT, ideal point models use a similar parameterization (the 2-Pl variant) but without the strong assumption that all items load in the same direction (i.e., higher ability). For more information, I refer you to my paper about IRT and ideal point models, documenting many of the features in the package.\nThe goal of idealstan is to offer both standard IRT/ideal point models and additional models for missing data, time-varying ideal points and diverse responses, such as binary, ordinal, count, continuous and positive-continuous outcomes. In addition, idealstan uses the Stan estimation engine to offer full Bayesian inference (with some options for approximate inference) for all models so that every model is estimated with uncertainty. Models can also have mixed outcomes, such as discrete and continuous responses.\nThe approach to handling missing data in this package is to model directly strategic censoring in observations. While this kind of missing data pattern can be found in many situations in which data is not missing at random, this particular version was developed to account for legislatures in which legislators (persons) are strategically absent for votes on bills (items). This approach to missing data can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point).\nThe package also includes ordinal ideal point models to handle situations in which a ranked outcome is polarizing, such as a legislator who can vote yes, no or to abstain. Because idealstan uses Bayesian inference, it can model any kind of ordinal data even if there aren’t an even distribution of ordinal categories for each item.\nThe package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#about-the-package",
    "href": "index.html#about-the-package",
    "title": "README",
    "section": "",
    "text": "This package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics. Compared to traditional IRT, ideal point models use a similar parameterization (the 2-Pl variant) but without the strong assumption that all items load in the same direction (i.e., higher ability). For more information, I refer you to my paper about IRT and ideal point models, documenting many of the features in the package.\nThe goal of idealstan is to offer both standard IRT/ideal point models and additional models for missing data, time-varying ideal points and diverse responses, such as binary, ordinal, count, continuous and positive-continuous outcomes. In addition, idealstan uses the Stan estimation engine to offer full Bayesian inference (with some options for approximate inference) for all models so that every model is estimated with uncertainty. Models can also have mixed outcomes, such as discrete and continuous responses.\nThe approach to handling missing data in this package is to model directly strategic censoring in observations. While this kind of missing data pattern can be found in many situations in which data is not missing at random, this particular version was developed to account for legislatures in which legislators (persons) are strategically absent for votes on bills (items). This approach to missing data can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point).\nThe package also includes ordinal ideal point models to handle situations in which a ranked outcome is polarizing, such as a legislator who can vote yes, no or to abstain. Because idealstan uses Bayesian inference, it can model any kind of ordinal data even if there aren’t an even distribution of ordinal categories for each item.\nThe package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).",
    "crumbs": [
      "Home"
    ]
  }
]