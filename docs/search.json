[
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nIf you use idealstan, please cite:\n\n  Kubinec, Robert. 2018. Generalized Ideal Point Models for Time-Varying and\n  Missing-Data Inference. Working Paper.\n\nA BibTeX entry for LaTeX users is\n\n  @Misc{,\n    title = {Generalized Ideal Point Models for Time-Varying and Missing-Data Inference},\n    author = {Robert Kubinec},\n    note = {Working Paper},\n    year = {2018},\n  }",
    "crumbs": [
      "Citation"
    ]
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "Release v0.2.2",
    "section": "",
    "text": "#Release v0.7.2 * Updated to be compatible with most recent rstan (version 2.19.2). * Added id_plot_cov function for marginal effects plotting of covariates. * Added id_plot_irf for calculating impulse-response functions for AR(1) models covariates.\n#Release v0.7.1 * Fixed bug where time series vignette did not show on CRAN screen\n#Release v0.7.0 * Implement a Gaussian process prior for ideal points to permit semi-parametric inference * Update id_plot_legis_dyn to allow for overlay plots comparing different time series models * Strength over-time model identification using variational inference fits\n#Release v0.6.0 * Set a stricter threshold for vb to 1e-04 to promote more robust variational inference\n#Release v0.5.1 * Fixed bugs in plotting functions related to plotting two groups. * Fixed bug in AR(1) model with restricted time variance. * Updated dependencies to rstan 2.18.2. * Added error-catching in covariate creation.\n#Release v0.5.0 * New models for Poisson, ordinal-graded response, Normal and Log-normal outcomes. * Time-varying ideal point processes: random-walks and auto-regressive priors. * Time-varying plot functions for ideal points. * Hierarchical covariates for ideal points and item/bill discrimination. * Switched from matrix data input to long data frames.\n#Release v0.2.9.1 * Fixed bugs in id_extract and id_make functions.\n#Release v0.2.9 * Fixed a bug in the ideal point plot function, and also in the auto_id option in id_estimate.\n\nRelease v0.2.2\n\nFirst release on CRAN.\nFixed documentation issues from v0.2.1\nAll vignettes now building properly.",
    "crumbs": [
      "News"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html",
    "href": "vignettes/Package_Introduction.html",
    "title": "Introduction to Idealstan",
    "section": "",
    "text": "Note: To report bugs with the package, please file an issue on the Github page.\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Time-Varying and Missing-Data Inference”. Working Paper.\nNote: At present, idealstan uses the cmdstanr package, which is not on CRAN and must be installed separately. Please see below for instructions.\nThis package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics, disagreement over product design in consumer choice, or psychometric scales in which the direction that items load on the latent scale is unknown. Compared to traditional IRT, ideal point models examine the polarizing influence of a set of items on a set of persons, and has similarities to models based on Euclidean latent spaces, such as multi-dimensional scaling. In fact, this package also implements a version of the latent space model for binary outcomes, which is an alternate formulation of an ideal point model.\nThe goal of idealstan is to offer a wide variety of ideal point models that can model missing-data, time-varying ideal points, and incorporate a range of outcomes, including binary outcomes, counts, continuous and ordinal responses. In addition, idealstan uses the Stan estimation engine to offer full and variational Bayesian inference for all models so that every model is estimated with uncertainty. Variational inference provides a means to estimate Bayesian models on very large data sets when full Bayesian estimation is impractical. The package also exploits variational inference to automatically identify models instead of requiring users to pre-specify which persons or items in the data to constrain in advance.\nHowever, variational inference can fail and it is difficult to diagnose when it will do so. For that reason, the preferred approach is to use full MCMC inference with multiple computer cores per chain to permit parallel processing (explained below) when there is a need to speed up computation. Variational inference should only be used for exploratory analysis or when there are no other alternatives.\nThe approach to handling missing data in this package is to model directly strategic censoring in observations. This particular version was developed to account for legislatures in which legislators (persons) are strategically absent for votes on bills (items), but it applies to any social choice situation in which actors’ failure to respond to an item may be a function of their ideal point. This approach to missing data can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point). If missingness does not appear to arise as a function of ideal points, the models will still incorporate missing data but will assume it is essentially random.\nThe package includes the following models:\nIn addition, all of these models can be estimated with either time-varying or static ideal points if a column of dates for each item is passed to the model function. This package implements the standard time-varying ideal point model by Martin and Quinn (2002) in which ideal points follow a random walk, i.e., in each time period the ideal points can jump in a random direction. In addition, I have implemented a stationary AR(1) ideal point process for situations in which the random walk model does not appropriately reflect over-time change in ideal points. For more information, please see the vignette about time-varying models.\nThe package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).\nThis vignette demonstrates basic usage of the package. I first show some crucial installation pre-requisities.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#installation-instructions",
    "href": "vignettes/Package_Introduction.html#installation-instructions",
    "title": "Introduction to Idealstan",
    "section": "Installation Instructions",
    "text": "Installation Instructions\nTo use idealstan, you first have to have both cmdstanr, an R package, installed and cmdstan, the underlying MCMC library. Unfortunately, cmdstanr is not yet available on CRAN, but you can read complete installation instructions on this page: https://mc-stan.org/cmdstanr/articles/cmdstanr.html.\nAssuming you install cmdstan using the functions provided in the package, please allow it to install in the default location. Otherwise you will always have to pass the path of the cmdstan installation to id_estimate.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#simulation-of-ordinal-irt-with-missing-data",
    "href": "vignettes/Package_Introduction.html#simulation-of-ordinal-irt-with-missing-data",
    "title": "Introduction to Idealstan",
    "section": "Simulation of Ordinal IRT with Missing Data",
    "text": "Simulation of Ordinal IRT with Missing Data\nTo begin with, we can simulate data from an ordinal ideal-point model in which there are three possible responses corresponding to a legislator voting: yes, abstain and no. An additional category is also simulated that indicates whether a legislator shows up to vote or is absent, which traditional IRT models would record as missing data and would drop from the estimation. This package can instead utilize missing data via a hurdle model in which the censoring of the vote/score data is estimated as a function of individual item/bill intercepts and discrimination parameters for the decision to be absent or present. In other words, if the missing data is a reflection of the person’s ideal point, such as more conservative legislators refusing to show up to vote, than the model will make use of this missing data to infer additional information about the legislators’ ideal points.\nThe function id_sim_gen() allows you to simulate data from any of the fourteen models currently implemented in idealstan (see previous list). To include missing data, specify the inflate option as TRUE. For example, here we sample data from an ordinal graded response model:\n\nord_ideal_sim &lt;- id_sim_gen(model='ordinal_grm',inflate = T)\nknitr::kable(as_data_frame(head(ord_ideal_sim@score_matrix)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nitem_id\nperson_id\nmodel_id\ngroup_id\ntime_id\noutcome_disc\nordered_id\nperson_x\nitemcov0\nitemcovmiss0\ndiscrete\n\n\n\n\n1\n1\nmissing\nG\n1\n3\n3\n0\n0\n0\n0\n\n\n2\n1\nmissing\nG\n1\n3\n3\n0\n0\n0\n0\n\n\n3\n1\nmissing\nG\n1\nMissing\n3\n0\n0\n0\n0\n\n\n4\n1\nmissing\nG\n1\n3\n3\n0\n0\n0\n0\n\n\n5\n1\nmissing\nG\n1\n3\n3\n0\n0\n0\n0\n\n\n6\n1\nmissing\nG\n1\n3\n3\n0\n0\n0\n0\n\n\n\n\n\nThe vote/score matrix in the idealdata object ord_ideal_sim has legislators/persons in the rows and bills/items in the columns. The outcome_disc column has the simulated 3-category ordered outcome.\nThe function id_estimate will take this processed data and run an IRT ideal point model. To specify the model type, simply include the number of the model in the id_estimate function. It is also possible to have multiple outcome types in a given model, which requires passing the model_id option in the id_make function with a given model number per item in the data. The package also includes the ability to incorporate hierarchical (person or item-level) covariates, as discussed below.\nTo speed up processing, all of the models in this vignette make use of multiple core parallel computation. To use this option, the specified number of available cores in the ncores option must exceed the number of MCMC chains nchains. cmdstanr will automatically assign cores by dividing the number of chains by the number of cores. In all of the examples in this vignette, I use a machine with 16 cores and estimate 2 chains, so there are 8 cores per chain. By default, id_estimate parallelizes over persons, although that can be changed to items with the map_over_id option (only works with static models).\nThe package has options for identification that are similar to other IRT packages in which the IDs of legislators/persons to constrain are specified to the id_estimate function. For example, we can use the true values of the simulated legislators to constrain one legislator/person with the highest simulated ideal point and one legislator/person with the lowest ideal point. Each constrained parameter must be fixed to a specific value, preferably at either end of the ideal point spectrum, to identify the model. In particular, two pieces of information are necessary: a value for the high ideal point, and the difference between the high and low points. In this example I pre-specify which parameters to constrain based on the simulated data, and leave the pinned values at their defaults, which are +1 and -1.\n\ntrue_legis &lt;- ord_ideal_sim@simul_data$true_person\nhigh_leg &lt;- sort(true_legis,decreasing = TRUE,index.return=TRUE)\nlow_leg &lt;- sort(true_legis,index.return=TRUE)\n\nord_ideal_est &lt;- id_estimate(idealdata=ord_ideal_sim,\n                             model_type=6,\n                             fixtype='prefix',\n                             restrict_ind_high = as.character(high_leg$ix[1]),\n                             restrict_ind_low=as.character(low_leg$ix[1]),\n                             fix_high = sort(true_legis,decreasing = TRUE)[1],\n                             fix_low = sort(true_legis,decreasing = FALSE)[1],\n                             id_refresh=500,\n                             ncores=8,\n                             nchains=2)\n\n[1] \"Running pathfinder to find starting values\"\nPath [1] :Initial log joint density = -1464.324821 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n            113      -7.585e+02      9.409e-04   4.008e-03    1.000e+00  1.000e+00      2826 -1.026e+03 -1.026e+03                   \nPath [1] :Best Iter: [4] ELBO (-964.330239) evaluations: (2826) \nFinished in  0.9 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\n\n\nInit values were only set for a subset of parameters. \nMissing init values for the following parameters:\n - chain 1: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n - chain 2: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n\nTo disable this message use options(cmdstanr_warn_inits = FALSE).\n\n\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -55.8111, but should be greater than the previous element, -55.8111 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 1 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 1 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -8.3876, but should be greater than the previous element, -8.3876 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -1.96713, but should be greater than the previous element, -1.96713 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -5.4228, but should be greater than the previous element, -5.4228 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 1 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 1 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is 1.095, but should be greater than the previous element, 1.095 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 42.6 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 43.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 42.9 seconds.\nTotal execution time: 43.2 seconds.\n\n\nWe can then check and see how well the Stan estimation engine was able to capture the “true” values used in the simulation by plotting the true ideal points relative to the estimated ones:\n\nid_plot_legis(ord_ideal_est,show_true = TRUE)\n\nJoining with `by = join_by(id_num)`\nJoining with `by = join_by(id_num)`\n\n\n\n\n\n\n\n\n\nGiven the small amount of data used to estimate the model, the imprecision with which the ideal points were recovered is not surprising.\nTo automatically identify the model, simply change the fixtype option to 'vb_full'. By default, the model will select the highest and lowest ideal points to constrain by running an approximation to the full posterior using cmdstanr’s pathfinder() function. While this method works, the exact rotation is not known a priori, and so it may produce a different result with multiple runs. Note that there will be two pathfinder runs as the first run identifies the parameters to constrain and the second is used to create starting values for the Hamiltonian Monte Carlo estimation.\nFor example, using our simulated data and identifying the model automatically with 'vb_full':\n\nord_ideal_est &lt;- id_estimate(idealdata=ord_ideal_sim,\n                             model_type=6,\n                             id_refresh=2000,fixtype=\"vb_full\",\n                             ncores=8,\n                           nchains=2)\n\n[1] \"(First Step): Estimating model with Pathfinder (variational inference) to identify modes to constrain.\"\nPath [1] :Initial log joint density = -1945.461108 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n             87      -7.682e+02      3.050e-03   3.012e-03    1.000e+00  1.000e+00      2176 -1.038e+03 -1.038e+03                   \nPath [1] :Best Iter: [78] ELBO (-956.317193) evaluations: (2176) \nFinished in  0.8 seconds.\n\n\n[1] \"Running pathfinder to find starting values\"\nPath [1] :Initial log joint density = -1503.313127 \nPath [1] : Iter      log prob        ||dx||      ||grad||     alpha      alpha0      # evals       ELBO    Best ELBO        Notes  \n            160      -7.477e+02      1.621e-03   6.159e-03    8.538e-01  8.538e-01      4001 -1.020e+03 -1.020e+03                   \nPath [1] :Best Iter: [14] ELBO (-988.052865) evaluations: (4001) \nFinished in  1.3 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\n\n\nInit values were only set for a subset of parameters. \nMissing init values for the following parameters:\n - chain 1: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n - chain 2: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n\nTo disable this message use options(cmdstanr_warn_inits = FALSE).\n\n\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: Exception: ordered_logistic: Cut-points is not a valid ordered vector. The element at 2 is -303.547, but should be greater than the previous element, -303.547 (in '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/model_types_mm_map_persons.stan', line 378, column 6, included from\n\n\nChain 2 '/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/idealstan/stan_files//chunks/map_func.stan', line 401, column 0, included from\n\n\nChain 2 '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 45, column 0) (in '/var/folders/4d/m4b3zyn966d7ctnd4hz4zvfh0000gs/T/Rtmp7rBptZ/model-1575a27f0eea7.stan', line 632, column 2 to line 735, column 20)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 52.9 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 54.3 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 53.6 seconds.\nTotal execution time: 54.4 seconds.\n\n\nWe can see from the plot of the Rhats, which is an MCMC convergence diagnostic, that all the Rhats are below 1.1, which is a good (though not perfect) sign that the model is fully identified:\n\nid_plot_rhats(ord_ideal_est)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nid_plot_legis(ord_ideal_est,show_true = T)\n\nJoining with `by = join_by(id_num)`\nJoining with `by = join_by(id_num)`\n\n\n\n\n\n\n\n\n\nIn general, it is always a good idea to check the Rhats before proceeding with further analysis. Identification of time-varying ideal point models can be more complicated and is discussed in the accompanying vignette. As can be seen above, while the Pathfinder algorithm can identify a mode, it may not be the mode that is theoretically interesting.",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#parameter-values",
    "href": "vignettes/Package_Introduction.html#parameter-values",
    "title": "Introduction to Idealstan",
    "section": "Parameter Values",
    "text": "Parameter Values\nWe can obtain summary estimates of all the ideal points and item/bill discrimination/difficulty parameters using the summary function that provides the median value of the parameters in addition to a specified posterior density interval (i.e., 5%-95%). For example, we can extract summaries for the ideal points:\n\nideal_pts_sum &lt;- summary(sen_est,pars='ideal_pts')\n\nJoining with `by = join_by(id_num)`\n\nknitr::kable(head(ideal_pts_sum))\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerson\nGroup\nTime_Point\nLow Posterior Interval\nPosterior Median\nHigh Posterior Interval\nParameter Name\n\n\n\n\nWYDEN, Ronald Lee\nD\n1\n-9.384757\n-7.691190\n-6.366312\nL_full[100]\n\n\nBOXER, Barbara\nD\n1\n-11.131880\n-8.884305\n-7.094957\nL_full[10]\n\n\nBROWN, Sherrod\nD\n1\n-12.155215\n-9.603485\n-7.695138\nL_full[11]\n\n\nBURR, Richard M.\nR\n1\n5.079804\n5.987380\n7.010768\nL_full[12]\n\n\nCANTWELL, Maria E.\nD\n1\n-11.239415\n-9.086980\n-7.358147\nL_full[13]\n\n\nCAPITO, Shelley Moore\nR\n1\n4.421042\n5.210490\n6.142833\nL_full[14]\n\n\n\n\n\nParameter Name is the name of the parameter in the underlying Stan code, which can be useful f you want to peruse the fitted Stan model (and can be accessed as given in the code below). The name of the parameters for ideal points in the Stan model is L_full (as seen in the summary from above).\n\nstan_obj &lt;- sen_est@stan_samples\n# show the \nstan_obj$draws(c(\"L_full[1]\",\n                        'L_full[2]',\n                        'L_full[3]'))\n\n# A draws_array: 1000 iterations, 2 chains, and 3 variables\n, , variable = L_full[1]\n\n         chain\niteration   1   2\n        1 4.1 4.1\n        2 4.3 4.6\n        3 3.8 4.3\n        4 3.8 4.8\n        5 4.3 5.0\n\n, , variable = L_full[2]\n\n         chain\niteration   1   2\n        1 2.6 1.6\n        2 2.1 3.0\n        3 2.5 2.0\n        4 2.1 3.1\n        5 2.6 3.1\n\n, , variable = L_full[3]\n\n         chain\niteration    1     2\n        1 -9.2  -6.6\n        2 -8.5 -11.3\n        3 -7.8  -7.5\n        4 -9.4 -10.7\n        5 -7.7  -6.2\n\n# ... with 995 more iterations\n\n\nIf we know the name of the Stan parameter, we can look at the trace plot to see how the quality of the Markov Chain Monte Carlo (MCMC) sampling used to fit the model. A good trace plot shows a bouncy line that is stable around an average value. For more info, see the Stan documentation.\n\nstan_trace(sen_est,par='L_full[1]')\n\n\n\n\n\n\n\n\nFinally we can also extract all of the posterior iterations to do additional calculations that average over posterior uncertainty by changing the aggregate option in summary. In the following code, I access the individual posterior iterations for the item/bill parameters, including difficulty (average probability of voting yes), discrimination (how strongly the item/bill loads on either end of the ideal point scale) and the midpoints (position where someone with that ideal point would be indifferent to voting yes/no).\n\nitem_all &lt;- summary(sen_est,pars='items', aggregate=F)\nknitr::kable(head(item_all))\n\n\n\n\n\n\n\n\n\n\n\n\nPosterior_Sample\nItem Name\nItem Type\nPredicted Outcome\nParameter\nIteration\n\n\n\n\n-0.9107640\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n1\n\n\n-1.9440006\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n2\n\n\n-0.9417496\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n3\n\n\n-1.7308176\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n4\n\n\n-1.8197285\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n5\n\n\n-2.3072628\n4\nNon-Inflated Item Midpoint\n1\nA function of other parameters\n6",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "vignettes/Package_Introduction.html#hierarchical-covariates",
    "href": "vignettes/Package_Introduction.html#hierarchical-covariates",
    "title": "Introduction to Idealstan",
    "section": "Hierarchical Covariates",
    "text": "Hierarchical Covariates\nNote: ideal point marginal effects have yet to be implemented as a separate function. In this section I demonstrate how to estimate these effects using R code.\nFinally, we can also fit a model where we include a covariate that varies by person/legislator. To do so, we need to pass a one-sided formula to the id_make function to prepare the data accordingly. By way of example, we will include a model where we include an interaction between party ID (party_code) and the legislator’s age to see if younger/older legislators are more or less conservative. Because this is a static model, the effect of the covariate is averaged over all of the bills in the dataset and all the legislators in the dataset without taking into account the order or time period of the bills.\nIt is important to note that for static ideal point models, covariates are only defined over the legislators/persons who are not being used as constraints in the model, such as John Barasso and Elizabeth Warren in this model.\n\nsenate114$age &lt;- 2018 - senate114$born\n# center the variable\nsenate114$age &lt;- senate114$age - mean(senate114$age)\n# put in units of 10 years\nsenate114$age &lt;- senate114$age / 10\n\n# doing this will improve estimation speed (variables mean-centered and with an SD\n# not much bigger than 1 or 2)\n\nsenate_data &lt;- id_make(senate114,outcome_disc = 'cast_code',\n                       person_id = 'bioname',\n                       item_id = 'rollnumber',\n                       group_id= 'party_code',\n                       time_id='date',\n                       person_cov = ~party_code*age)\n\nsen_est_cov &lt;- id_estimate(senate_data,\n                model_type = 1,\n                fixtype='prefix',\n                nchains=2,\n                ncores=8,\n                 restrict_ind_high = \"BARRASSO, John A.\",\n                 restrict_ind_low=\"WARREN, Elizabeth\",\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  12.8 seconds.\n[1] \"Estimating model with full Stan MCMC sampler.\"\n\n\nInit values were only set for a subset of parameters. \nMissing init values for the following parameters:\n - chain 1: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm3, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n - chain 2: m_sd_free, gp_sd_free, ls_int, ls_int_abs, L_tp1_var, L_AR1, steps_votes3, steps_votes4, steps_votes5, steps_votes6, steps_votes7, steps_votes8, steps_votes9, steps_votes10, steps_votes_grm3, steps_votes_grm4, steps_votes_grm5, steps_votes_grm6, steps_votes_grm7, steps_votes_grm8, steps_votes_grm9, steps_votes_grm10, extra_sd, time_var_gp_free, time_var_free, a_raw\n\nTo disable this message use options(cmdstanr_warn_inits = FALSE).\n\n\nRunning MCMC with 2 parallel chains, with 4 thread(s) per chain...\n\nChain 1 finished in 606.8 seconds.\nChain 2 finished in 613.8 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 610.3 seconds.\nTotal execution time: 614.0 seconds.\n\n\nAs discussed in the associated working paper (https://osf.io/preprints/osf/8j2bt), ideal point marginal effects can be derived from idealstan models in which the raw relationship between the hierarchical covariates and the actual outcomes (in this case, votes) can be shown at the item (vote) level. At present, this feature is not yet implemented in a function, but it can be calculated using code as shown below for a given covariate. In this case, we will look at the marginal effect of age on votes conditional on party affiliation. To do so, we will extract the hierarchical covariate effects from the underlying cmdstanr model and then use the id_post_pred, which allows us to predict the outcome given new data, to calculate the effects.\n\n# First make two new datasets that have different values for age\n# difference is quite small (0.001)\n# This is for numerical differentiation as described in the working paper\n# We need to begin with our original dataset that we passed to the id_make function\n\n  # parameter for the change we will calculate, just needs to be very small\n  eps &lt;- 1e-5\n  \n  new_data1 &lt;- mutate(senate114,\n                      age = age - eps / 2)\n  \n  new_data2 &lt;- mutate(senate114,\n                      age = age + eps / 2)\n  \n  # now predict new outcome distributions given these slightly different datasets\n  # use draws=\"all\" to avoid comparing different draws to each other\n  \n  sen_mod_pred1 &lt;- id_post_pred(sen_est_cov,newdata=new_data1,\n                                 use_cores=4,\n                                draws=\"all\",\n                                 type=\"epred\")\n\n[1] \"Processing posterior replications for 23352 scores using all posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n  sen_mod_pred2 &lt;- id_post_pred(sen_est_cov,newdata=new_data2,\n                                 use_cores=4,\n                                draws=\"all\",\n                                 type=\"epred\")\n\n[1] \"Processing posterior replications for 23352 scores using all posterior samples out of a total of 2000 samples.\"\n[1] \"Adding in hierarchical covariates values to the time-varying person scores.\"\n[1] \"Collapsing covariates to person and time IDs.\"\n[1] \"Done!\"\n[1] \"Now on model 1\"\n\n  # now we need to difference the datasets at the item level to calculate the effects\n  # this will create some lists that will then be appended together to a big data frame\n  # with one observation per posterior draw\n  \n    print(\"Looping over items\")\n\n[1] \"Looping over items\"\n\n    # difference the predictions\n  \n  c1 &lt;- purrr::map2(sen_mod_pred1[[1]],\n                    sen_mod_pred2[[1]],\n                    function(small,big) {\n                      \n                      # difference the effects\n                      \n                      (big - small)/eps\n                      \n                    })\n  \n  # combine into datasets for each item with item id + person (senator) id\n  \n  c2 &lt;- lapply(c1, function(mat) {\n    \n    out_data &lt;- attr(mat, \"data\")\n    colnames(mat) &lt;- out_data$person_id\n    \n    as_tibble(mat) %&gt;% \n      mutate(draws=1:n(),\n             item_id=unique(out_data$item_id)) %&gt;% \n      gather(key=\"person_id\",value=\"estimate\",-draws,-item_id) %&gt;% \n      mutate(person_id=as.numeric(person_id),\n             estimate=as.numeric(estimate))\n    \n  }) %&gt;% bind_rows\n  \n  # merge in some original data\n  to_merge &lt;- mutate(sen_est_cov@score_data@score_matrix, \n                     item_orig=item_id,\n                     person_orig=person_id,\n                     person_id=as.numeric(person_id),\n                     item_id=as.numeric(item_id)) %&gt;% \n    select(person_id, item_id, group_id,item_orig, person_orig) %&gt;% \n    distinct\n  \n  # add in party data so we can calculate party-specific effects\n  \n  c2 &lt;- left_join(c2, to_merge, \n                  by=c(\"item_id\",\"person_id\"))\n  \n  # get effect separately by each item and party\n  # first have to aggregate to party level by draw, then take average by item\n  \n   by_party &lt;- group_by(c2, draws, group_id, item_id, item_orig) %&gt;% \n    summarize(mean_est1=mean(estimate)) %&gt;% \n    group_by(group_id, item_id, item_orig) %&gt;% \n    summarize(mean_est=mean(mean_est1),\n              low_est=quantile(mean_est1, .05),\n              high_est=quantile(mean_est1, .95))\n\n`summarise()` has grouped output by 'draws', 'group_id', 'item_id'. You can\noverride using the `.groups` argument.\n`summarise()` has grouped output by 'group_id', 'item_id'. You can override\nusing the `.groups` argument.\n\n   # merge in item discrimination to add some color / show high-discrim votes\n   \n   item_discrim &lt;- filter(sen_est_cov@summary,\n                         grepl(x=variable, pattern=\"sigma\\\\_reg\\\\_free\")) %&gt;% \n    mutate(item_id=as.numeric(stringr::str_extract(variable, \"[0-9]+\")))\n   \n   by_party &lt;- left_join(by_party,\n                        select(item_discrim, median, item_id))\n\nJoining with `by = join_by(item_id)`\n\n   # plot the result\n   \n   by_party %&gt;% \n    mutate(group_id=factor(group_id,levels=c(\"D\",\"R\",\"I\"),\n                           labels=c(\"Democrats\", \"Republicans\",\"Independent\"))) %&gt;% \n    ggplot(aes(y=mean_est,\n               x=reorder(item_id,mean_est))) +\n    geom_linerange(aes(ymin=low_est,\n                       ymax=high_est,\n                       colour=`median`)) +\n    facet_wrap(~group_id,scales=\"free_x\") +\n    ggthemes::theme_tufte() + \n    scale_colour_viridis_c(name=\"Discrimination\") +\n    coord_flip() +\n    labs(y=\"Marginal Change in Probability of Voting\",\n         x=\"Rollcalls\",\n         caption=\"Marginal effect of age on voting on a specific rollcall in the Senate.\") +\n    geom_hline(yintercept=0,linetype=2) +\n    ggthemes::theme_clean() +\n    theme(axis.text.y=element_blank(),\n          axis.ticks.y=element_blank()) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nBecause these covariates are on the ideal point scale, the meaning of the scale in terms of party ideology must be kept in mind in order to interpret the plot. The way to interpret these plots is that for Republicans, increasing age is associated with voting for bills that are more conservative, while for Democrats, the opposite is true. In other words, older party members tend to vote for bills that are ideologically more extreme than younger party members, though the relationship is strongest for Republicans vs. others. Keeping the direction of the scale in mind is crucial for understanding hierarchical covariates in ideal point models.\nWe can also extract the covariate summary values using the summary function:\n\ncov_sum &lt;- summary(sen_est_cov,pars='person_cov')\nknitr::kable(cov_sum)\n\n\n\n\n\n\n\n\n\n\n\nCovariate\nPosterior Median\nPosterior High Interval\nPosterior Low Interval\nParameter\n\n\n\n\nparty_codeR\n-13.340550\n-12.2172500\n-14.5709100\nlegis_x\n\n\nparty_codeI\n0.737863\n7.3616855\n-5.5033630\nlegis_x\n\n\nage\n0.630616\n1.5679505\n-0.2337192\nlegis_x\n\n\nparty_codeR:age\n-1.396575\n-0.3106965\n-2.5564375\nlegis_x\n\n\nparty_codeI:age\n2.271770\n8.3431525\n-3.6176505\nlegis_x",
    "crumbs": [
      "Articles",
      "Introduction to Idealstan"
    ]
  },
  {
    "objectID": "man/id_plot_all_hist.html",
    "href": "man/id_plot_all_hist.html",
    "title": "idealstan",
    "section": "",
    "text": "This function produces density plots of the different types of parameters in an idealstan model: item (bill) difficulty and discrimination parameters, and person (legislator) ideal points.\n\n\n\nid_plot_all_hist(\n  object,\n  params = \"person\",\n  param_labels = NULL,\n  dens_type = \"all\",\n  return_data = FALSE,\n  func = median,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nparams\n\n\nSelect the type of parameter from the model to plot. ‘person’ for person/legislator ideal points, ‘miss_diff’ and ‘miss_discrim’ for difficulty and discrimination parameters from the missing/inflated item/bill parameters, and ‘obs_diff’ and ‘obs_discrim’ for difficulty and discrimination parameters from the non-missing/non-inflated item/bill parameters.\n\n\n\n\nparam_labels\n\n\nA vector of labels equal to the number of parameters. Primarily useful if return_data is TRUE.\n\n\n\n\ndens_type\n\n\nCan be ‘all’ for showing 90 Or to show one of those posterior estimates at a time, use ‘high’ for 90 ‘low’ for 10 in func (median by default).\n\n\n\n\nreturn_data\n\n\nWhether or not to return the plot as a ggplot2 object and the data together in a list instead of plotting.\n\n\n\n\nfunc\n\n\nThe function to use if ‘dens_type’ is set to ‘function’.\n\n\n\n\n…\n\n\nOther options passed on to the plotting function, currently ignored.",
    "crumbs": [
      "Reference",
      "id_plot_all_hist"
    ]
  },
  {
    "objectID": "man/id_plot_all_hist.html#density-plots-of-posterior-parameters",
    "href": "man/id_plot_all_hist.html#density-plots-of-posterior-parameters",
    "title": "idealstan",
    "section": "",
    "text": "This function produces density plots of the different types of parameters in an idealstan model: item (bill) difficulty and discrimination parameters, and person (legislator) ideal points.\n\n\n\nid_plot_all_hist(\n  object,\n  params = \"person\",\n  param_labels = NULL,\n  dens_type = \"all\",\n  return_data = FALSE,\n  func = median,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nparams\n\n\nSelect the type of parameter from the model to plot. ‘person’ for person/legislator ideal points, ‘miss_diff’ and ‘miss_discrim’ for difficulty and discrimination parameters from the missing/inflated item/bill parameters, and ‘obs_diff’ and ‘obs_discrim’ for difficulty and discrimination parameters from the non-missing/non-inflated item/bill parameters.\n\n\n\n\nparam_labels\n\n\nA vector of labels equal to the number of parameters. Primarily useful if return_data is TRUE.\n\n\n\n\ndens_type\n\n\nCan be ‘all’ for showing 90 Or to show one of those posterior estimates at a time, use ‘high’ for 90 ‘low’ for 10 in func (median by default).\n\n\n\n\nreturn_data\n\n\nWhether or not to return the plot as a ggplot2 object and the data together in a list instead of plotting.\n\n\n\n\nfunc\n\n\nThe function to use if ‘dens_type’ is set to ‘function’.\n\n\n\n\n…\n\n\nOther options passed on to the plotting function, currently ignored.",
    "crumbs": [
      "Reference",
      "id_plot_all_hist"
    ]
  },
  {
    "objectID": "man/id_rebuild_mpi.html",
    "href": "man/id_rebuild_mpi.html",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function takes as input a file location storing the results of a MPI/cluster run.\n\n\n\nid_rebuild_mpi(file_loc = NULL, csv_name = NULL)\n\n\n\n\n\n\n\nfile_loc\n\n\nA string with the location of the original files exported by id_estimate\n\n\n\n\ncsv_name\n\n\nA vector of character names of CSV files with posterior estimates from cmdstan. Should be located in the same place as file_loc.\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\n\n\nGiven the CSV output from cmdstan and the original files exported from the id_estimate function, this function will create an idealstan object which can be further analyzed with other idealstan package helper functions.",
    "crumbs": [
      "Reference",
      "id_rebuild_mpi"
    ]
  },
  {
    "objectID": "man/id_rebuild_mpi.html#deprecated-reconstitute-an-idealstan-object-after-an-mpicluster-run",
    "href": "man/id_rebuild_mpi.html#deprecated-reconstitute-an-idealstan-object-after-an-mpicluster-run",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function takes as input a file location storing the results of a MPI/cluster run.\n\n\n\nid_rebuild_mpi(file_loc = NULL, csv_name = NULL)\n\n\n\n\n\n\n\nfile_loc\n\n\nA string with the location of the original files exported by id_estimate\n\n\n\n\ncsv_name\n\n\nA vector of character names of CSV files with posterior estimates from cmdstan. Should be located in the same place as file_loc.\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\n\n\nGiven the CSV output from cmdstan and the original files exported from the id_estimate function, this function will create an idealstan object which can be further analyzed with other idealstan package helper functions.",
    "crumbs": [
      "Reference",
      "id_rebuild_mpi"
    ]
  },
  {
    "objectID": "man/id_plot_legis.html",
    "href": "man/id_plot_legis.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items.\n\n\n\nid_plot_legis(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  item_plot = NULL,\n  item_plot_type = \"non-inflated\",\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.2,\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects to compare across models\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\nitem_plot\n\n\nThe IDs (character vector) of the bill/item midpoints to overlay on the plot\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model. It will plot them as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options). In addition, if item/bill IDs as a character vector is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\nTo compare across multiple idealstan models, pass a named list list(model1=model1,model2=model2,etc) to the object option. Note that these comparisons will done by individual persons/groups, so if there are a lot of persons/groups, consider using the include option to only compare a specific set of persons/groups.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis"
    ]
  },
  {
    "objectID": "man/id_plot_legis.html#plot-legislatorperson-and-billitem-ideal-points",
    "href": "man/id_plot_legis.html#plot-legislatorperson-and-billitem-ideal-points",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items.\n\n\n\nid_plot_legis(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  item_plot = NULL,\n  item_plot_type = \"non-inflated\",\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.2,\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects to compare across models\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\nitem_plot\n\n\nThe IDs (character vector) of the bill/item midpoints to overlay on the plot\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model. It will plot them as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options). In addition, if item/bill IDs as a character vector is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\nTo compare across multiple idealstan models, pass a named list list(model1=model1,model2=model2,etc) to the object option. Note that these comparisons will done by individual persons/groups, so if there are a lot of persons/groups, consider using the include option to only compare a specific set of persons/groups.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis"
    ]
  },
  {
    "objectID": "man/id_estimate.html",
    "href": "man/id_estimate.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will take a pre-processed idealdata vote/score dataframe and run one of the available IRT/latent space ideal point models on the data using Stan’s MCMC engine.\n\n\n\nid_estimate(\n  idealdata = NULL,\n  model_type = 2,\n  inflate_zero = FALSE,\n  vary_ideal_pts = \"none\",\n  keep_param = NULL,\n  grainsize = 1,\n  mpi_export = NULL,\n  use_subset = FALSE,\n  sample_it = FALSE,\n  subset_group = NULL,\n  subset_person = NULL,\n  sample_size = 20,\n  nchains = 4,\n  niters = 1000,\n  use_vb = FALSE,\n  ignore_db = NULL,\n  restrict_ind_high = NULL,\n  fix_high = 1,\n  fix_low = (-1),\n  restrict_ind_low = NULL,\n  num_restrict_high = 1,\n  num_restrict_low = 1,\n  fixtype = \"prefix\",\n  const_type = \"persons\",\n  id_refresh = 0,\n  prior_only = FALSE,\n  warmup = 1000,\n  ncores = 4,\n  use_groups = FALSE,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  person_sd = 3,\n  time_fix_sd = 0.1,\n  time_var = 10,\n  spline_knots = NULL,\n  spline_degree = 2,\n  ar1_up = 1,\n  ar1_down = 0,\n  boundary_prior = NULL,\n  time_center_cutoff = 50,\n  restrict_var = FALSE,\n  sample_stationary = FALSE,\n  ar_sd = 1,\n  diff_reg_sd = 3,\n  diff_miss_sd = 3,\n  restrict_sd_high = 10,\n  restrict_sd_low = 10,\n  restrict_N_high = 1000,\n  restrict_N_low = 1000,\n  gp_sd_par = 0.025,\n  gp_num_diff = 3,\n  gp_m_sd_par = 0.3,\n  gp_min_length = 0,\n  cmdstan_path_user = NULL,\n  map_over_id = \"persons\",\n  save_files = NULL,\n  het_var = TRUE,\n  compile_optim = FALSE,\n  debug = FALSE,\n  init_pathfinder = TRUE,\n  debug_mode = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nidealdata\n\n\nAn object produced by the id_make containing a score/vote matrix for use for estimation & plotting\n\n\n\n\nmodel_type\n\n\nAn integer reflecting the kind of model to be estimated. See below.\n\n\n\n\ninflate_zero\n\n\nIf the outcome is distributed as Poisson (count/unbounded integer), setting this to TRUE will fit a traditional zero-inflated model. To use correctly, the value for zero must be passed as the miss_val option to id_make before running a model so that zeroes are coded as missing data.\n\n\n\n\nvary_ideal_pts\n\n\nDefault ‘none’. If ‘random_walk’, ‘AR1’, ‘GP’, or ‘splines’, a time-varying ideal point model will be fit with either a random-walk process, an AR1 process, a Gaussian process or a spline. Note that the spline is the easiest time-varying model to fit so long as the number of knots (option spline_knots) is significantly less than the number of time points in the data. See documentation for more info.\n\n\n\n\nkeep_param\n\n\nA list with logical values for different categories of paremeters which should/should not be kept following estimation. Can be any/all of person_int for the person-level intercepts (static ideal points), person_vary for person-varying ideal points, item for observed item parameters (discriminations/intercepts), item_miss for missing item parameters (discriminations/intercepts), and extra for other parameters (hierarchical covariates, ordinal intercepts, etc.). Takes the form list(person_int=TRUE,person_vary=TRUE,item=TRUE,item_miss=TRUE,extra=TRUE). If any are missing in the list, it is assumed that those parameters will be excluded. If NULL (default), will save all parameters in output.\n\n\n\n\ngrainsize\n\n\nThe grainsize parameter for the reduce_sum function used for within-chain parallelization. The default is 1, which means 1 chunk (item or person) per core. Set to -1. to use\n\n\n\n\nmpi_export\n\n\nIf within_chains=“mpi”, this parameter should refer to the directory where the necessary data and Stan code will be exported to. If missing, an interactive dialogue will prompt the user for a directory.\n\n\n\n\nuse_subset\n\n\nWhether a subset of the legislators/persons should be used instead of the full response matrix\n\n\n\n\nsample_it\n\n\nWhether or not to use a random subsample of the response matrix. Useful for testing.\n\n\n\n\nsubset_group\n\n\nIf person/legislative data was included in the id_make function, then you can subset by any value in the $group column of that data if use_subset is TRUE.\n\n\n\n\nsubset_person\n\n\nA list of character values of names of persons/legislators to use to subset if use_subset is TRUE and person/legislative data was included in the id_make function with the required $person.names column\n\n\n\n\nsample_size\n\n\nIf sample_it is TRUE, this value reflects how many legislators/persons will be sampled from the response matrix\n\n\n\n\nnchains\n\n\nThe number of chains to use in Stan’s sampler. Minimum is one. See stan for more info. If use_vb=TRUE, this parameter will determine the number of Pathfinder paths to estimate.\n\n\n\n\nniters\n\n\nThe number of iterations to run Stan’s sampler. Shouldn’t be set much lower than 500. See stan for more info.\n\n\n\n\nuse_vb\n\n\nWhether or not to use Stan’s Pathfinder algorithm instead of full Bayesian inference. Pros: it’s much faster but can be much less accurate. Note that Pathfinder is also used by default for finding initial starting values for sfull HMC sampling.\n\n\n\n\nignore_db\n\n\nIf there are multiple time periods (particularly when there are very many time periods), you can pass in a data frame (or tibble) with one row per person per time period and an indicator column ignore that is equal to 1 for periods that should be considered in sample and 0 for periods for periods that should be considered out of sample. This is useful for excluding time periods from estimation for persons when they could not be present, i.e. such as before entrance into an organization or following death. If ignore equals 0, the person’s ideal point is estimated as a standard Normal draw rather than an auto-correlated parameter, reducing computational burden substantially. Note that there can only be one pre-sample period of 0s, one in-sample period of 1s, and one post-sample period of 0s. Multiple in-sample periods cannot be interspersed with out of sample periods. The columns must be labeled as person_id, time_id and ignore and must match the formatting of the columns fed to the id_make function.\n\n\n\n\nrestrict_ind_high\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a high value (default +1).\n\n\n\n\nfix_high\n\n\nThe value that the high fixed ideal point(s) should be fixed to. Default is +1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nfix_low\n\n\nThe value that the low fixed ideal point(s) should be fixed to. Default is -1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nrestrict_ind_low\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a low value (default -1).\n\n\n\n\nnum_restrict_high\n\n\nIf using variational inference for identification (fixtype=“vb_full”), how many parameters to constraint to positive values? Default is 1.\n\n\n\n\nnum_restrict_low\n\n\nIf using variational inference for identification (ixtype=“vb_full”), how many parameters to constraint to positive negative values? Default is 1.\n\n\n\n\nfixtype\n\n\nSets the particular kind of identification used on the model, could be either ‘vb_full’ (identification provided exclusively by running a variational identification model with no prior info), or ‘prefix’ (two indices of ideal points or items to fix are provided to options restrict_ind_high and restrict_ind_low). See details for more information.\n\n\n\n\nconst_type\n\n\nWhether “persons” are the parameters to be fixed for identification (the default) or “items”. Each of these pinned parameters should be specified to fix_high and fix_low if fixtype equals “prefix”, otherwise the model will select the parameters to pin to fixed values.\n\n\n\n\nid_refresh\n\n\nThe number of times to report iterations from the variational run used to identify models. Default is 0 (nothing output to console).\n\n\n\n\nprior_only\n\n\nWhether to only sample from priors as opposed to the full model with likelihood (the default). Useful for doing posterior predictive checks.\n\n\n\n\nwarmup\n\n\nThe number of iterations to use to calibrate Stan’s sampler on a given model. Shouldn’t be less than 100. See stan for more info.\n\n\n\n\nncores\n\n\nThe number of cores in your computer to use for parallel processing in the Stan engine. See stan for more info. If within_chain is set to “threads”, this parameter will determine the number of threads (independent processes) used for within-chain parallelization.\n\n\n\n\nuse_groups\n\n\nIf TRUE, group parameters from the person/legis data given in id_make will be estimated instead of individual parameters.\n\n\n\n\ndiscrim_reg_upb\n\n\nUpper bound of the rescaled Beta distribution for observed discrimination parameters (default is +1)\n\n\n\n\ndiscrim_reg_lb\n\n\nLower bound of the rescaled Beta distribution for observed discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_miss_upb\n\n\nUpper bound of the rescaled Beta distribution for missing discrimination parameters (default is +1)\n\n\n\n\ndiscrim_miss_lb\n\n\nLower bound of the rescaled Beta distribution for missing discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_reg_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_reg_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_miss_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ndiscrim_miss_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ntime_fix_sd\n\n\nThe variance of the over-time component of the first person/legislator is fixed to this value as a reference. Default is 0.1.\n\n\n\n\nspline_knots\n\n\nNumber of knots (essentially, number of points at which to calculate time-varying ideal points given T time points). Default is NULL, which means that the spline is equivalent to polynomial time trend of degree spline_degree. Note that the spline number (if not null) must be equal or less than the number of time points–and there is no reason to have it equal to the number of time points as that will likely over-fit the data.\n\n\n\n\nspline_degree\n\n\nThe degree of the spline polynomial. The default is 2 which is a quadratic polynomial. A value of 1 will result in independent knots (essentially pooled across time points T). A higher value will result in wigglier time series. There is no \"correct\" value but lower values are likely more stable and easier to identify.\n\n\n\n\nboundary_prior\n\n\nIf your time series has very low variance (change over time), you may want to use this option to put a boundary-avoiding inverse gamma prior on the time series variance parameters if your model has a lot of divergent transitions. To do so, pass a list with a element called beta that signifies the rate parameter of the inverse-gamma distribution. For example, try boundary_prior=list(beta=1). Increasing the value of beta will increase the \"push\" away from zero. Setting it too high will result in time series that exhibit a lot of \"wiggle\" without much need.\n\n\n\n\ntime_center_cutoff\n\n\nThe number of time points above which the model will employ a centered time series approach for AR(1) and random walk models. Below this number the model will employ a non-centered approach. The default is 50 time points, which is relatively arbitrary and higher values may be better if sampling quality is poor above the threshold.\n\n\n\n\nsample_stationary\n\n\nIf TRUE, the AR(1) coefficients in a time-varying model will be sampled from an unconstrained space and then mapped back to a stationary space. Leaving this TRUE is slower but will work better when there is limited information to identify a model. If used, the ar_sd parameter should be increased to 5 to allow for wider sampling in the unconstrained space.\n\n\n\n\nar_sd\n\n\nIf an AR(1) model is used, this defines the prior scale of the Normal distribution. A lower number can help identify the model when there are few time points.\n\n\n\n\ndiff_reg_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the non-inflated model.\n\n\n\n\ndiff_miss_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the inflated model.\n\n\n\n\nrestrict_sd_high\n\n\nSet the prior shape for high pinned parameters. This has a default of 0.01 (equivalent to +0.99), but could be set lower if the data is really large.\n\n\n\n\nrestrict_sd_low\n\n\nSet the prior scale for low pinned parameters. This has a default of 0.01 (equivalent to -0.99), but could be set lower if the data is really large. To make the prior uninformative, set this value and restrict_N_low to +1 (or +2, +2 for weakly informative).\n\n\n\n\nrestrict_N_high\n\n\nSet the prior scale for high pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nrestrict_N_low\n\n\nSet the prior shape for high pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\ngp_sd_par\n\n\nThe upper limit on allowed residual variation of the Gaussian process prior. Increasing the limit will permit the GP to more closely follow the time points, resulting in much sharper bends in the function and potentially oscillation.\n\n\n\n\ngp_num_diff\n\n\nThe number of time points to use to calculate the length-scale prior that determines the level of smoothness of the GP time process. Increasing this value will result in greater smoothness/autocorrelation over time by selecting a greater number of time points over which to calculate the length-scale prior.\n\n\n\n\ngp_m_sd_par\n\n\nThe upper limit of the marginal standard deviation of the GP time process. Decreasing this value will result in smoother fits.\n\n\n\n\ngp_min_length\n\n\nThe minimum value of the GP length-scale parameter. This is a hard lower limit. Increasing this value will force a smoother GP fit. It should always be less than gp_num_diff.\n\n\n\n\ncmdstan_path_user\n\n\nDefault is NULL, and so will default to whatever is set in cmdstanr package. Specify a file path here to use a different cmdtstan installation.\n\n\n\n\nmap_over_id\n\n\nThis parameter identifies which ID variable to use to construct the shards for within-chain parallelization. It defaults to “persons” but can also take a value of “items”. It is recommended to select whichever variable has more distinct values to improve parallelization.\n\n\n\n\nsave_files\n\n\nThe location to save CSV files with MCMC draws from cmdstanr. The default is NULL, which will use a folder in the package directory.\n\n\n\n\nhet_var\n\n\nWhether to use a separate variance parameter for each item if using Normal or Log-Normal distributions that have variance parameters. Defaults to TRUE and should be set to FALSE only if all items have a similar variance.\n\n\n\n\ncompile_optim\n\n\nWhether to use Stan compile optimization flags (off by default)\n\n\n\n\ndebug\n\n\nFor debugging purposes, turns off threading to enable more informative error messages from Stan. Also recompiles model objects.\n\n\n\n\ninit_pathfinder\n\n\nWhether to generate initial values from the Pathfinder algorithm (see Stan documentation). If FALSE, will generate random start values..\n\n\n\n\ndebug_mode\n\n\nWhether to print valuesof all parameters for debugging purposes. If this is used, only one iteration should be used as it generates a lot of console output.\n\n\n\n\n…\n\n\nAdditional parameters passed on to Stan’s sampling engine. See stan for more information.\n\n\n\n\n\n\nTo run an IRT ideal point model, you must first pre-process your data using the id_make function. Be sure to specify the correct options for the kind of model you are going to run: if you want to run an unbounded outcome (i.e. Poisson or continuous), the data needs to be processed differently. Also any hierarchical covariates at the person or item level need to be specified in id_make. If they are specified in id_make, than all subsequent models fit by this function will have these covariates.\nNote that for static ideal point models, the covariates are only defined for those persons who are not being used as constraints.\nAs of this version of idealstan, the following model types are available. Simply pass the number of the model in the list to the model_type option to fit the model.\n\n\nIRT 2-PL (binary response) ideal point model, no missing-data inflation\n\n\nIRT 2-PL ideal point model (binary response) with missing- inflation\n\n\nOrdinal IRT (rating scale) ideal point model no missing-data inflation\n\n\nOrdinal IRT (rating scale) ideal point model with missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model no missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model with missing-data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with no missing data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with missing-data inflation\n\n\nunbounded (Gaussian) IRT ideal point model with no missing data\n\n\nunbounded (Gaussian) IRT ideal point model with missing-data inflation\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with no missing data\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with missing-data inflation\n\n\nLatent Space (binary response) ideal point model with no missing data\n\n\nLatent Space (binary response) ideal point model with missing-data inflation\n\n\nOrdered Beta (proportion/percentage) with no missing data\n\n\nOrdered Beta (proportion/percentage) with missing-data inflation\n\n\n\n\n\nA fitted idealstan object that contains posterior samples of all parameters either via full Bayesian inference or a variational approximation if use_vb is set to TRUE. This object can then be passed to the plotting functions for further analysis.\n\n\n\nIdentifying IRT models is challenging, and ideal point models are still more challenging because the discrimination parameters are not constrained. As a result, more care must be taken to obtain estimates that are the same regardless of starting values. The parameter fixtype enables you to change the type of identification used. The default, ‘vb_full’, does not require any further information from you in order for the model to be fit. In this version of identification, an unidentified model is run using variational Bayesian inference (see vb). The function will then select two persons/legislators or items/bills that end up on either end of the ideal point spectrum, and pin their ideal points to those specific values. To control whether persons/legislator or items/bills are constrained, the const_type can be set to either “persons” or “items” respectively. In many situations, it is prudent to select those persons or items ahead of time to pin to specific values. This allows the analyst to be more specific about what type of latent dimension is to be estimated. To do so, the fixtype option should be set to “prefix”. The values of the persons/items to be pinned can be passed as character values to restrict_ind_high and restrict_ind_low to pin the high/low ends of the latent scale respectively. Note that these should be the actual data values passed to the id_make function. If you don’t pass any values, you will see a prompt asking you to select certain values of persons/items.\nThe pinned values for persons/items are set by default to +1/-1, though this can be changed using the fix_high and fix_low options. This pinned range is sufficient to identify all of the models implemented in idealstan, though fiddling with some parameters may be necessary in difficult cases. For time-series models, one of the person ideal point over-time variances is also fixed to .1, a value that can be changed using the option time_fix_sd.\n\n\n\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\nKubinec, R. \"Generalized Ideal Point Models for Time-Varying and Missing-Data Inference\". Working Paper.\n\n\nBetancourt, Michael. \"Robust Gaussian Processes in Stan\". (October 2017). Case Study.\n\n\n\n\n\nid_make for pre-processing data, id_plot_legis for plotting results, summary for obtaining posterior quantiles, posterior_predict for producing predictive replications.\n\n\n\n\nlibrary(idealstan)\n\n# First we can simulate data for an IRT 2-PL model that is inflated for missing data\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# This code will take at least a few minutes to run \nbin_irt_2pl_abs_sim &lt;- id_sim_gen(model_type='binary',inflate=T)\n\n# Now we can put that directly into the id_estimate function \n# to get full Bayesian posterior estimates\n# We will constrain discrimination parameters \n# for identification purposes based on the true simulated values\n\nbin_irt_2pl_abs_est &lt;- id_estimate(bin_irt_2pl_abs_sim,\n                       model_type=2,\n                       restrict_ind_high = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=TRUE,\n                       index=TRUE)$ix[1],\n                       restrict_ind_low = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=FALSE,\n                       index=TRUE)$ix[1],\n                       fixtype='prefix',\n                       ncores=2,\n                       nchains=2)\n                                   \n# We can now see how well the model recovered the true parameters\n\nid_sim_coverage(bin_irt_2pl_abs_est) %&gt;% \n         bind_rows(.id='Parameter') %&gt;% \n         ggplot(aes(y=avg,x=Parameter)) +\n           stat_summary(fun.args=list(mult=1.96)) + \n           theme_minimal()\n \n\n# In most cases, we will use pre-existing data \n# and we will need to use the id_make function first\n# We will use the full rollcall voting data \n# from the 114th Senate as a rollcall object\n\ndata('senate114')\n\n# Running this model will take at least a few minutes, even with \n# variational inference (use_vb=T) turned on\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(to_idealstan,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='prefix',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_estimate"
    ]
  },
  {
    "objectID": "man/id_estimate.html#estimate-an-idealstan-model",
    "href": "man/id_estimate.html#estimate-an-idealstan-model",
    "title": "idealstan",
    "section": "",
    "text": "This function will take a pre-processed idealdata vote/score dataframe and run one of the available IRT/latent space ideal point models on the data using Stan’s MCMC engine.\n\n\n\nid_estimate(\n  idealdata = NULL,\n  model_type = 2,\n  inflate_zero = FALSE,\n  vary_ideal_pts = \"none\",\n  keep_param = NULL,\n  grainsize = 1,\n  mpi_export = NULL,\n  use_subset = FALSE,\n  sample_it = FALSE,\n  subset_group = NULL,\n  subset_person = NULL,\n  sample_size = 20,\n  nchains = 4,\n  niters = 1000,\n  use_vb = FALSE,\n  ignore_db = NULL,\n  restrict_ind_high = NULL,\n  fix_high = 1,\n  fix_low = (-1),\n  restrict_ind_low = NULL,\n  num_restrict_high = 1,\n  num_restrict_low = 1,\n  fixtype = \"prefix\",\n  const_type = \"persons\",\n  id_refresh = 0,\n  prior_only = FALSE,\n  warmup = 1000,\n  ncores = 4,\n  use_groups = FALSE,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  person_sd = 3,\n  time_fix_sd = 0.1,\n  time_var = 10,\n  spline_knots = NULL,\n  spline_degree = 2,\n  ar1_up = 1,\n  ar1_down = 0,\n  boundary_prior = NULL,\n  time_center_cutoff = 50,\n  restrict_var = FALSE,\n  sample_stationary = FALSE,\n  ar_sd = 1,\n  diff_reg_sd = 3,\n  diff_miss_sd = 3,\n  restrict_sd_high = 10,\n  restrict_sd_low = 10,\n  restrict_N_high = 1000,\n  restrict_N_low = 1000,\n  gp_sd_par = 0.025,\n  gp_num_diff = 3,\n  gp_m_sd_par = 0.3,\n  gp_min_length = 0,\n  cmdstan_path_user = NULL,\n  map_over_id = \"persons\",\n  save_files = NULL,\n  het_var = TRUE,\n  compile_optim = FALSE,\n  debug = FALSE,\n  init_pathfinder = TRUE,\n  debug_mode = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nidealdata\n\n\nAn object produced by the id_make containing a score/vote matrix for use for estimation & plotting\n\n\n\n\nmodel_type\n\n\nAn integer reflecting the kind of model to be estimated. See below.\n\n\n\n\ninflate_zero\n\n\nIf the outcome is distributed as Poisson (count/unbounded integer), setting this to TRUE will fit a traditional zero-inflated model. To use correctly, the value for zero must be passed as the miss_val option to id_make before running a model so that zeroes are coded as missing data.\n\n\n\n\nvary_ideal_pts\n\n\nDefault ‘none’. If ‘random_walk’, ‘AR1’, ‘GP’, or ‘splines’, a time-varying ideal point model will be fit with either a random-walk process, an AR1 process, a Gaussian process or a spline. Note that the spline is the easiest time-varying model to fit so long as the number of knots (option spline_knots) is significantly less than the number of time points in the data. See documentation for more info.\n\n\n\n\nkeep_param\n\n\nA list with logical values for different categories of paremeters which should/should not be kept following estimation. Can be any/all of person_int for the person-level intercepts (static ideal points), person_vary for person-varying ideal points, item for observed item parameters (discriminations/intercepts), item_miss for missing item parameters (discriminations/intercepts), and extra for other parameters (hierarchical covariates, ordinal intercepts, etc.). Takes the form list(person_int=TRUE,person_vary=TRUE,item=TRUE,item_miss=TRUE,extra=TRUE). If any are missing in the list, it is assumed that those parameters will be excluded. If NULL (default), will save all parameters in output.\n\n\n\n\ngrainsize\n\n\nThe grainsize parameter for the reduce_sum function used for within-chain parallelization. The default is 1, which means 1 chunk (item or person) per core. Set to -1. to use\n\n\n\n\nmpi_export\n\n\nIf within_chains=“mpi”, this parameter should refer to the directory where the necessary data and Stan code will be exported to. If missing, an interactive dialogue will prompt the user for a directory.\n\n\n\n\nuse_subset\n\n\nWhether a subset of the legislators/persons should be used instead of the full response matrix\n\n\n\n\nsample_it\n\n\nWhether or not to use a random subsample of the response matrix. Useful for testing.\n\n\n\n\nsubset_group\n\n\nIf person/legislative data was included in the id_make function, then you can subset by any value in the $group column of that data if use_subset is TRUE.\n\n\n\n\nsubset_person\n\n\nA list of character values of names of persons/legislators to use to subset if use_subset is TRUE and person/legislative data was included in the id_make function with the required $person.names column\n\n\n\n\nsample_size\n\n\nIf sample_it is TRUE, this value reflects how many legislators/persons will be sampled from the response matrix\n\n\n\n\nnchains\n\n\nThe number of chains to use in Stan’s sampler. Minimum is one. See stan for more info. If use_vb=TRUE, this parameter will determine the number of Pathfinder paths to estimate.\n\n\n\n\nniters\n\n\nThe number of iterations to run Stan’s sampler. Shouldn’t be set much lower than 500. See stan for more info.\n\n\n\n\nuse_vb\n\n\nWhether or not to use Stan’s Pathfinder algorithm instead of full Bayesian inference. Pros: it’s much faster but can be much less accurate. Note that Pathfinder is also used by default for finding initial starting values for sfull HMC sampling.\n\n\n\n\nignore_db\n\n\nIf there are multiple time periods (particularly when there are very many time periods), you can pass in a data frame (or tibble) with one row per person per time period and an indicator column ignore that is equal to 1 for periods that should be considered in sample and 0 for periods for periods that should be considered out of sample. This is useful for excluding time periods from estimation for persons when they could not be present, i.e. such as before entrance into an organization or following death. If ignore equals 0, the person’s ideal point is estimated as a standard Normal draw rather than an auto-correlated parameter, reducing computational burden substantially. Note that there can only be one pre-sample period of 0s, one in-sample period of 1s, and one post-sample period of 0s. Multiple in-sample periods cannot be interspersed with out of sample periods. The columns must be labeled as person_id, time_id and ignore and must match the formatting of the columns fed to the id_make function.\n\n\n\n\nrestrict_ind_high\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a high value (default +1).\n\n\n\n\nfix_high\n\n\nThe value that the high fixed ideal point(s) should be fixed to. Default is +1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nfix_low\n\n\nThe value that the low fixed ideal point(s) should be fixed to. Default is -1. Does not apply when const_type=“items”; in that case, use restrict_sd/restrict_N parameters (see below).\n\n\n\n\nrestrict_ind_low\n\n\nIf fixtype is not \"vb_full\", a vector of character values or integer indices of a legislator/person or bill/item to pin to a low value (default -1).\n\n\n\n\nnum_restrict_high\n\n\nIf using variational inference for identification (fixtype=“vb_full”), how many parameters to constraint to positive values? Default is 1.\n\n\n\n\nnum_restrict_low\n\n\nIf using variational inference for identification (ixtype=“vb_full”), how many parameters to constraint to positive negative values? Default is 1.\n\n\n\n\nfixtype\n\n\nSets the particular kind of identification used on the model, could be either ‘vb_full’ (identification provided exclusively by running a variational identification model with no prior info), or ‘prefix’ (two indices of ideal points or items to fix are provided to options restrict_ind_high and restrict_ind_low). See details for more information.\n\n\n\n\nconst_type\n\n\nWhether “persons” are the parameters to be fixed for identification (the default) or “items”. Each of these pinned parameters should be specified to fix_high and fix_low if fixtype equals “prefix”, otherwise the model will select the parameters to pin to fixed values.\n\n\n\n\nid_refresh\n\n\nThe number of times to report iterations from the variational run used to identify models. Default is 0 (nothing output to console).\n\n\n\n\nprior_only\n\n\nWhether to only sample from priors as opposed to the full model with likelihood (the default). Useful for doing posterior predictive checks.\n\n\n\n\nwarmup\n\n\nThe number of iterations to use to calibrate Stan’s sampler on a given model. Shouldn’t be less than 100. See stan for more info.\n\n\n\n\nncores\n\n\nThe number of cores in your computer to use for parallel processing in the Stan engine. See stan for more info. If within_chain is set to “threads”, this parameter will determine the number of threads (independent processes) used for within-chain parallelization.\n\n\n\n\nuse_groups\n\n\nIf TRUE, group parameters from the person/legis data given in id_make will be estimated instead of individual parameters.\n\n\n\n\ndiscrim_reg_upb\n\n\nUpper bound of the rescaled Beta distribution for observed discrimination parameters (default is +1)\n\n\n\n\ndiscrim_reg_lb\n\n\nLower bound of the rescaled Beta distribution for observed discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_miss_upb\n\n\nUpper bound of the rescaled Beta distribution for missing discrimination parameters (default is +1)\n\n\n\n\ndiscrim_miss_lb\n\n\nLower bound of the rescaled Beta distribution for missing discrimination parameters (default is -1). Set to 0 for conventional IRT.\n\n\n\n\ndiscrim_reg_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_reg_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the discrimination parameters.\n\n\n\n\ndiscrim_miss_scale\n\n\nSet the scale parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ndiscrim_miss_shape\n\n\nSet the shape parameter for the rescaled Beta distribution of the missingness discrimination parameters.\n\n\n\n\ntime_fix_sd\n\n\nThe variance of the over-time component of the first person/legislator is fixed to this value as a reference. Default is 0.1.\n\n\n\n\nspline_knots\n\n\nNumber of knots (essentially, number of points at which to calculate time-varying ideal points given T time points). Default is NULL, which means that the spline is equivalent to polynomial time trend of degree spline_degree. Note that the spline number (if not null) must be equal or less than the number of time points–and there is no reason to have it equal to the number of time points as that will likely over-fit the data.\n\n\n\n\nspline_degree\n\n\nThe degree of the spline polynomial. The default is 2 which is a quadratic polynomial. A value of 1 will result in independent knots (essentially pooled across time points T). A higher value will result in wigglier time series. There is no \"correct\" value but lower values are likely more stable and easier to identify.\n\n\n\n\nboundary_prior\n\n\nIf your time series has very low variance (change over time), you may want to use this option to put a boundary-avoiding inverse gamma prior on the time series variance parameters if your model has a lot of divergent transitions. To do so, pass a list with a element called beta that signifies the rate parameter of the inverse-gamma distribution. For example, try boundary_prior=list(beta=1). Increasing the value of beta will increase the \"push\" away from zero. Setting it too high will result in time series that exhibit a lot of \"wiggle\" without much need.\n\n\n\n\ntime_center_cutoff\n\n\nThe number of time points above which the model will employ a centered time series approach for AR(1) and random walk models. Below this number the model will employ a non-centered approach. The default is 50 time points, which is relatively arbitrary and higher values may be better if sampling quality is poor above the threshold.\n\n\n\n\nsample_stationary\n\n\nIf TRUE, the AR(1) coefficients in a time-varying model will be sampled from an unconstrained space and then mapped back to a stationary space. Leaving this TRUE is slower but will work better when there is limited information to identify a model. If used, the ar_sd parameter should be increased to 5 to allow for wider sampling in the unconstrained space.\n\n\n\n\nar_sd\n\n\nIf an AR(1) model is used, this defines the prior scale of the Normal distribution. A lower number can help identify the model when there are few time points.\n\n\n\n\ndiff_reg_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the non-inflated model.\n\n\n\n\ndiff_miss_sd\n\n\nSet the prior standard deviation for the bill (item) intercepts for the inflated model.\n\n\n\n\nrestrict_sd_high\n\n\nSet the prior shape for high pinned parameters. This has a default of 0.01 (equivalent to +0.99), but could be set lower if the data is really large.\n\n\n\n\nrestrict_sd_low\n\n\nSet the prior scale for low pinned parameters. This has a default of 0.01 (equivalent to -0.99), but could be set lower if the data is really large. To make the prior uninformative, set this value and restrict_N_low to +1 (or +2, +2 for weakly informative).\n\n\n\n\nrestrict_N_high\n\n\nSet the prior scale for high pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\nrestrict_N_low\n\n\nSet the prior shape for high pinned parameters. Default is 1000 (equivalent to 1,000 observations of the pinned value). Higher values make the pin stronger (for example if there is a lot of data).\n\n\n\n\ngp_sd_par\n\n\nThe upper limit on allowed residual variation of the Gaussian process prior. Increasing the limit will permit the GP to more closely follow the time points, resulting in much sharper bends in the function and potentially oscillation.\n\n\n\n\ngp_num_diff\n\n\nThe number of time points to use to calculate the length-scale prior that determines the level of smoothness of the GP time process. Increasing this value will result in greater smoothness/autocorrelation over time by selecting a greater number of time points over which to calculate the length-scale prior.\n\n\n\n\ngp_m_sd_par\n\n\nThe upper limit of the marginal standard deviation of the GP time process. Decreasing this value will result in smoother fits.\n\n\n\n\ngp_min_length\n\n\nThe minimum value of the GP length-scale parameter. This is a hard lower limit. Increasing this value will force a smoother GP fit. It should always be less than gp_num_diff.\n\n\n\n\ncmdstan_path_user\n\n\nDefault is NULL, and so will default to whatever is set in cmdstanr package. Specify a file path here to use a different cmdtstan installation.\n\n\n\n\nmap_over_id\n\n\nThis parameter identifies which ID variable to use to construct the shards for within-chain parallelization. It defaults to “persons” but can also take a value of “items”. It is recommended to select whichever variable has more distinct values to improve parallelization.\n\n\n\n\nsave_files\n\n\nThe location to save CSV files with MCMC draws from cmdstanr. The default is NULL, which will use a folder in the package directory.\n\n\n\n\nhet_var\n\n\nWhether to use a separate variance parameter for each item if using Normal or Log-Normal distributions that have variance parameters. Defaults to TRUE and should be set to FALSE only if all items have a similar variance.\n\n\n\n\ncompile_optim\n\n\nWhether to use Stan compile optimization flags (off by default)\n\n\n\n\ndebug\n\n\nFor debugging purposes, turns off threading to enable more informative error messages from Stan. Also recompiles model objects.\n\n\n\n\ninit_pathfinder\n\n\nWhether to generate initial values from the Pathfinder algorithm (see Stan documentation). If FALSE, will generate random start values..\n\n\n\n\ndebug_mode\n\n\nWhether to print valuesof all parameters for debugging purposes. If this is used, only one iteration should be used as it generates a lot of console output.\n\n\n\n\n…\n\n\nAdditional parameters passed on to Stan’s sampling engine. See stan for more information.\n\n\n\n\n\n\nTo run an IRT ideal point model, you must first pre-process your data using the id_make function. Be sure to specify the correct options for the kind of model you are going to run: if you want to run an unbounded outcome (i.e. Poisson or continuous), the data needs to be processed differently. Also any hierarchical covariates at the person or item level need to be specified in id_make. If they are specified in id_make, than all subsequent models fit by this function will have these covariates.\nNote that for static ideal point models, the covariates are only defined for those persons who are not being used as constraints.\nAs of this version of idealstan, the following model types are available. Simply pass the number of the model in the list to the model_type option to fit the model.\n\n\nIRT 2-PL (binary response) ideal point model, no missing-data inflation\n\n\nIRT 2-PL ideal point model (binary response) with missing- inflation\n\n\nOrdinal IRT (rating scale) ideal point model no missing-data inflation\n\n\nOrdinal IRT (rating scale) ideal point model with missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model no missing-data inflation\n\n\nOrdinal IRT (graded response) ideal point model with missing-data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with no missing data inflation\n\n\nPoisson IRT (Wordfish) ideal point model with missing-data inflation\n\n\nunbounded (Gaussian) IRT ideal point model with no missing data\n\n\nunbounded (Gaussian) IRT ideal point model with missing-data inflation\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with no missing data\n\n\nPositive-unbounded (Log-normal) IRT ideal point model with missing-data inflation\n\n\nLatent Space (binary response) ideal point model with no missing data\n\n\nLatent Space (binary response) ideal point model with missing-data inflation\n\n\nOrdered Beta (proportion/percentage) with no missing data\n\n\nOrdered Beta (proportion/percentage) with missing-data inflation\n\n\n\n\n\nA fitted idealstan object that contains posterior samples of all parameters either via full Bayesian inference or a variational approximation if use_vb is set to TRUE. This object can then be passed to the plotting functions for further analysis.\n\n\n\nIdentifying IRT models is challenging, and ideal point models are still more challenging because the discrimination parameters are not constrained. As a result, more care must be taken to obtain estimates that are the same regardless of starting values. The parameter fixtype enables you to change the type of identification used. The default, ‘vb_full’, does not require any further information from you in order for the model to be fit. In this version of identification, an unidentified model is run using variational Bayesian inference (see vb). The function will then select two persons/legislators or items/bills that end up on either end of the ideal point spectrum, and pin their ideal points to those specific values. To control whether persons/legislator or items/bills are constrained, the const_type can be set to either “persons” or “items” respectively. In many situations, it is prudent to select those persons or items ahead of time to pin to specific values. This allows the analyst to be more specific about what type of latent dimension is to be estimated. To do so, the fixtype option should be set to “prefix”. The values of the persons/items to be pinned can be passed as character values to restrict_ind_high and restrict_ind_low to pin the high/low ends of the latent scale respectively. Note that these should be the actual data values passed to the id_make function. If you don’t pass any values, you will see a prompt asking you to select certain values of persons/items.\nThe pinned values for persons/items are set by default to +1/-1, though this can be changed using the fix_high and fix_low options. This pinned range is sufficient to identify all of the models implemented in idealstan, though fiddling with some parameters may be necessary in difficult cases. For time-series models, one of the person ideal point over-time variances is also fixed to .1, a value that can be changed using the option time_fix_sd.\n\n\n\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\nKubinec, R. \"Generalized Ideal Point Models for Time-Varying and Missing-Data Inference\". Working Paper.\n\n\nBetancourt, Michael. \"Robust Gaussian Processes in Stan\". (October 2017). Case Study.\n\n\n\n\n\nid_make for pre-processing data, id_plot_legis for plotting results, summary for obtaining posterior quantiles, posterior_predict for producing predictive replications.\n\n\n\n\nlibrary(idealstan)\n\n# First we can simulate data for an IRT 2-PL model that is inflated for missing data\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# This code will take at least a few minutes to run \nbin_irt_2pl_abs_sim &lt;- id_sim_gen(model_type='binary',inflate=T)\n\n# Now we can put that directly into the id_estimate function \n# to get full Bayesian posterior estimates\n# We will constrain discrimination parameters \n# for identification purposes based on the true simulated values\n\nbin_irt_2pl_abs_est &lt;- id_estimate(bin_irt_2pl_abs_sim,\n                       model_type=2,\n                       restrict_ind_high = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=TRUE,\n                       index=TRUE)$ix[1],\n                       restrict_ind_low = \n                       sort(bin_irt_2pl_abs_sim@simul_data$true_person,\n                       decreasing=FALSE,\n                       index=TRUE)$ix[1],\n                       fixtype='prefix',\n                       ncores=2,\n                       nchains=2)\n                                   \n# We can now see how well the model recovered the true parameters\n\nid_sim_coverage(bin_irt_2pl_abs_est) %&gt;% \n         bind_rows(.id='Parameter') %&gt;% \n         ggplot(aes(y=avg,x=Parameter)) +\n           stat_summary(fun.args=list(mult=1.96)) + \n           theme_minimal()\n \n\n# In most cases, we will use pre-existing data \n# and we will need to use the id_make function first\n# We will use the full rollcall voting data \n# from the 114th Senate as a rollcall object\n\ndata('senate114')\n\n# Running this model will take at least a few minutes, even with \n# variational inference (use_vb=T) turned on\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(to_idealstan,\nmodel_type = 2,\nuse_vb = TRUE,\nfixtype='prefix',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis(sen_est)",
    "crumbs": [
      "Reference",
      "id_estimate"
    ]
  },
  {
    "objectID": "man/id_sim_rmse.html",
    "href": "man/id_sim_rmse.html",
    "title": "idealstan",
    "section": "",
    "text": "RMSE function for calculating individual RMSE values compared to true simulation scores Returns a data frame with RMSE plus quantiles.\n\nDescription\nRMSE function for calculating individual RMSE values compared to true simulation scores Returns a data frame with RMSE plus quantiles.\n\n\nUsage\nid_sim_rmse(obj, rep = 1)\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data from id_sim_gen\n\n\n\n\nrep\n\n\nOver how many replicates to calculate RMSE? Currently can only be 1",
    "crumbs": [
      "Reference",
      "id_sim_rmse"
    ]
  },
  {
    "objectID": "man/idealdata-class.html",
    "href": "man/idealdata-class.html",
    "title": "idealstan",
    "section": "",
    "text": "idealdata objects contain the relevant legislator/bill (person/item) matrix of data along with slots containing information about the kind of identification used in the estimation.\n\n\n\nid_make to create an idealdata object suitable for estimation with id_estimate.",
    "crumbs": [
      "Reference",
      "idealdata-class"
    ]
  },
  {
    "objectID": "man/idealdata-class.html#data-and-identification-for-id_estimate",
    "href": "man/idealdata-class.html#data-and-identification-for-id_estimate",
    "title": "idealstan",
    "section": "",
    "text": "idealdata objects contain the relevant legislator/bill (person/item) matrix of data along with slots containing information about the kind of identification used in the estimation.\n\n\n\nid_make to create an idealdata object suitable for estimation with id_estimate.",
    "crumbs": [
      "Reference",
      "idealdata-class"
    ]
  },
  {
    "objectID": "man/id_plot_legis_var.html",
    "href": "man/id_plot_legis_var.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the over-time variances (average rates of change in ideal points) for all the persons/legislators in the model.\n\n\n\nid_plot_legis_var(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.1,\n  group_color = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis function will plot the person/legislator over-time variances as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options).\n\n\n\n\nlibrary(idealstan)\n\n\n# To demonstrate, we load the 114th Senate data and fit a time-varying model\n\ndata('senate114_fit')\n\nsenate_data &lt;- id_make(senate114,outcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nmiss_val='Absent')\n\n senate114_time_fit &lt;- id_estimate(senate_data,\n model_type = 2,\n use_vb = T,\n fixtype='vb_partial',\n vary_ideal_pts='random_walk',\n restrict_ind_high = \"WARREN, Elizabeth\",\n restrict_ind_low=\"BARRASSO, John A.\",\n seed=84520)\n# We plot the variances for all the Senators\n\nid_plot_legis_var(senate114_fit)",
    "crumbs": [
      "Reference",
      "id_plot_legis_var"
    ]
  },
  {
    "objectID": "man/id_plot_legis_var.html#plot-legislatorperson-over-time-variances",
    "href": "man/id_plot_legis_var.html#plot-legislatorperson-over-time-variances",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the over-time variances (average rates of change in ideal points) for all the persons/legislators in the model.\n\n\n\nid_plot_legis_var(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  point_size = 1,\n  hjust_length = -0.7,\n  person_labels = TRUE,\n  group_labels = F,\n  person_ci_alpha = 0.1,\n  group_color = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nhigh_limit\n\n\nThe quantile (number between 0 and 1) for the high end of posterior uncertainty to show in plot\n\n\n\n\nlow_limit\n\n\nThe quantile (number between 0 and 1) for the low end of posterior uncertainty to show in plot\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\npoint_size\n\n\nIf person_labels and group_labels are set to FALSE, controls the size of the points plotted.\n\n\n\n\nhjust_length\n\n\nhorizontal adjustment of the legislator labels\n\n\n\n\nperson_labels\n\n\nif TRUE, use the person_id column to plot labels for the person (legislator) ideal points\n\n\n\n\ngroup_labels\n\n\nif TRUE, use the group column to plot text markers for the group (parties) from the person/legislator data\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of the dot plot and confidence bars for the person ideal points\n\n\n\n\ngroup_color\n\n\nIf TRUE, give each group/bloc a different color\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis function will plot the person/legislator over-time variances as a vertical dot plot with associated high-density posterior interval (can be changed with high_limit and low_limit options).\n\n\n\n\nlibrary(idealstan)\n\n\n# To demonstrate, we load the 114th Senate data and fit a time-varying model\n\ndata('senate114_fit')\n\nsenate_data &lt;- id_make(senate114,outcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nmiss_val='Absent')\n\n senate114_time_fit &lt;- id_estimate(senate_data,\n model_type = 2,\n use_vb = T,\n fixtype='vb_partial',\n vary_ideal_pts='random_walk',\n restrict_ind_high = \"WARREN, Elizabeth\",\n restrict_ind_low=\"BARRASSO, John A.\",\n seed=84520)\n# We plot the variances for all the Senators\n\nid_plot_legis_var(senate114_fit)",
    "crumbs": [
      "Reference",
      "id_plot_legis_var"
    ]
  },
  {
    "objectID": "man/senate114.html",
    "href": "man/senate114.html",
    "title": "idealstan",
    "section": "",
    "text": "This rollcall vote object (see rollcall) contains voting records for the 114th Senate in the US Congress. Not all rollcalls are included, only those that had a 70-30 or closer split in the vote. The data can be pre-processed via the id_make function for estimation. See package vignette for details.\n\n\n\nsenate114\n\n\n\n\nA long data frame with one row for every vote cast by a Senator.\n\n\n\nhttp://www.voteview.com/",
    "crumbs": [
      "Reference",
      "senate114"
    ]
  },
  {
    "objectID": "man/senate114.html#rollcall-vote-data-for-114th-senate",
    "href": "man/senate114.html#rollcall-vote-data-for-114th-senate",
    "title": "idealstan",
    "section": "",
    "text": "This rollcall vote object (see rollcall) contains voting records for the 114th Senate in the US Congress. Not all rollcalls are included, only those that had a 70-30 or closer split in the vote. The data can be pre-processed via the id_make function for estimation. See package vignette for details.\n\n\n\nsenate114\n\n\n\n\nA long data frame with one row for every vote cast by a Senator.\n\n\n\nhttp://www.voteview.com/",
    "crumbs": [
      "Reference",
      "senate114"
    ]
  },
  {
    "objectID": "man/id_plot_ppc.html",
    "href": "man/id_plot_ppc.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is the generic method for generating posterior distributions from a fitted idealstan model. Functions are documented in the actual method.\n\n\n\nid_plot_ppc(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars",
    "crumbs": [
      "Reference",
      "id_plot_ppc"
    ]
  },
  {
    "objectID": "man/id_plot_ppc.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "href": "man/id_plot_ppc.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is the generic method for generating posterior distributions from a fitted idealstan model. Functions are documented in the actual method.\n\n\n\nid_plot_ppc(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars",
    "crumbs": [
      "Reference",
      "id_plot_ppc"
    ]
  },
  {
    "objectID": "man/id_post_pred.html",
    "href": "man/id_post_pred.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is a generic that is used to match the functions used with ppc_bars to calculate the posterior predictive distribution of the data given the model.\n\n\n\nid_post_pred(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nAll other parameters passed on to the underlying function.\n\n\n\n\n\n\nposterior_predict methods should return a \\(D\\) by \\(N\\) matrix, where \\(D\\) is the number of draws from the posterior predictive distribution and \\(N\\) is the number of data points being predicted per draw.",
    "crumbs": [
      "Reference",
      "id_post_pred"
    ]
  },
  {
    "objectID": "man/id_post_pred.html#generic-method-for-obtaining-posterior-predictive-distribution-from-stan-objects",
    "href": "man/id_post_pred.html#generic-method-for-obtaining-posterior-predictive-distribution-from-stan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is a generic that is used to match the functions used with ppc_bars to calculate the posterior predictive distribution of the data given the model.\n\n\n\nid_post_pred(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nAll other parameters passed on to the underlying function.\n\n\n\n\n\n\nposterior_predict methods should return a \\(D\\) by \\(N\\) matrix, where \\(D\\) is the number of draws from the posterior predictive distribution and \\(N\\) is the number of data points being predicted per draw.",
    "crumbs": [
      "Reference",
      "id_post_pred"
    ]
  },
  {
    "objectID": "man/id_plot_irf.html",
    "href": "man/id_plot_irf.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will generate an impulse response function (IRF) for a given covariate. The IRF shows the marginal impact of a 1-unit change in the covariate on a person’s ideal point over time. To use this function, the vary_ideal_pts option in id_estimate must have received the ‘AR1’ option as IRFs are only available for the AR(1) auto-regressive model.\n\n\n\nid_plot_irf(\n  object,\n  cov_name = NULL,\n  label_high = \"Liberal\",\n  label_low = \"Conservative\",\n  pred_outcome = NULL,\n  recalc_vals = F,\n  include = NULL,\n  time_calc = 10,\n  time_label = \"Time Points\",\n  line_type = 2,\n  line_width = 1,\n  line_alpha = 1,\n  line_color = \"red\",\n  ci_color = \"black\",\n  ci_alpha = 0.5,\n  use_ci = TRUE,\n  high_quantile = 0.95,\n  low_quantile = 0.05,\n  calc_varying = T\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncov_name\n\n\nThe name of the covariate to plot. Leave blank to select from a list of available covariates\n\n\n\n\nlabel_high\n\n\nThe character label for the upper end of the latent scale\n\n\n\n\nlabel_low\n\n\nThe character label for the lower end of the latent scale\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be a character value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nrecalc_vals\n\n\nWhether to combine two variables into one through addition before computing IRFs. If TRUE, two names of parameters should be passed to cov_name or selected from the dialog list\n\n\n\n\ninclude\n\n\nA list of character names of person or group IDs for which to calculate IRFs\n\n\n\n\ntime_calc\n\n\nThe maximum number of time points over which to calculate the IRF\n\n\n\n\ntime_label\n\n\nCharacter string specifying the type of time points (default is just “Time Points”)\n\n\n\n\nline_type\n\n\nThe line type of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_width\n\n\nThe line width of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_alpha\n\n\nThe line alpha (transparency) of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_color\n\n\nThe color of the IRF line (see ggplot2 documentation)\n\n\n\n\nci_color\n\n\nThe color of the IRF credible interval (see ggplot2 documentation)\n\n\n\n\nci_alpha\n\n\nThe alpha of the IRF credible interval (see ggplot2 documentation)\n\n\n\n\nuse_ci\n\n\nWhether or not to plot a credible interval around the lines\n\n\n\n\nhigh_quantile\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nlow_quantile\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\ncalc_varying\n\n\nif TRUE, will calculate marginal effects of the covariates on each end of the latent scale (see vignette for more information)\n\n\n\n\n\n\na ggplot2 object that can be further customized if necessary",
    "crumbs": [
      "Reference",
      "id_plot_irf"
    ]
  },
  {
    "objectID": "man/id_plot_irf.html#generate-impulse-response-functions-for-covariates",
    "href": "man/id_plot_irf.html#generate-impulse-response-functions-for-covariates",
    "title": "idealstan",
    "section": "",
    "text": "This function will generate an impulse response function (IRF) for a given covariate. The IRF shows the marginal impact of a 1-unit change in the covariate on a person’s ideal point over time. To use this function, the vary_ideal_pts option in id_estimate must have received the ‘AR1’ option as IRFs are only available for the AR(1) auto-regressive model.\n\n\n\nid_plot_irf(\n  object,\n  cov_name = NULL,\n  label_high = \"Liberal\",\n  label_low = \"Conservative\",\n  pred_outcome = NULL,\n  recalc_vals = F,\n  include = NULL,\n  time_calc = 10,\n  time_label = \"Time Points\",\n  line_type = 2,\n  line_width = 1,\n  line_alpha = 1,\n  line_color = \"red\",\n  ci_color = \"black\",\n  ci_alpha = 0.5,\n  use_ci = TRUE,\n  high_quantile = 0.95,\n  low_quantile = 0.05,\n  calc_varying = T\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncov_name\n\n\nThe name of the covariate to plot. Leave blank to select from a list of available covariates\n\n\n\n\nlabel_high\n\n\nThe character label for the upper end of the latent scale\n\n\n\n\nlabel_low\n\n\nThe character label for the lower end of the latent scale\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be a character value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nrecalc_vals\n\n\nWhether to combine two variables into one through addition before computing IRFs. If TRUE, two names of parameters should be passed to cov_name or selected from the dialog list\n\n\n\n\ninclude\n\n\nA list of character names of person or group IDs for which to calculate IRFs\n\n\n\n\ntime_calc\n\n\nThe maximum number of time points over which to calculate the IRF\n\n\n\n\ntime_label\n\n\nCharacter string specifying the type of time points (default is just “Time Points”)\n\n\n\n\nline_type\n\n\nThe line type of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_width\n\n\nThe line width of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_alpha\n\n\nThe line alpha (transparency) of the IRF line (see ggplot2 documentation)\n\n\n\n\nline_color\n\n\nThe color of the IRF line (see ggplot2 documentation)\n\n\n\n\nci_color\n\n\nThe color of the IRF credible interval (see ggplot2 documentation)\n\n\n\n\nci_alpha\n\n\nThe alpha of the IRF credible interval (see ggplot2 documentation)\n\n\n\n\nuse_ci\n\n\nWhether or not to plot a credible interval around the lines\n\n\n\n\nhigh_quantile\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nlow_quantile\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\ncalc_varying\n\n\nif TRUE, will calculate marginal effects of the covariates on each end of the latent scale (see vignette for more information)\n\n\n\n\n\n\na ggplot2 object that can be further customized if necessary",
    "crumbs": [
      "Reference",
      "id_plot_irf"
    ]
  },
  {
    "objectID": "man/derive_chain.html",
    "href": "man/derive_chain.html",
    "title": "idealstan",
    "section": "",
    "text": "This function accepts a log-likelihood matrix produced by ‘id_post_pred’ and extracts the IDs of the MCMC chains. It is necessary to use this function as the second argument to the ‘loo’ function along with an exponentiated log-likelihood matrix. See the package vignette How to Evaluate Models for more details.\n\n\n\nderive_chain(ll_matrix = NULL)\n\n\n\n\n\n\n\nll_matrix\n\n\nA log-likelihood matrix as produced by the id_post_pred function",
    "crumbs": [
      "Reference",
      "derive_chain"
    ]
  },
  {
    "objectID": "man/derive_chain.html#helper-function-for-loo-calculation",
    "href": "man/derive_chain.html#helper-function-for-loo-calculation",
    "title": "idealstan",
    "section": "",
    "text": "This function accepts a log-likelihood matrix produced by ‘id_post_pred’ and extracts the IDs of the MCMC chains. It is necessary to use this function as the second argument to the ‘loo’ function along with an exponentiated log-likelihood matrix. See the package vignette How to Evaluate Models for more details.\n\n\n\nderive_chain(ll_matrix = NULL)\n\n\n\n\n\n\n\nll_matrix\n\n\nA log-likelihood matrix as produced by the id_post_pred function",
    "crumbs": [
      "Reference",
      "derive_chain"
    ]
  },
  {
    "objectID": "man/id_sim_resid.html",
    "href": "man/id_sim_resid.html",
    "title": "idealstan",
    "section": "",
    "text": "Residual function for checking estimated samples compared to true simulation scores Returns a data frame with residuals plus quantiles.\n\nDescription\nResidual function for checking estimated samples compared to true simulation scores Returns a data frame with residuals plus quantiles.\n\n\nUsage\nid_sim_resid(obj, rep = 1)\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data from id_sim_gen\n\n\n\n\nrep\n\n\nOver how many replicates to calculate residuals? Currently can only be 1",
    "crumbs": [
      "Reference",
      "id_sim_resid"
    ]
  },
  {
    "objectID": "man/id_make.html",
    "href": "man/id_make.html",
    "title": "idealstan",
    "section": "",
    "text": "To run an IRT model using idealstan, you must first process your data using the id_make function.\n\n\n\nid_make(\n  score_data = NULL,\n  outcome_disc = \"outcome_disc\",\n  outcome_cont = \"outcome_cont\",\n  person_id = \"person_id\",\n  item_id = \"item_id\",\n  time_id = \"time_id\",\n  group_id = \"group_id\",\n  model_id = \"model_id\",\n  ordered_id = \"ordered_id\",\n  ignore_id = \"ignore_id\",\n  simul_data = NULL,\n  person_cov = NULL,\n  item_cov = NULL,\n  item_cov_miss = NULL,\n  remove_cov_int = FALSE,\n  unbounded = FALSE,\n  exclude_level = NA,\n  simulation = FALSE\n)\n\n\n\n\n\n\n\nscore_data\n\n\nA data frame in long form, i.e., one row in the data for each measured score or vote in the data or a rollcall data object from package pscl.\n\n\n\n\nperson_id\n\n\nColumn name of the person/legislator ID index in score_data, default is ‘person_id’. Should be integer, character or factor.\n\n\n\n\nitem_id\n\n\nColumn name of the item/bill ID index in score_data, default is ‘item_id’. Should be integer, character or factor.\n\n\n\n\ntime_id\n\n\nColumn name of the time values in score_data: optional, default is ‘time_id’. Should be a date or date-time class, but can be an integer (i.e., years in whole numbers).\n\n\n\n\ngroup_id\n\n\nOptional column name of a person/legislator group IDs (i.e., parties) in score_data. Optional, default is ‘group_id’. Should be integer, character or factor.\n\n\n\n\nmodel_id\n\n\nColumn name of the model/response types in the data. Default is “model_id”. Only necessary if a model with multiple response types (i.e., binary + continuous outcomes). Must be a column with a series of integers matching the model types in id_estimate showing which row of the data matches which outcome.\n\n\n\n\nsimul_data\n\n\nOptionally, data that has been generated by the id_sim_gen function.\n\n\n\n\nperson_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the person/legislator ideal points\n\n\n\n\nitem_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the item/bill discrimination parameters for the regular model\n\n\n\n\nitem_cov_miss\n\n\nA one-sided formula that specifies the covariates in the dataset that will be used to hierarchically model the item/bill discrimination parameters for the missing data model.\n\n\n\n\nremove_cov_int\n\n\nWhether to remove constituent terms from hierarchical covariates that interact covariates with IDs like person_id or item_id. Set to TRUE if including these constituent terms would cause multi-collinearity with other terms in the model (such as running a group-level model with a group-level interaction or a person-level model with a person-level interaction).\n\n\n\n\nunbounded\n\n\nWhether or not the outcome/response is unbounded (i.e., continuous or Poisson). If it is, miss_val is recoded as the maximum of the outcome + 1.\n\n\n\n\nexclude_level\n\n\nA vector of any values that should be treated as NA in the response matrix. Unlike the miss_val parameter, these values will be dropped from the data before estimation rather than modeled explicitly.\n\n\n\n\nsimulation\n\n\nIf TRUE, simulated values are saved in the idealdata object for later plotting with the id_plot_sims function\n\n\n\n\noutcome\n\n\nColumn name of the outcome in score_data, default is “outcome”\n\n\n\n\n\n\nThis function can accept either a rollcall data object from package pscl or a long data frame where one row equals one item-person (bill-legislator) observation with associated outcome. The preferred method is the long data frame as passing a long data frame permits the inclusion of a wide range of covariates in the model, such as person-varying and item-varying (bill-varying) covariates. If a rollcall object is passed to the function, the rollcall data is converted to a long data frame with data from the vote.data matrix used to determine dates for bills. If passing a long data frame, you should specify the names of the columns containing the IDs for persons, items and groups (groups are IDs that may have multiple observations per ID, such as political parties or classes) to the id_make function, along with the name of the response/outcome. The only required columns are the item/bill ID and the person/legislator ID along with an outcome column.\nThe preferred format for the outcome column for discrete variables (binary or ordinal) is to pass a factor variable with levels in the correct order, i.e., in ascending order. For example, if using legislative data, the levels of the factor should be c(‘No’,‘Yes’). If a different kind of variable is passed, such as a character or numeric variable, you should consider specifying low_val,high_val and middle_val to determine the correct order of the discrete outcome. Specifying middle_val is only necessary if you are estimating an ordinal model.\nIf you do not specify a value for miss_val, then any NA are assumed to be missing. If you do specify miss_val and you also have NA in your data (assuming miss_val is not NA), then the function will treat the data coded as miss_val as missing data that should be modeled and will treat the NA data as ignorable missing data that will be removed (list-wise deletion) before estimating a model.\n\n\n\nA idealdata object that can then be used in the id_estimate function to fit a model.\n\n\n\n\nlibrary(idealstan)\n\n# You can either use a pscl rollcall object or a vote/score matrix \n# where persons/legislators are in the rows\n# and items/bills are in the columns\n\nlibrary(dplyr)\n\n# First, using a rollcall object with the 114th Senate's rollcall votes:\n\ndata('senate114')\n\nto_idealstan &lt;-   id_make(score_data = senate114,\n               outcome_disc = 'cast_code',\n               person_id = 'bioname',\n               item_id = 'rollnumber',\n               group_id= 'party_code',\n               time_id='date')",
    "crumbs": [
      "Reference",
      "id_make"
    ]
  },
  {
    "objectID": "man/id_make.html#create-data-to-run-irt-model",
    "href": "man/id_make.html#create-data-to-run-irt-model",
    "title": "idealstan",
    "section": "",
    "text": "To run an IRT model using idealstan, you must first process your data using the id_make function.\n\n\n\nid_make(\n  score_data = NULL,\n  outcome_disc = \"outcome_disc\",\n  outcome_cont = \"outcome_cont\",\n  person_id = \"person_id\",\n  item_id = \"item_id\",\n  time_id = \"time_id\",\n  group_id = \"group_id\",\n  model_id = \"model_id\",\n  ordered_id = \"ordered_id\",\n  ignore_id = \"ignore_id\",\n  simul_data = NULL,\n  person_cov = NULL,\n  item_cov = NULL,\n  item_cov_miss = NULL,\n  remove_cov_int = FALSE,\n  unbounded = FALSE,\n  exclude_level = NA,\n  simulation = FALSE\n)\n\n\n\n\n\n\n\nscore_data\n\n\nA data frame in long form, i.e., one row in the data for each measured score or vote in the data or a rollcall data object from package pscl.\n\n\n\n\nperson_id\n\n\nColumn name of the person/legislator ID index in score_data, default is ‘person_id’. Should be integer, character or factor.\n\n\n\n\nitem_id\n\n\nColumn name of the item/bill ID index in score_data, default is ‘item_id’. Should be integer, character or factor.\n\n\n\n\ntime_id\n\n\nColumn name of the time values in score_data: optional, default is ‘time_id’. Should be a date or date-time class, but can be an integer (i.e., years in whole numbers).\n\n\n\n\ngroup_id\n\n\nOptional column name of a person/legislator group IDs (i.e., parties) in score_data. Optional, default is ‘group_id’. Should be integer, character or factor.\n\n\n\n\nmodel_id\n\n\nColumn name of the model/response types in the data. Default is “model_id”. Only necessary if a model with multiple response types (i.e., binary + continuous outcomes). Must be a column with a series of integers matching the model types in id_estimate showing which row of the data matches which outcome.\n\n\n\n\nsimul_data\n\n\nOptionally, data that has been generated by the id_sim_gen function.\n\n\n\n\nperson_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the person/legislator ideal points\n\n\n\n\nitem_cov\n\n\nA one-sided formula that specifies the covariates in score_data that will be used to hierarchically model the item/bill discrimination parameters for the regular model\n\n\n\n\nitem_cov_miss\n\n\nA one-sided formula that specifies the covariates in the dataset that will be used to hierarchically model the item/bill discrimination parameters for the missing data model.\n\n\n\n\nremove_cov_int\n\n\nWhether to remove constituent terms from hierarchical covariates that interact covariates with IDs like person_id or item_id. Set to TRUE if including these constituent terms would cause multi-collinearity with other terms in the model (such as running a group-level model with a group-level interaction or a person-level model with a person-level interaction).\n\n\n\n\nunbounded\n\n\nWhether or not the outcome/response is unbounded (i.e., continuous or Poisson). If it is, miss_val is recoded as the maximum of the outcome + 1.\n\n\n\n\nexclude_level\n\n\nA vector of any values that should be treated as NA in the response matrix. Unlike the miss_val parameter, these values will be dropped from the data before estimation rather than modeled explicitly.\n\n\n\n\nsimulation\n\n\nIf TRUE, simulated values are saved in the idealdata object for later plotting with the id_plot_sims function\n\n\n\n\noutcome\n\n\nColumn name of the outcome in score_data, default is “outcome”\n\n\n\n\n\n\nThis function can accept either a rollcall data object from package pscl or a long data frame where one row equals one item-person (bill-legislator) observation with associated outcome. The preferred method is the long data frame as passing a long data frame permits the inclusion of a wide range of covariates in the model, such as person-varying and item-varying (bill-varying) covariates. If a rollcall object is passed to the function, the rollcall data is converted to a long data frame with data from the vote.data matrix used to determine dates for bills. If passing a long data frame, you should specify the names of the columns containing the IDs for persons, items and groups (groups are IDs that may have multiple observations per ID, such as political parties or classes) to the id_make function, along with the name of the response/outcome. The only required columns are the item/bill ID and the person/legislator ID along with an outcome column.\nThe preferred format for the outcome column for discrete variables (binary or ordinal) is to pass a factor variable with levels in the correct order, i.e., in ascending order. For example, if using legislative data, the levels of the factor should be c(‘No’,‘Yes’). If a different kind of variable is passed, such as a character or numeric variable, you should consider specifying low_val,high_val and middle_val to determine the correct order of the discrete outcome. Specifying middle_val is only necessary if you are estimating an ordinal model.\nIf you do not specify a value for miss_val, then any NA are assumed to be missing. If you do specify miss_val and you also have NA in your data (assuming miss_val is not NA), then the function will treat the data coded as miss_val as missing data that should be modeled and will treat the NA data as ignorable missing data that will be removed (list-wise deletion) before estimating a model.\n\n\n\nA idealdata object that can then be used in the id_estimate function to fit a model.\n\n\n\n\nlibrary(idealstan)\n\n# You can either use a pscl rollcall object or a vote/score matrix \n# where persons/legislators are in the rows\n# and items/bills are in the columns\n\nlibrary(dplyr)\n\n# First, using a rollcall object with the 114th Senate's rollcall votes:\n\ndata('senate114')\n\nto_idealstan &lt;-   id_make(score_data = senate114,\n               outcome_disc = 'cast_code',\n               person_id = 'bioname',\n               item_id = 'rollnumber',\n               group_id= 'party_code',\n               time_id='date')",
    "crumbs": [
      "Reference",
      "id_make"
    ]
  },
  {
    "objectID": "man/id_post_pred-idealstan-method.html",
    "href": "man/id_post_pred-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will draw from the posterior distribution, whether in terms of the outcome (prediction) or to produce the log-likelihood values.\nThis function can also produce either distribution of the outcomes (i.e., predictions) or the log-likelihood values of the posterior (set option type to ‘log_lik’. For more information, see the package vignette How to Evaluate Models.\nYou can then use functions such as id_plot_ppc to see how well the model does returning the correct number of categories in the score/vote matrix. Also see help(“posterior_predict”, package = “rstanarm”)\n\n\n\n## S4 method for signature 'idealstan'\nid_post_pred(\n  object,\n  draws = 100,\n  output = \"observed\",\n  type = \"predict\",\n  covar = \"person\",\n  sample_scores = NULL,\n  item_subset = NULL,\n  use_cores = 1,\n  use_chain = NULL,\n  newdata = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ndraws\n\n\nThe number of draws to use from the total number of posterior draws (default is 100). Set to \"all\" to use all draws in the chains. For reproducibility, you can also pass a vector of specific draws to use.\n\n\n\n\noutput\n\n\nIf the model has an unbounded outcome (Poisson, continuous, etc.), then specify whether to show the ‘observed’ data (the default) or the binary output ‘missing’ showing whether an observation was predicted as missing or not\n\n\n\n\ntype\n\n\nWhether to produce posterior predictive values (‘predict’, the default), the posterior expected (average) values (‘epred’), or log-likelihood values (‘log_lik’). See the How to Evaluate Models vignette for more info.\n\n\n\n\ncovar\n\n\nWhat kind of covariates to include as part of the prediction – either \"person\" (the default) or \"items\" if you included predictors for item discriminations.\n\n\n\n\nsample_scores\n\n\nIn addition to reducing the number of posterior draws used to calculate the posterior predictive distribution, which will reduce computational overhead. Only available for calculating predictive distributions, not log-likelihood values.\n\n\n\n\nitem_subset\n\n\nWhether to calculate marginal effects for only a subset of items. Should be item IDs that match the item_id column passed to the id_make function.\n\n\n\n\nuse_cores\n\n\nNumber of cores to use for multicore parallel processing with the base R parallel package\n\n\n\n\nnewdata\n\n\nOptional: pass a data frame that must have all of the predictors that were given to the id_make function. Used to generate predictions from person or item covariates on to items.\n\n\n\n\n…\n\n\nAny other arguments passed on to posterior_predict (currently none available)",
    "crumbs": [
      "Reference",
      "id_post_pred-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_post_pred-idealstan-method.html#posterior-prediction-for-idealstan-objects",
    "href": "man/id_post_pred-idealstan-method.html#posterior-prediction-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function will draw from the posterior distribution, whether in terms of the outcome (prediction) or to produce the log-likelihood values.\nThis function can also produce either distribution of the outcomes (i.e., predictions) or the log-likelihood values of the posterior (set option type to ‘log_lik’. For more information, see the package vignette How to Evaluate Models.\nYou can then use functions such as id_plot_ppc to see how well the model does returning the correct number of categories in the score/vote matrix. Also see help(“posterior_predict”, package = “rstanarm”)\n\n\n\n## S4 method for signature 'idealstan'\nid_post_pred(\n  object,\n  draws = 100,\n  output = \"observed\",\n  type = \"predict\",\n  covar = \"person\",\n  sample_scores = NULL,\n  item_subset = NULL,\n  use_cores = 1,\n  use_chain = NULL,\n  newdata = NULL,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ndraws\n\n\nThe number of draws to use from the total number of posterior draws (default is 100). Set to \"all\" to use all draws in the chains. For reproducibility, you can also pass a vector of specific draws to use.\n\n\n\n\noutput\n\n\nIf the model has an unbounded outcome (Poisson, continuous, etc.), then specify whether to show the ‘observed’ data (the default) or the binary output ‘missing’ showing whether an observation was predicted as missing or not\n\n\n\n\ntype\n\n\nWhether to produce posterior predictive values (‘predict’, the default), the posterior expected (average) values (‘epred’), or log-likelihood values (‘log_lik’). See the How to Evaluate Models vignette for more info.\n\n\n\n\ncovar\n\n\nWhat kind of covariates to include as part of the prediction – either \"person\" (the default) or \"items\" if you included predictors for item discriminations.\n\n\n\n\nsample_scores\n\n\nIn addition to reducing the number of posterior draws used to calculate the posterior predictive distribution, which will reduce computational overhead. Only available for calculating predictive distributions, not log-likelihood values.\n\n\n\n\nitem_subset\n\n\nWhether to calculate marginal effects for only a subset of items. Should be item IDs that match the item_id column passed to the id_make function.\n\n\n\n\nuse_cores\n\n\nNumber of cores to use for multicore parallel processing with the base R parallel package\n\n\n\n\nnewdata\n\n\nOptional: pass a data frame that must have all of the predictors that were given to the id_make function. Used to generate predictions from person or item covariates on to items.\n\n\n\n\n…\n\n\nAny other arguments passed on to posterior_predict (currently none available)",
    "crumbs": [
      "Reference",
      "id_post_pred-idealstan-method"
    ]
  },
  {
    "objectID": "man/release_questions.html",
    "href": "man/release_questions.html",
    "title": "idealstan",
    "section": "",
    "text": "Function that provides additional check questions for package release\n\n\n\nrelease_questions()",
    "crumbs": [
      "Reference",
      "release_questions"
    ]
  },
  {
    "objectID": "man/release_questions.html#function-that-provides-additional-check-questions-for-package-release",
    "href": "man/release_questions.html#function-that-provides-additional-check-questions-for-package-release",
    "title": "idealstan",
    "section": "",
    "text": "Function that provides additional check questions for package release\n\n\n\nrelease_questions()",
    "crumbs": [
      "Reference",
      "release_questions"
    ]
  },
  {
    "objectID": "man/idealstan-class.html",
    "href": "man/idealstan-class.html",
    "title": "idealstan",
    "section": "",
    "text": "The idealstan objects store the results of estimations carried out by the id_estimate function. These objects include the full results of Bayesian sampling performed by the stan function in the rstan package.",
    "crumbs": [
      "Reference",
      "idealstan-class"
    ]
  },
  {
    "objectID": "man/idealstan-class.html#results-of-id_estimate-function",
    "href": "man/idealstan-class.html#results-of-id_estimate-function",
    "title": "idealstan",
    "section": "",
    "text": "The idealstan objects store the results of estimations carried out by the id_estimate function. These objects include the full results of Bayesian sampling performed by the stan function in the rstan package.",
    "crumbs": [
      "Reference",
      "idealstan-class"
    ]
  },
  {
    "objectID": "man/id_plot_compare.html",
    "href": "man/id_plot_compare.html",
    "title": "idealstan",
    "section": "",
    "text": "Function to compare two fitted idealstan models by plotting ideal points. Assumes that underlying data is the same for both models.\n\nDescription\nFunction to compare two fitted idealstan models by plotting ideal points. Assumes that underlying data is the same for both models.\n\n\nUsage\nid_plot_compare(\n  model1 = NULL,\n  model2 = NULL,\n  scale_flip = FALSE,\n  return_data = FALSE,\n  labels = NULL,\n  hjust = -0.1,\n  palette = \"Set1\",\n  color_direction = 1,\n  text_size_label = 2,\n  rescale = FALSE\n)\n\n\n\nArguments\n\n\n\nmodel1\n\n\nThe first model to compare\n\n\n\n\nmodel2\n\n\nThe second model to compare\n\n\n\n\nscale_flip\n\n\nThis parameter is set to true if you have two models that are reflected around the ideal point axis. This can happen as a result of identification and is harmless.\n\n\n\n\nreturn_data\n\n\nWhether to return the underlying data\n\n\n\n\nlabels\n\n\nTRUE or FALSE, whether to use labels for points\n\n\n\n\nhjust\n\n\nThe horizontal adjustment of point labels\n\n\n\n\npalette\n\n\ncolorbrewer palette name\n\n\n\n\ncolor_direction\n\n\nWhether to reverse the color scale\n\n\n\n\ntext_size_label\n\n\nSize of point labels\n\n\n\n\nrescale\n\n\nWhether to rescale the estimates from two models so they will match regardless of arbitrary scale shifts in the ideal points",
    "crumbs": [
      "Reference",
      "id_plot_compare"
    ]
  },
  {
    "objectID": "man/id_plot_sims.html",
    "href": "man/id_plot_sims.html",
    "title": "idealstan",
    "section": "",
    "text": "This function plots the results from a simulation generated by id_sim_gen.\n\n\n\nid_plot_sims(sims, type = \"RMSE\")\n\n\n\n\n\n\n\nsims\n\n\nA fitted idealstan object that has true data generated by id_sim_gen\n\n\n\n\ntype\n\n\nType of analysis of true versus fitted values, can be ‘RMSE’, ‘Residuals’ or ‘Coverage’",
    "crumbs": [
      "Reference",
      "id_plot_sims"
    ]
  },
  {
    "objectID": "man/id_plot_sims.html#this-function-plots-the-results-from-a-simulation-generated-by-id_sim_gen.",
    "href": "man/id_plot_sims.html#this-function-plots-the-results-from-a-simulation-generated-by-id_sim_gen.",
    "title": "idealstan",
    "section": "",
    "text": "This function plots the results from a simulation generated by id_sim_gen.\n\n\n\nid_plot_sims(sims, type = \"RMSE\")\n\n\n\n\n\n\n\nsims\n\n\nA fitted idealstan object that has true data generated by id_sim_gen\n\n\n\n\ntype\n\n\nType of analysis of true versus fitted values, can be ‘RMSE’, ‘Residuals’ or ‘Coverage’",
    "crumbs": [
      "Reference",
      "id_plot_sims"
    ]
  },
  {
    "objectID": "man/idealstan.html",
    "href": "man/idealstan.html",
    "title": "idealstan",
    "section": "",
    "text": "R Interface to Stan for Item-Response Theory Ideal Point Models\n\n\n\nSee the README on GitHub\n\n\n\nMaintainer: Robert Kubinec rmk7@nyu.edu\nOther contributors:\n\n\nJonah Gabry [contributor]\n\n\nBen Goodrich [contributor]\n\n\nTrustees of Columbia University [copyright holder]\n\n\n\n\n\n\n\nKubinec, Robert. Generalized Ideal Point Models for Time-Varying and Missing-Data Inference. Working Paper.\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\n\n\n\nUseful links:\n\n\nReport bugs at https://github.com/saudiwin/idealstan/issues",
    "crumbs": [
      "Reference",
      "idealstan"
    ]
  },
  {
    "objectID": "man/idealstan.html#idealstan-package",
    "href": "man/idealstan.html#idealstan-package",
    "title": "idealstan",
    "section": "",
    "text": "R Interface to Stan for Item-Response Theory Ideal Point Models\n\n\n\nSee the README on GitHub\n\n\n\nMaintainer: Robert Kubinec rmk7@nyu.edu\nOther contributors:\n\n\nJonah Gabry [contributor]\n\n\nBen Goodrich [contributor]\n\n\nTrustees of Columbia University [copyright holder]\n\n\n\n\n\n\n\nKubinec, Robert. Generalized Ideal Point Models for Time-Varying and Missing-Data Inference. Working Paper.\n\n\nClinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. The American Political Science Review, 98(2), 355-370. doi:10.1017/S0003055404001194\n\n\nBafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. Political Analysis, 13(2), 171-187. doi:10.1093/pan/mpi010\n\n\n\n\n\nUseful links:\n\n\nReport bugs at https://github.com/saudiwin/idealstan/issues",
    "crumbs": [
      "Reference",
      "idealstan"
    ]
  },
  {
    "objectID": "man/id_plot_cov.html",
    "href": "man/id_plot_cov.html",
    "title": "idealstan",
    "section": "",
    "text": "This function will calculate marginal effects, or the first derivative of the IRT/ideal point model with respect to the hierarchical covariate, separately for the two poles of the latent variable. These two marginal effects permit the interpretation of the effect of the covariate on with respect to either end of the latent variable.\n\n\n\nid_plot_cov(\n  object,\n  calc_varying = T,\n  label_high = \"Liberal\",\n  label_low = \"Conservative\",\n  cov_type = \"person_cov\",\n  use_items = \"all\",\n  pred_outcome = NULL,\n  high_quantile = 0.95,\n  low_quantile = 0.05,\n  filter_cov = NULL,\n  new_cov_names = NULL,\n  recalc_vals = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncalc_varying\n\n\nWhether to marginalize covariate effects over discrimination parameters to calculate a meaningful quantity for the effect of covariates on the latent scale (see vignette). Defaults to TRUE\n\n\n\n\nlabel_high\n\n\nWhat label to use on the plot for the high end of the latent scale\n\n\n\n\nlabel_low\n\n\nWhat label to use on the plot for the low end of the latent scale\n\n\n\n\ncov_type\n\n\nEither ‘person_cov’ for person or group-level hierarchical parameters, ‘discrim_reg_cov’ for bill/item discrimination parameters from regular (non-inflated) model, and ‘discrim_infl_cov’ for bill/item discrimination parameters from inflated model.\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be a character value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nhigh_quantile\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nlow_quantile\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\nfilter_cov\n\n\nA character vector of coefficients from covariate plots to exclude from plotting (should be the names of coefficients as they appear in the plots)\n\n\n\n\nnew_cov_names\n\n\nA character vector of length equal to the number of covariates (plus 1 for the intercept) to change the default labels. To see the default labels, use the plot function with this option blank. The character vector should be of th form used by\n\n\n\n\nrecalc_vals\n\n\nA character value of length three that can be used to create a new variable that is a sum of two other variables. The first two values of the character vector are the names of these parameters, while the third value is the name of the new combined variable. Note that if the parameters are renamed, the new names should be used in this option.\n\n\n\n\n\n\nBecause the marginal effects are always with respect to a given outcome/response, the outcome to be predicted must be specified in pred_outcome. If it is not specified, the function will prompt you to select one of the outcome’s values in the data.\nThe ends of the latent variable can be specified via the label_low and label_high options, which will use those labels in the ensuing plot.\nTo exclude parameters from the plot, use the filter_cov option. Note that the parameters must be specified using the underlying model syntax (however they are labeled in the plot). You can also change the names of parameters using the new_cov_names option.\nNote that the function produces a ggplot2 object, which can be further modified with ggplot2 functions.\n\n\n\nA ggplot2 plot that can be further customized with ggplot2 functions if need be.",
    "crumbs": [
      "Reference",
      "id_plot_cov"
    ]
  },
  {
    "objectID": "man/id_plot_cov.html#marginal-effects-plot-for-hierarchical-covariates",
    "href": "man/id_plot_cov.html#marginal-effects-plot-for-hierarchical-covariates",
    "title": "idealstan",
    "section": "",
    "text": "This function will calculate marginal effects, or the first derivative of the IRT/ideal point model with respect to the hierarchical covariate, separately for the two poles of the latent variable. These two marginal effects permit the interpretation of the effect of the covariate on with respect to either end of the latent variable.\n\n\n\nid_plot_cov(\n  object,\n  calc_varying = T,\n  label_high = \"Liberal\",\n  label_low = \"Conservative\",\n  cov_type = \"person_cov\",\n  use_items = \"all\",\n  pred_outcome = NULL,\n  high_quantile = 0.95,\n  low_quantile = 0.05,\n  filter_cov = NULL,\n  new_cov_names = NULL,\n  recalc_vals = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\ncalc_varying\n\n\nWhether to marginalize covariate effects over discrimination parameters to calculate a meaningful quantity for the effect of covariates on the latent scale (see vignette). Defaults to TRUE\n\n\n\n\nlabel_high\n\n\nWhat label to use on the plot for the high end of the latent scale\n\n\n\n\nlabel_low\n\n\nWhat label to use on the plot for the low end of the latent scale\n\n\n\n\ncov_type\n\n\nEither ‘person_cov’ for person or group-level hierarchical parameters, ‘discrim_reg_cov’ for bill/item discrimination parameters from regular (non-inflated) model, and ‘discrim_infl_cov’ for bill/item discrimination parameters from inflated model.\n\n\n\n\npred_outcome\n\n\nFor discrete models with more than 2 categories, or binary models with missing data, which outcome to predict. This should be a character value that matches what the outcome was coded as in the data passed to id_make.\n\n\n\n\nhigh_quantile\n\n\nThe upper limit of the posterior density to use for calculating credible intervals\n\n\n\n\nlow_quantile\n\n\nThe lower limit of the posterior density to use for calculating credible intervals\n\n\n\n\nfilter_cov\n\n\nA character vector of coefficients from covariate plots to exclude from plotting (should be the names of coefficients as they appear in the plots)\n\n\n\n\nnew_cov_names\n\n\nA character vector of length equal to the number of covariates (plus 1 for the intercept) to change the default labels. To see the default labels, use the plot function with this option blank. The character vector should be of th form used by\n\n\n\n\nrecalc_vals\n\n\nA character value of length three that can be used to create a new variable that is a sum of two other variables. The first two values of the character vector are the names of these parameters, while the third value is the name of the new combined variable. Note that if the parameters are renamed, the new names should be used in this option.\n\n\n\n\n\n\nBecause the marginal effects are always with respect to a given outcome/response, the outcome to be predicted must be specified in pred_outcome. If it is not specified, the function will prompt you to select one of the outcome’s values in the data.\nThe ends of the latent variable can be specified via the label_low and label_high options, which will use those labels in the ensuing plot.\nTo exclude parameters from the plot, use the filter_cov option. Note that the parameters must be specified using the underlying model syntax (however they are labeled in the plot). You can also change the names of parameters using the new_cov_names option.\nNote that the function produces a ggplot2 object, which can be further modified with ggplot2 functions.\n\n\n\nA ggplot2 plot that can be further customized with ggplot2 functions if need be.",
    "crumbs": [
      "Reference",
      "id_plot_cov"
    ]
  },
  {
    "objectID": "man/launch_shinystan-idealstan-method.html",
    "href": "man/launch_shinystan-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This wrapper will pull the rstan samples out of a fitted idealstan model and then launch launch_shinystan. This function is useful for examining convergence statistics of the underlying MCMC sampling.\n\n\n\n## S4 method for signature 'idealstan'\nlaunch_shinystan(\n  object,\n  pars = c(\"L_full\", \"sigma_reg_full\", \"sigma_abs_free\", \"A_int_free\", \"B_int_free\",\n    \"steps_votes\", \"steps_votes_grm\"),\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\npars\n\n\nA character vector of parameters to select from the underlying rstan model object\n\n\n\n\n…\n\n\nOther parameters passed on to shinystan\n\n\n\n\n\n\nshinystan",
    "crumbs": [
      "Reference",
      "launch_shinystan-idealstan-method"
    ]
  },
  {
    "objectID": "man/launch_shinystan-idealstan-method.html#function-to-launch-shinystan-with-an-idealstan-object",
    "href": "man/launch_shinystan-idealstan-method.html#function-to-launch-shinystan-with-an-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This wrapper will pull the rstan samples out of a fitted idealstan model and then launch launch_shinystan. This function is useful for examining convergence statistics of the underlying MCMC sampling.\n\n\n\n## S4 method for signature 'idealstan'\nlaunch_shinystan(\n  object,\n  pars = c(\"L_full\", \"sigma_reg_full\", \"sigma_abs_free\", \"A_int_free\", \"B_int_free\",\n    \"steps_votes\", \"steps_votes_grm\"),\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\npars\n\n\nA character vector of parameters to select from the underlying rstan model object\n\n\n\n\n…\n\n\nOther parameters passed on to shinystan\n\n\n\n\n\n\nshinystan",
    "crumbs": [
      "Reference",
      "launch_shinystan-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_sim_coverage.html",
    "href": "man/id_sim_coverage.html",
    "title": "idealstan",
    "section": "",
    "text": "Function that computes how often the true value of the parameter is included within the 95/5 high posterior density interval\n\nDescription\nFunction that computes how often the true value of the parameter is included within the 95/5 high posterior density interval\n\n\nUsage\nid_sim_coverage(obj, rep = 1, quantiles = c(0.95, 0.05))\n\n\n\nArguments\n\n\n\nobj\n\n\nA fitted idealstan object with true data generated by id_sim_gen\n\n\n\n\nrep\n\n\nHow many times the models were fitted on new data, currently can only be 1\n\n\n\n\nquantiles\n\n\nWhat the quantile coverage of the high posterior density interval should be",
    "crumbs": [
      "Reference",
      "id_sim_coverage"
    ]
  },
  {
    "objectID": "man/delaware.html",
    "href": "man/delaware.html",
    "title": "idealstan",
    "section": "",
    "text": "This data frame contains the rollcall voting data for the Delaware state legislature from 1995 to present. The data is in long format so that each row is one vote cast by a legislator. It includes a column, ‘group_id’, that lists a party for each legislator (D=Democrat, R=Republican,X=Independent).\n\n\n\ndelaware\n\n\n\n\nA long data frame with one row for every vote cast by a legislator.\n\n\n\nThe original data come from Boris Shor and Nolan McCarty (2002), \"The Ideological Mapping of American Legislatures\", American Political Science Review.\n\n\n\nhttps://www.cambridge.org/core/journals/american-political-science-review/article/ideological-mapping-of-american-legislatures/8E1192C22AA0B9F9B56167998A41CAB0",
    "crumbs": [
      "Reference",
      "delaware"
    ]
  },
  {
    "objectID": "man/delaware.html#rollcall-vote-data-for-delaware-state-legislature",
    "href": "man/delaware.html#rollcall-vote-data-for-delaware-state-legislature",
    "title": "idealstan",
    "section": "",
    "text": "This data frame contains the rollcall voting data for the Delaware state legislature from 1995 to present. The data is in long format so that each row is one vote cast by a legislator. It includes a column, ‘group_id’, that lists a party for each legislator (D=Democrat, R=Republican,X=Independent).\n\n\n\ndelaware\n\n\n\n\nA long data frame with one row for every vote cast by a legislator.\n\n\n\nThe original data come from Boris Shor and Nolan McCarty (2002), \"The Ideological Mapping of American Legislatures\", American Political Science Review.\n\n\n\nhttps://www.cambridge.org/core/journals/american-political-science-review/article/ideological-mapping-of-american-legislatures/8E1192C22AA0B9F9B56167998A41CAB0",
    "crumbs": [
      "Reference",
      "delaware"
    ]
  },
  {
    "objectID": "man/id_extract.html",
    "href": "man/id_extract.html",
    "title": "idealstan",
    "section": "",
    "text": "This is a generic function.\n\n\n\nid_extract(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to underlying functions",
    "crumbs": [
      "Reference",
      "id_extract"
    ]
  },
  {
    "objectID": "man/id_extract.html#generic-method-for-extracting-posterior-samples",
    "href": "man/id_extract.html#generic-method-for-extracting-posterior-samples",
    "title": "idealstan",
    "section": "",
    "text": "This is a generic function.\n\n\n\nid_extract(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\n…\n\n\nOther arguments passed on to underlying functions",
    "crumbs": [
      "Reference",
      "id_extract"
    ]
  },
  {
    "objectID": "man/id_plot_ppc-idealstan-method.html",
    "href": "man/id_plot_ppc-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function is the actual method for generating posterior distributions from a fitted idealstan model.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot_ppc(\n  object,\n  ppc_pred = NULL,\n  group = NULL,\n  item = NULL,\n  combine_item = TRUE,\n  type = NULL,\n  only_observed = NULL,\n  which_mod = NULL,\n  prompt_plot = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nppc_pred\n\n\nThe output of the id_post_pred function on a fitted idealstan object\n\n\n\n\ngroup\n\n\nA character vector of the person or group IDs over which to subset the predictive distribution\n\n\n\n\nitem\n\n\nA character vector of the item IDs over which to subset the predictive distribution\n\n\n\n\ncombine_item\n\n\nWhether to combine all items together (TRUE) or create one plot for each item (FALSE)\n\n\n\n\ntype\n\n\nWhether to plot \"continuous\" or \"discrete\" responses\n\n\n\n\nwhich_mod\n\n\nIf you are producing one plot aggregating data across multiple items and you have different item distributions, then you need to specify the item type number to plot (see function documentation in id_estimate).\n\n\n\n\nprompt_plot\n\n\nWhether to expect a user prompt for each plot if multiple plots are produced (defaults to TRUE) If NULL (default), will use the type specified in the data. However, if both continuous and discrete items are present, will throw an error if NULL.\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars",
    "crumbs": [
      "Reference",
      "id_plot_ppc-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot_ppc-idealstan-method.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "href": "man/id_plot_ppc-idealstan-method.html#plot-posterior-predictive-distribution-for-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This function is the actual method for generating posterior distributions from a fitted idealstan model.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot_ppc(\n  object,\n  ppc_pred = NULL,\n  group = NULL,\n  item = NULL,\n  combine_item = TRUE,\n  type = NULL,\n  only_observed = NULL,\n  which_mod = NULL,\n  prompt_plot = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nppc_pred\n\n\nThe output of the id_post_pred function on a fitted idealstan object\n\n\n\n\ngroup\n\n\nA character vector of the person or group IDs over which to subset the predictive distribution\n\n\n\n\nitem\n\n\nA character vector of the item IDs over which to subset the predictive distribution\n\n\n\n\ncombine_item\n\n\nWhether to combine all items together (TRUE) or create one plot for each item (FALSE)\n\n\n\n\ntype\n\n\nWhether to plot \"continuous\" or \"discrete\" responses\n\n\n\n\nwhich_mod\n\n\nIf you are producing one plot aggregating data across multiple items and you have different item distributions, then you need to specify the item type number to plot (see function documentation in id_estimate).\n\n\n\n\nprompt_plot\n\n\nWhether to expect a user prompt for each plot if multiple plots are produced (defaults to TRUE) If NULL (default), will use the type specified in the data. However, if both continuous and discrete items are present, will throw an error if NULL.\n\n\n\n\n…\n\n\nOther arguments passed on to ppc_bars",
    "crumbs": [
      "Reference",
      "id_plot_ppc-idealstan-method"
    ]
  },
  {
    "objectID": "man/launch_shinystan.html",
    "href": "man/launch_shinystan.html",
    "title": "idealstan",
    "section": "",
    "text": "A generic function for launching launch_shinystan.\n\n\n\nlaunch_shinystan(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object.\n\n\n\n\n…\n\n\nOther arguments passed on to underlying function",
    "crumbs": [
      "Reference",
      "launch_shinystan"
    ]
  },
  {
    "objectID": "man/launch_shinystan.html#generic-method-to-use-shinystan-with-idealstan",
    "href": "man/launch_shinystan.html#generic-method-to-use-shinystan-with-idealstan",
    "title": "idealstan",
    "section": "",
    "text": "A generic function for launching launch_shinystan.\n\n\n\nlaunch_shinystan(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object.\n\n\n\n\n…\n\n\nOther arguments passed on to underlying function",
    "crumbs": [
      "Reference",
      "launch_shinystan"
    ]
  },
  {
    "objectID": "man/summary-idealstan-method.html",
    "href": "man/summary-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function produces quantiles and standard deviations for the posterior samples of idealstan objects.\n\n\n\n## S4 method for signature 'idealstan'\nsummary(\n  object,\n  pars = \"ideal_pts\",\n  high_limit = 0.95,\n  low_limit = 0.05,\n  aggregated = TRUE,\n  use_chain = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object fitted by id_estimate\n\n\n\n\npars\n\n\nEither ‘ideal_pts’ for person ideal points, ‘items’ for items/bills difficulty and discrimination parameters, and ‘all’ for all parameters in the model, including incidental parameters.\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 reflecting the upper limit of the uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 reflecting the lower limit of the uncertainty interval (defaults to 0.05).\n\n\n\n\naggregate\n\n\nWhether to return summaries of the posterior values or the full posterior samples. Defaults to TRUE.\n\n\n\n\n\n\nA tibble data frame with parameters as rows and descriptive statistics as columns",
    "crumbs": [
      "Reference",
      "summary-idealstan-method"
    ]
  },
  {
    "objectID": "man/summary-idealstan-method.html#posterior-summaries-for-fitted-idealstan-object",
    "href": "man/summary-idealstan-method.html#posterior-summaries-for-fitted-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This function produces quantiles and standard deviations for the posterior samples of idealstan objects.\n\n\n\n## S4 method for signature 'idealstan'\nsummary(\n  object,\n  pars = \"ideal_pts\",\n  high_limit = 0.95,\n  low_limit = 0.05,\n  aggregated = TRUE,\n  use_chain = NULL\n)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object fitted by id_estimate\n\n\n\n\npars\n\n\nEither ‘ideal_pts’ for person ideal points, ‘items’ for items/bills difficulty and discrimination parameters, and ‘all’ for all parameters in the model, including incidental parameters.\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 reflecting the upper limit of the uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 reflecting the lower limit of the uncertainty interval (defaults to 0.05).\n\n\n\n\naggregate\n\n\nWhether to return summaries of the posterior values or the full posterior samples. Defaults to TRUE.\n\n\n\n\n\n\nA tibble data frame with parameters as rows and descriptive statistics as columns",
    "crumbs": [
      "Reference",
      "summary-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot-idealstan-method.html",
    "href": "man/id_plot-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to access the full range of plotting options for fitted idealstan models.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot(object, plot_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nplot_type\n\n\nSpecify the plot as a character string. Currently ‘persons’ for legislator/person ideal point plot, ‘histogram’ for a histogram of model estimates for given parameters. Alternatively, use the param option to specify a specific model parameter.\n\n\n\n\n…\n\n\nAdditional arguments passed on to the underlying functions. See individual function documentation for details.\n\n\n\n\nparam\n\n\nA character name of a parameter from an idealstan model.\n\n\n\n\n\n\nid_plot is a wrapper function that can access the various plotting functions available in the idealstan package. Currently, the options are limited to a plot of legislator/person ideal points with bills/item midpoints as an optional overlay. Additional plots will be available in future versions of idealstan.\n\n\n\nA ggplot object\n\n\n\nid_plot_legis for a legislator/person ideal point plot, id_plot_all_hist for a standard histogram plot, id_plot_compare for an ideal point plot of two different models of the same data, id_plot_rhats for a histogram of Rhat values, id_plot_sims for plotting true versus estimated values, id_estimate for how to estimate an idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot-idealstan-method.html#plot-results-of-id_estimate",
    "href": "man/id_plot-idealstan-method.html#plot-results-of-id_estimate",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to access the full range of plotting options for fitted idealstan models.\n\n\n\n## S4 method for signature 'idealstan'\nid_plot(object, plot_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object\n\n\n\n\nplot_type\n\n\nSpecify the plot as a character string. Currently ‘persons’ for legislator/person ideal point plot, ‘histogram’ for a histogram of model estimates for given parameters. Alternatively, use the param option to specify a specific model parameter.\n\n\n\n\n…\n\n\nAdditional arguments passed on to the underlying functions. See individual function documentation for details.\n\n\n\n\nparam\n\n\nA character name of a parameter from an idealstan model.\n\n\n\n\n\n\nid_plot is a wrapper function that can access the various plotting functions available in the idealstan package. Currently, the options are limited to a plot of legislator/person ideal points with bills/item midpoints as an optional overlay. Additional plots will be available in future versions of idealstan.\n\n\n\nA ggplot object\n\n\n\nid_plot_legis for a legislator/person ideal point plot, id_plot_all_hist for a standard histogram plot, id_plot_compare for an ideal point plot of two different models of the same data, id_plot_rhats for a histogram of Rhat values, id_plot_sims for plotting true versus estimated values, id_estimate for how to estimate an idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot-idealstan-method"
    ]
  },
  {
    "objectID": "man/stan_trace.html",
    "href": "man/stan_trace.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\nstan_trace(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\n…\n\n\nOther options passed on to stan_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace"
    ]
  },
  {
    "objectID": "man/stan_trace.html#plot-the-mcmc-posterior-draws-by-chain",
    "href": "man/stan_trace.html#plot-the-mcmc-posterior-draws-by-chain",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\nstan_trace(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\n…\n\n\nOther options passed on to stan_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace"
    ]
  },
  {
    "objectID": "man/stan_trace-idealstan-method.html",
    "href": "man/stan_trace-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\n## S4 method for signature 'idealstan'\nstan_trace(object, par = \"L_full[1]\")\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\npar\n\n\nThe character string name of a parameter in the model\n\n\n\n\n…\n\n\nOther options passed on to mcmc_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace-idealstan-method"
    ]
  },
  {
    "objectID": "man/stan_trace-idealstan-method.html#plot-the-mcmc-posterior-draws-by-chain",
    "href": "man/stan_trace-idealstan-method.html#plot-the-mcmc-posterior-draws-by-chain",
    "title": "idealstan",
    "section": "",
    "text": "This function allows you to produce trace plots for assessing the quality and convergence of MCMC chains.\n\n\n\n## S4 method for signature 'idealstan'\nstan_trace(object, par = \"L_full[1]\")\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan model\n\n\n\n\npar\n\n\nThe character string name of a parameter in the model\n\n\n\n\n…\n\n\nOther options passed on to mcmc_trace\n\n\n\n\n\n\nTo use this function, you must pass a fitted idealstan object along with the name of a parameter in the model. To determine these parameter names, use the summary function or obtain the data from a plot by passing the return_data=TRUE option to id_plog_legis or id_plot_legis_dyn to find the name of the parameter in the Stan model.\nThis function is a simple wrapper around mcmc_trace. Please refer to that function’s documentation for further options.",
    "crumbs": [
      "Reference",
      "stan_trace-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot.html",
    "href": "man/id_plot.html",
    "title": "idealstan",
    "section": "",
    "text": "This generic function will run all the plotting functions associated with fitted idealstan objects.\n\n\n\nid_plot(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object\n\n\n\n\n…\n\n\nOther options passed onto the underlying plot function",
    "crumbs": [
      "Reference",
      "id_plot"
    ]
  },
  {
    "objectID": "man/id_plot.html#generic-function-for-plotting-idealstan-objects",
    "href": "man/id_plot.html#generic-function-for-plotting-idealstan-objects",
    "title": "idealstan",
    "section": "",
    "text": "This generic function will run all the plotting functions associated with fitted idealstan objects.\n\n\n\nid_plot(object, ...)\n\n\n\n\n\n\n\nobject\n\n\nAn idealstan object\n\n\n\n\n…\n\n\nOther options passed onto the underlying plot function",
    "crumbs": [
      "Reference",
      "id_plot"
    ]
  },
  {
    "objectID": "man/id_plot_rhats.html",
    "href": "man/id_plot_rhats.html",
    "title": "idealstan",
    "section": "",
    "text": "This plotting function displays a histogram of the Rhat values of all parameters in an idealstan model.\n\n\n\nid_plot_rhats(obj)\n\n\n\n\n\n\n\nobj\n\n\nA fitted idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot_rhats"
    ]
  },
  {
    "objectID": "man/id_plot_rhats.html#plotting-function-to-display-rhat-distribution",
    "href": "man/id_plot_rhats.html#plotting-function-to-display-rhat-distribution",
    "title": "idealstan",
    "section": "",
    "text": "This plotting function displays a histogram of the Rhat values of all parameters in an idealstan model.\n\n\n\nid_plot_rhats(obj)\n\n\n\n\n\n\n\nobj\n\n\nA fitted idealstan object.",
    "crumbs": [
      "Reference",
      "id_plot_rhats"
    ]
  },
  {
    "objectID": "man/id_sim_gen.html",
    "href": "man/id_sim_gen.html",
    "title": "idealstan",
    "section": "",
    "text": "A function designed to simulate IRT ideal point data.\n\n\n\nid_sim_gen(\n  num_person = 20,\n  num_items = 50,\n  cov_effect = NULL,\n  model_type = \"binary\",\n  latent_space = FALSE,\n  absence_discrim_sd = 3,\n  absence_diff_mean = 0,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  diff_sd = 3,\n  time_points = 1,\n  time_process = \"random\",\n  time_sd = 0.1,\n  ideal_pts_sd = 3,\n  prior_type = \"gaussian\",\n  ordinal_outcomes = 3,\n  inflate = FALSE,\n  sigma_sd = 1\n)\n\n\n\n\n\n\n\nnum_person\n\n\nThe number of persons/persons\n\n\n\n\nnum_items\n\n\nThe number of items (bills in the canonical ideal point model)\n\n\n\n\ncov_effect\n\n\nThe effect of a hierarchical/external covariate on the person ideal points. The covariate will be a uniformly-distributed random variable on the [0,1] scale, so covariate effects in the [-2,2] approximate range would result in noticeable effects on the ideal point scale.\n\n\n\n\nmodel_type\n\n\nOne of ‘binary’, ‘ordinal_rating’, ‘ordinal_grm’, ‘poisson’ ‘normal’, or ‘lognormal’\n\n\n\n\nlatent_space\n\n\nWhether to use the latent space formulation of the ideal point model FALSE by default. NOTE: currently, the package only has estimation for a binary response with the latent space formulation.\n\n\n\n\nabsence_discrim_sd\n\n\nThe SD of the discrimination parameters for the inflated model\n\n\n\n\nabsence_diff_mean\n\n\nThe mean intercept for the inflated model; increasing it will lower the total number of missing data\n\n\n\n\ndiscrim_reg_upb\n\n\nThe upper bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_lb\n\n\nThe lower bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_upb\n\n\nThe upper bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_lb\n\n\nThe lower bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_reg_scale\n\n\nThe scale parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_shape\n\n\nThe shape parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_scale\n\n\nThe scale parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_shape\n\n\nThe shape parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiff_sd\n\n\nThe SD of the difficulty parameters (bill/item intercepts) for both missing and observed parameters (beta and omega)\n\n\n\n\ntime_points\n\n\nThe number of time points for time-varying legislator/person parameters\n\n\n\n\ntime_process\n\n\nThe process used to generate the ideal points: either ‘random’ for a random walk, ‘AR’ for an AR1 process, or ‘GP’ for a Gaussian process.\n\n\n\n\ntime_sd\n\n\nThe standard deviation of the change in ideal points over time (should be low relative to ideal_pts_sd)\n\n\n\n\nideal_pts_sd\n\n\nThe SD for the person/person ideal points\n\n\n\n\nprior_type\n\n\nThe statistical distribution that generates the data for ideal point parameters (alpha) and difficulty intercepts (beta and omega). Currently only ‘gaussian’ is supported.\n\n\n\n\nordinal_outcomes\n\n\nIf model is ‘ordinal’, an integer giving the total number of categories\n\n\n\n\ninflate\n\n\nIf TRUE, an missing-data-inflated dataset is produced.\n\n\n\n\nsigma_sd\n\n\nIf a normal or log-normal distribution is being fitted, this parameter gives the standard deviation of the outcome (i.e. the square root of the variance).\n\n\n\n\n\n\nThis function produces simulated data that matches (as closely as possible) the models used in the underlying Stan code. Currently the simulation can produce inflated and non-inflated models with binary, ordinal (GRM and rating-scale), Poisson, Normal and Log-Normal responses.\n\n\n\nThe results is a idealdata object that can be used in the id_estimate function to run a model. It can also be used in the simulation plotting functions.\n\n\n\nid_plot_sims for plotting fitted models versus true values.",
    "crumbs": [
      "Reference",
      "id_sim_gen"
    ]
  },
  {
    "objectID": "man/id_sim_gen.html#simulate-irt-ideal-point-data",
    "href": "man/id_sim_gen.html#simulate-irt-ideal-point-data",
    "title": "idealstan",
    "section": "",
    "text": "A function designed to simulate IRT ideal point data.\n\n\n\nid_sim_gen(\n  num_person = 20,\n  num_items = 50,\n  cov_effect = NULL,\n  model_type = \"binary\",\n  latent_space = FALSE,\n  absence_discrim_sd = 3,\n  absence_diff_mean = 0,\n  discrim_reg_upb = 1,\n  discrim_reg_lb = -1,\n  discrim_miss_upb = 1,\n  discrim_miss_lb = -1,\n  discrim_reg_scale = 2,\n  discrim_reg_shape = 2,\n  discrim_miss_scale = 2,\n  discrim_miss_shape = 2,\n  diff_sd = 3,\n  time_points = 1,\n  time_process = \"random\",\n  time_sd = 0.1,\n  ideal_pts_sd = 3,\n  prior_type = \"gaussian\",\n  ordinal_outcomes = 3,\n  inflate = FALSE,\n  sigma_sd = 1\n)\n\n\n\n\n\n\n\nnum_person\n\n\nThe number of persons/persons\n\n\n\n\nnum_items\n\n\nThe number of items (bills in the canonical ideal point model)\n\n\n\n\ncov_effect\n\n\nThe effect of a hierarchical/external covariate on the person ideal points. The covariate will be a uniformly-distributed random variable on the [0,1] scale, so covariate effects in the [-2,2] approximate range would result in noticeable effects on the ideal point scale.\n\n\n\n\nmodel_type\n\n\nOne of ‘binary’, ‘ordinal_rating’, ‘ordinal_grm’, ‘poisson’ ‘normal’, or ‘lognormal’\n\n\n\n\nlatent_space\n\n\nWhether to use the latent space formulation of the ideal point model FALSE by default. NOTE: currently, the package only has estimation for a binary response with the latent space formulation.\n\n\n\n\nabsence_discrim_sd\n\n\nThe SD of the discrimination parameters for the inflated model\n\n\n\n\nabsence_diff_mean\n\n\nThe mean intercept for the inflated model; increasing it will lower the total number of missing data\n\n\n\n\ndiscrim_reg_upb\n\n\nThe upper bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_lb\n\n\nThe lower bound of the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_upb\n\n\nThe upper bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_lb\n\n\nThe lower bound of the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_reg_scale\n\n\nThe scale parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_reg_shape\n\n\nThe shape parameter for the generalized Beta distribution for the observed discrimination parameters (gamma)\n\n\n\n\ndiscrim_miss_scale\n\n\nThe scale parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiscrim_miss_shape\n\n\nThe shape parameter for the generalized Beta distribution for the missingness discrimination parameters (nu)\n\n\n\n\ndiff_sd\n\n\nThe SD of the difficulty parameters (bill/item intercepts) for both missing and observed parameters (beta and omega)\n\n\n\n\ntime_points\n\n\nThe number of time points for time-varying legislator/person parameters\n\n\n\n\ntime_process\n\n\nThe process used to generate the ideal points: either ‘random’ for a random walk, ‘AR’ for an AR1 process, or ‘GP’ for a Gaussian process.\n\n\n\n\ntime_sd\n\n\nThe standard deviation of the change in ideal points over time (should be low relative to ideal_pts_sd)\n\n\n\n\nideal_pts_sd\n\n\nThe SD for the person/person ideal points\n\n\n\n\nprior_type\n\n\nThe statistical distribution that generates the data for ideal point parameters (alpha) and difficulty intercepts (beta and omega). Currently only ‘gaussian’ is supported.\n\n\n\n\nordinal_outcomes\n\n\nIf model is ‘ordinal’, an integer giving the total number of categories\n\n\n\n\ninflate\n\n\nIf TRUE, an missing-data-inflated dataset is produced.\n\n\n\n\nsigma_sd\n\n\nIf a normal or log-normal distribution is being fitted, this parameter gives the standard deviation of the outcome (i.e. the square root of the variance).\n\n\n\n\n\n\nThis function produces simulated data that matches (as closely as possible) the models used in the underlying Stan code. Currently the simulation can produce inflated and non-inflated models with binary, ordinal (GRM and rating-scale), Poisson, Normal and Log-Normal responses.\n\n\n\nThe results is a idealdata object that can be used in the id_estimate function to run a model. It can also be used in the simulation plotting functions.\n\n\n\nid_plot_sims for plotting fitted models versus true values.",
    "crumbs": [
      "Reference",
      "id_sim_gen"
    ]
  },
  {
    "objectID": "man/id_extract-idealstan-method.html",
    "href": "man/id_extract-idealstan-method.html",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function allows you to extract the underlying rstan posterior estimates for the full parameters estimates of the idealstan model object. See extract for the underlying function and more options.\nYou can use this function to access a matrix or array of the full posterior estimates of each of the parameters in an idealstan object. There are available options to pick certain parameters of the model, such as the person (legislator) ideal points or item (bill) discrimination scores. Alternatively, you can leave the extract_type option blank and receive a list of all of the available parameters. Please note that the list of parameters do not have particularly informative names.\nAll parameters are returned in the order in which they were input into the id_make function.\n\n\n\n## S4 method for signature 'idealstan'\nid_extract(object, extract_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\nextract_type\n\n\nCan be one of ‘persons’ for person/legislator ideal points, ‘obs_discrim’ for non-inflated item (bill) discrimination scores, ‘obs_diff’ for non-inflated item (bill) difficulty scores, ‘miss_discrim’ for inflated item (bill) discrimination scores, and ‘miss_diff’ for inflated item (bill) difficulty scores.\n\n\n\n\n…\n\n\nAny additional arguments passed on to the extract function.",
    "crumbs": [
      "Reference",
      "id_extract-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_extract-idealstan-method.html#extract-stan-joint-posterior-distribution-from-idealstan-object",
    "href": "man/id_extract-idealstan-method.html#extract-stan-joint-posterior-distribution-from-idealstan-object",
    "title": "idealstan",
    "section": "",
    "text": "This convenience function allows you to extract the underlying rstan posterior estimates for the full parameters estimates of the idealstan model object. See extract for the underlying function and more options.\nYou can use this function to access a matrix or array of the full posterior estimates of each of the parameters in an idealstan object. There are available options to pick certain parameters of the model, such as the person (legislator) ideal points or item (bill) discrimination scores. Alternatively, you can leave the extract_type option blank and receive a list of all of the available parameters. Please note that the list of parameters do not have particularly informative names.\nAll parameters are returned in the order in which they were input into the id_make function.\n\n\n\n## S4 method for signature 'idealstan'\nid_extract(object, extract_type = \"persons\", ...)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object (see id_estimate)\n\n\n\n\nextract_type\n\n\nCan be one of ‘persons’ for person/legislator ideal points, ‘obs_discrim’ for non-inflated item (bill) discrimination scores, ‘obs_diff’ for non-inflated item (bill) difficulty scores, ‘miss_discrim’ for inflated item (bill) discrimination scores, and ‘miss_diff’ for inflated item (bill) difficulty scores.\n\n\n\n\n…\n\n\nAny additional arguments passed on to the extract function.",
    "crumbs": [
      "Reference",
      "id_extract-idealstan-method"
    ]
  },
  {
    "objectID": "man/id_plot_legis_dyn.html",
    "href": "man/id_plot_legis_dyn.html",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items when the legislator/person ideal points are allowed to vary over time.\n\n\n\nid_plot_legis_dyn(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  item_plot = NULL,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  line_size = 1,\n  highlight = NULL,\n  plot_text = TRUE,\n  use_ci = TRUE,\n  plot_lines = 0,\n  draw_line_alpha = 0.5,\n  person_line_alpha = 0.3,\n  person_ci_alpha = 0.8,\n  item_plot_type = \"non-inflated\",\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  plot_sim = FALSE,\n  use_chain = NULL,\n  add_cov = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects if the plot is supposed to show a comparison of different fitted idealstan models (see Time Series vignette)\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nitem_plot\n\n\nThe value of the item/bill for which to plot its midpoint (character value)\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 showing the upper limit to compute the posterior uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 showing the lower limit to compute the posterior uncertainty interval (defaults to 0.05).\n\n\n\n\nline_size\n\n\nSets the size of the line of the time-varying ideal points.\n\n\n\n\nhighlight\n\n\nA character referring to one of the persons in person_labels that the plot can highlight relative to other persons\n\n\n\n\nplot_text\n\n\nIf TRUE, will plot person_labels over the lines.\n\n\n\n\nuse_ci\n\n\nWhether or not high-posterior density intervals (credible intervals) should be plotted over the estimates (turn off if the plot is too busy)\n\n\n\n\nplot_lines\n\n\nThe number of lines of actual draws of time-varying ideal points to draw on the plot. Note that these are grouped by persons. Specific draws selected at random from total number of draws of the estimation. Default is 0.\n\n\n\n\ndraw_line_alpha\n\n\nThe opacity of lines plotted over the distribution (should be between 0 and 1, default is 0.5).\n\n\n\n\nperson_line_alpha\n\n\nThe transparency level of the time-varying ideal point line\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of ribbon confidence interval around the time-varying ideal points\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, use the groups instead of individuals to plot colours\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\nplot_sim\n\n\nWhether to plot the true values of parameters if a simulation was used to generate data (see id_sim_gen)\n\n\n\n\nadd_cov\n\n\nWhether to add values of hierarchical person-level covariates to the time trends (defaults to TRUE).\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model, and also traces the path of these ideal points over time. It will plot them as a vertical line with associated high-density posterior interval (10% to 90%). In addition, if the column index for a bill/item from the response matrix is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nvary_ideal_pts='random_walk',\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis_dyn(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis_dyn"
    ]
  },
  {
    "objectID": "man/id_plot_legis_dyn.html#function-to-plot-dynamic-ideal-point-models",
    "href": "man/id_plot_legis_dyn.html#function-to-plot-dynamic-ideal-point-models",
    "title": "idealstan",
    "section": "",
    "text": "This function can be used on a fitted idealstan object to plot the relative positions and uncertainties of legislator/persons and bills/items when the legislator/person ideal points are allowed to vary over time.\n\n\n\nid_plot_legis_dyn(\n  object,\n  return_data = FALSE,\n  include = NULL,\n  item_plot = NULL,\n  text_size_label = 2,\n  text_size_group = 2.5,\n  high_limit = 0.95,\n  low_limit = 0.05,\n  line_size = 1,\n  highlight = NULL,\n  plot_text = TRUE,\n  use_ci = TRUE,\n  plot_lines = 0,\n  draw_line_alpha = 0.5,\n  person_line_alpha = 0.3,\n  person_ci_alpha = 0.8,\n  item_plot_type = \"non-inflated\",\n  show_true = FALSE,\n  group_color = TRUE,\n  hpd_limit = 10,\n  sample_persons = NULL,\n  plot_sim = FALSE,\n  use_chain = NULL,\n  add_cov = TRUE,\n  ...\n)\n\n\n\n\n\n\n\nobject\n\n\nA fitted idealstan object or a named list of idealstan objects if the plot is supposed to show a comparison of different fitted idealstan models (see Time Series vignette)\n\n\n\n\nreturn_data\n\n\nIf true, the calculated legislator/bill data is returned along with the plot in a list\n\n\n\n\ninclude\n\n\nSpecify a list of person/legislator IDs to include in the plot (all others excluded)\n\n\n\n\nitem_plot\n\n\nThe value of the item/bill for which to plot its midpoint (character value)\n\n\n\n\ntext_size_label\n\n\nggplot2 text size for legislator labels\n\n\n\n\ntext_size_group\n\n\nggplot2 text size for group text used for points\n\n\n\n\nhigh_limit\n\n\nA number between 0 and 1 showing the upper limit to compute the posterior uncertainty interval (defaults to 0.95).\n\n\n\n\nlow_limit\n\n\nA number between 0 and 1 showing the lower limit to compute the posterior uncertainty interval (defaults to 0.05).\n\n\n\n\nline_size\n\n\nSets the size of the line of the time-varying ideal points.\n\n\n\n\nhighlight\n\n\nA character referring to one of the persons in person_labels that the plot can highlight relative to other persons\n\n\n\n\nplot_text\n\n\nIf TRUE, will plot person_labels over the lines.\n\n\n\n\nuse_ci\n\n\nWhether or not high-posterior density intervals (credible intervals) should be plotted over the estimates (turn off if the plot is too busy)\n\n\n\n\nplot_lines\n\n\nThe number of lines of actual draws of time-varying ideal points to draw on the plot. Note that these are grouped by persons. Specific draws selected at random from total number of draws of the estimation. Default is 0.\n\n\n\n\ndraw_line_alpha\n\n\nThe opacity of lines plotted over the distribution (should be between 0 and 1, default is 0.5).\n\n\n\n\nperson_line_alpha\n\n\nThe transparency level of the time-varying ideal point line\n\n\n\n\nperson_ci_alpha\n\n\nThe transparency level of ribbon confidence interval around the time-varying ideal points\n\n\n\n\nitem_plot_type\n\n\nWhether to show the ‘non-inflated’ item/bill midpoints, the ‘inflated’ item/bill midpoints, or produce plots for ‘both’ kinds of models. Defaults to ‘non-inflated’ and will only display an item/bill midpoint if one has been specified in item_plot.\n\n\n\n\nshow_true\n\n\nWhether to show the true values of the legislators (if model has been simulated)\n\n\n\n\ngroup_color\n\n\nIf TRUE, use the groups instead of individuals to plot colours\n\n\n\n\nhpd_limit\n\n\nThe greatest absolute difference in high-posterior density interval shown for any point. Useful for excluding imprecisely estimated persons/legislators from the plot. Leave NULL if you don’t want to exclude any.\n\n\n\n\nsample_persons\n\n\nIf you don’t want to use the full number of persons/legislators from the model, enter a proportion (between 0 and 1) to select only a fraction of the persons/legislators.\n\n\n\n\nplot_sim\n\n\nWhether to plot the true values of parameters if a simulation was used to generate data (see id_sim_gen)\n\n\n\n\nadd_cov\n\n\nWhether to add values of hierarchical person-level covariates to the time trends (defaults to TRUE).\n\n\n\n\n…\n\n\nOther options passed on to plotting function, currently ignored\n\n\n\n\n\n\nThis plot shows the distribution of ideal points for the legislators/persons in the model, and also traces the path of these ideal points over time. It will plot them as a vertical line with associated high-density posterior interval (10% to 90%). In addition, if the column index for a bill/item from the response matrix is passed to the item_plot option, then an item/bill midpoint will be overlain on the ideal point plot, showing the point at which legislators/persons are indifferent to voting/answering on the bill/item. Note that because this is an ideal point model, it is not possible to tell from the midpoint itself which side will be voting which way. For that reason, the legislators/persons are colored by their votes/scores to make it clear.\n\n\n\n\nlibrary(idealstan)\n\n\n\n# First create data and run a model\n\nto_idealstan &lt;-   id_make(score_data = senate114,\noutcome = 'cast_code',\nperson_id = 'bioname',\nitem_id = 'rollnumber',\ngroup_id= 'party_code',\ntime_id='date',\nhigh_val='Yes',\nlow_val='No',\nmiss_val='Absent')\n\nsen_est &lt;- id_estimate(senate_data,\nmodel_type = 2,\nuse_vb = TRUE,\nvary_ideal_pts='random_walk',\nfixtype='vb_partial',\nrestrict_ind_high = \"BARRASSO, John A.\",\nrestrict_ind_low = \"WARREN, Elizabeth\")\n\n# After running the model, we can plot \n# the results of the person/legislator ideal points\n\nid_plot_legis_dyn(sen_est)",
    "crumbs": [
      "Reference",
      "id_plot_legis_dyn"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html",
    "href": "vignettes/Time_Series.html",
    "title": "Time-Varying Ideal Points",
    "section": "",
    "text": "Note: To report bugs with the package, please file an issue on the Github page.\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Robust Measurement with Dirty Data in the Social Sciences.”\nThis package implements to kinds of time-varying ideal point models. Because these time-varying models are independent of the specific outcome used, time-varying ideal point models can be fit with any outcome/response supported by the package, including binary, ordinal, counts, continuous and positive-continuous data, in addition to the latent space model for binary data. This vignette demonstrates the use of the two time-varying ideal point models and how to decide between them with example data drawn from Delaware’s state legislature.\ndata('delaware')\nknitr::kable(slice(delaware,1:10))\n\n\n\n\noutcome\nitem_id\nperson_id\ngroup_id\ntime_id\n\n\n\n\nNA\n1\nAtkins, John 1\nR\n1995-01-01\n\n\nNA\n1\nAtkins, John 2\nD\n1995-01-01\n\n\nYes\n1\nBanning 3\nD\n1995-01-01\n\n\nNA\n1\nBarbieri, Michael A. 4\nD\n1995-01-01\n\n\nNA\n1\nBaumbach, Paul S. 5\nD\n1995-01-01\n\n\nNA\n1\nBennett, Andria 6\nD\n1995-01-01\n\n\nNA\n1\nBennett, E. 7\nD\n1995-01-01\n\n\nNA\n1\nBentz, David 8\nD\n1995-01-01\n\n\nNA\n1\nBlakey, Donald 9\nR\n1995-01-01\n\n\nNA\n1\nBolden, Stephanie 10\nD\n1995-01-01\nThe process to create a time-varying ideal point model is no different than that for creating a static model, except that a column should exist in the data with dates, preferably in date or date-time format. If you have a character vector of dates that you need to convert to R’s date format, check out the excellent lubridate package.\nThere are four time-varying models included in idealstan package, each of which makes different assumptions about how ideal points change over time. It is important to note that none of these models is superior to the other. Ideal points do not have any natural time process as they are a latent, unobserved construct, so the question is more about which time process is most relevant to the social or physical process being studied. The models can be differentiated by whether they permit general description of time series versus inference on specific aspects, and also in terms of complexity.\nThe first kind of model included in idealstan is known as a random-walk process (also known as non-stationary time-series, Brownian motion and I(1)). This simple model of time implies that the location of an ideal point in the current time point is equal to the position of the ideal point in the prior time point plus some random noise. A helpful analogy is to imagine a frog hopping around a room. It could head in virtually any direction.\nThe advantage of the random-walk model is that it allows ideal points to move in any direction. The downside is that it can assume too much change in the ideal point process. It also does not provide a great deal of information about the time series other than the variance parameter of the time series that indicate the average rate of change over time (i.e., how bouncy the time series is). Furthermore, random-walk models change significantly when other covariates are included in the model, as an additional covariate that has a constant effect over time will push the time-series in a single direction, making it less than ideal for testing the effect of time-varying covariates.\nDespite these limitations, this model is still useful, especially in two situations. First, when little is known about the time process/social situation, this model makes the most minimal assumptions about how ideal points change. Second, when the time series is of a relatively long time period, then the time series is likely to have some kind of random-walk nature, especially if there is no natural limit. For example, when looking at legislature voting data, ideal points may follow a random-walk pattern when looking at a legislator’s entire career over decades. In general, a random walk provides a good descriptive inference of where the ideal points are moving; it just won’t tell you a lot about why.\nThe second model included in idealstan is a stationary time series model (also called an AR(1) or first-order autoregressive time series). A stationary time-series is so called because it must return over time to a long-term average or mean. Change over time is conceived of as shocks that push the time series away from its long-term average. The AR(1) model includes additional parameters that measure how fast a time-series will return to its long-term average. A good empirical example for this model is economic growth over time. There are periods when “growth shocks” occur, such as recessions and boom times. Overall, though, economic growth for a specific country will tend towards some long-term average rate of growth. Economic growth can’t simply move off in any direction, especially in an upward direction, as that would over-heat the economy and result in massive inflation.\nThe third model is known as a Gaussian process. Fully explaining how Gaussian processes work is beyond the scope of this vignette, but I refer readers to this case study as a very helpful introduction. A Gaussian process is similar to a random walk in that it can in principle move in any direction. Unlike a random walk, the prior position of the time series doesn’t necessarily constrain the position of the time series in the present position. Rather, a Gaussian process is a generalized smoother: it will find a smooth path between the points, but can take any shape in principle.\nOne major advantage of the Gaussian process is that it is a so-called continuous time series model. In practice this means that the time series does not have to be sequential. For example, if legislators only vote at irregular intervals, and the fact that some bills are separated than more time than others is important, then a Gaussian process will take into account the actual length of time between each vote. Random walks and stationary models, on the other hand, consider each time point to be sequential to the previous time point, effectively ignoring any big gaps.\nThe main disadvantage of the Gaussian process is that the power and flexbility require a lot more data. It is not a useful model unless you have considerable numbers of bills/items. The model can handle additional time-varying covariates although their meaning is not as precise as the stationary model.\nThe stationary model, by contrast, assumes that ideal points have a single long-term average. The ideal points may receive “shocks” that force them away from the long-term mean, but they will inevitably return. While this is a more specific set of assumptions than the random walk or Gaussian process, stationary models have the significant advantage of allowing us to fit covariates that have a more meaningful interpretation: the estimates of covariates represent shocks to the ideal points away from their long-term average.\nA simpler kind of time series model is also available in idealstan known as splines. Splines are combinations of polynomial functions; the more combinations, the more flexible splines become. idealstan includes splines primarily because it is easy to estimate relatively simple time series functions that are useful when there is only a limited amount of data per time point and when the latent trait is unlikely change very quickly. In these cases, a spline can help estimate a latent trait that varies over time but only within certain bounds defined by the complexity of the polynomial function.\nTo show what these models look like, we will fit each model to the delaware data in turn. We use the use_vb option to produce variational estimates of the true posterior; these approximations are much faster to fit than the full model but usually have some distortions. For finished analysis we would want to use the full sampler (use_vb=FALSE), unless we have so much data that processing time for the full model is infeasible.\nThe models will be fit with parallel processing over the persons in the model (i.e. more ncores than nchains specified in id_estimate). Parallel processing is only possible for persons as time series model introduce dependence between time points. As such do not change the map_over_id option for dynamic models or you will get incorrect results.",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#random-walk-model",
    "href": "vignettes/Time_Series.html#random-walk-model",
    "title": "Time-Varying Ideal Points",
    "section": "Random-Walk Model",
    "text": "Random-Walk Model\nTo fit the random walk model, we first create data in which we pass the name of the column of dates for each bill/item to the time_id option of id_make. One important thing to note about this model is that we code missing values as 'Absent', but we leave NA values in the outcome. These NA values will be dropped before running the model. They represent periods of time when legislators were not in office, and hence it is reasonable to exclude these periods of time from analysis.\n\n# Absent to missing\n\ndelaware$outcome[delaware$outcome==\"Absent\"] &lt;- NA\n\n# adjust data to 0/1\n\ndelaware$outcome &lt;- as.numeric(delaware$outcome==\"Yes\")\n\ndelaware_data &lt;- id_make(delaware,outcome_disc = 'outcome',\n                       person_id = 'person_id',\n                       item_id = 'item_id',\n                       group_id= 'group_id',\n                       time_id='time_id')\n\nWe then pass this object to the id_estimate function and specify 'random_walk' in the vary_ideal_pts option. We also use model_type=2 to select a binary model (yes/no votes) that adjust for the missing data (legislator absences). We pass the names of two rollcall votes to restrict their item discrimination parameters for identification (i.e. we constrain one vote with all Republicans voting for to be positive and one vote with all Democrats voting for to be negative). To do so, we need to set the const_type argument to \"items\" and pass the name of bills to the restrict_ind_high and restrict_ind_low options. Using bills (or whatever indicators are in the data) that have a clear split in the votes between parties will help achieve identification, as well as using bills that are far apart in time.\nOne problem with time-varying models is that they introduce additional identification issues with the ideal point scores. Theoretically, if over-time variance is high enough, ideal point scores can oscillate from positive to negative. In these cases, you can add additional items to constrain via the restrict_ind_high and restrict_ind_low options or use a simpler time-series model like a spline with few degrees.\n\n# parallel processing over persons/legislators specified with\n# ncores = 16 and nchains = 2\n# this will equal 8 cores per chain.\n# of course your machine must have 16 cores for \n# that number to be useful\n\ndel_est &lt;- id_estimate(delaware_data,\n                model_type = 1,\n                fixtype='prefix',const_type=\"items\",\n                nchains = 2,use_vb = T,\n                ncores = 8,\n                vary_ideal_pts='random_walk',\n                 restrict_ind_high = 305,\n                 restrict_ind_low=  276,\n            seed=84520,\n            id_refresh=0)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  16.1 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (33) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  27.9 seconds.\n\n\nIt is important to note that the warnings about importance resampling and the approximation do matter and a run with the Hamiltonian Markov Chain sampler should be used before final inferences by setting use_vb=TRUE. The approximation is only useful for exploratory model development.\nGiven the fitted model, we can now plot the ideal points. We will turn off the option for showing the uncertainty interval as there are a lot of lines, one for each legislator:\n\nid_plot_legis_dyn(del_est,use_ci = T) +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'),\n                     name=\"Party\") +\n  ggtitle(\"Yearly Ideal Point Scores for Delaware Legislature\")\n\n\n\n\n\n\n\n\nThis plot does now show very much that is particularly interesting. Most of the ideal points are not changing over time, although it is important to note that polarization is increasing over time–both within parties and between parties as some legislators move to the extremes.\n\nWe can also look at the variance of the ideal points to see which of the legislators had the highest variance in their ideal points:\n\nid_plot_legis_var(del_est) + ggtitle('Variances of Time-Varying Ideal Points in Delaware State Legislature',subtitle='Higher Variances Indicate Less Stable Ideal Points') +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'))\n\n\n\n\n\n\n\n\nWe can access the actual estimates of the variances by passing the return_data=TRUE option to the plot function:\n\nout_d &lt;- id_plot_legis_var(del_est,return_data = T)\nknitr::kable(head(out_d$plot_data))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlegis\nlow_pt\nhigh_pt\nmedian_pt\nid_num\nperson_id\ngroup_id\n\n\n\n\ntime_var_free[100]\n0.269333\n0.269333\n0.269333\n100\nPettyjohn, Brian Guy 137\nR\n\n\ntime_var_free[101]\n0.103812\n0.103812\n0.103812\n101\nPlant, Al Sr. 76\nD\n\n\ntime_var_free[102]\n0.381774\n0.381774\n0.381774\n102\nPlant, Hazel 77\nD\n\n\ntime_var_free[103]\n0.518860\n0.518860\n0.518860\n103\nPoore, Nicole 138\nD\n\n\ntime_var_free[104]\n0.607370\n0.607370\n0.607370\n104\nPostles, Charles S. 78\nR\n\n\ntime_var_free[105]\n0.169317\n0.169317\n0.169317\n105\nPotter, Charles Jr. 79\nD",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#spline-model",
    "href": "vignettes/Time_Series.html#spline-model",
    "title": "Time-Varying Ideal Points",
    "section": "Spline Model",
    "text": "Spline Model\nWe now fit a form of splines for the legislator trajectories by passing 'splines' to vary_ideal_pts. This model has two main control parameters - spline_degree and spline_knots. The first is equal to the number of polynomial coefficients or “bends” in the time series – for a value of 2 the model is quadratic, with 3 it is a sigmoid (three bends), with 4 there is an additional possible bend in the time series, and so on. We will fit a restrictive time-varying model with 0 knots (equivalent to a single polynomial function) and only 2 degrees for the polynomial function:\n\ndel_est_spline &lt;- id_estimate(delaware_data,\n                model_type = 1,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,\n                ncores=8,spline_knots = NULL,spline_degree = 2,\n                vary_ideal_pts='splines',use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  10.1 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (29) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  16.5 seconds.\n\nid_plot_legis_dyn(del_est_spline,use_ci = F) +\n  scale_color_manual(values=c(R='red',\n                              D='blue',\n                              X='green'))\n\n\n\n\n\n\n\n\nThese ideal points are similar to the random walk estimates and show the limited variation possible in a 2-degree polynomial function (essentially a quadratic function). For one session, this model would appear adequate at capturing monthly changes in legislator trajectories.\nFinally, we can also examine the individual ideal points by each time point using the summary function:\n\nsummary(del_est_spline,pars='ideal_pts') %&gt;% \n  head %&gt;% \n  knitr::kable(.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerson\nGroup\nTime_Point\nLow Posterior Interval\nPosterior Median\nHigh Posterior Interval\nParameter Name\n\n\n\n\nNA\nNA\nNA\n0.438427\n0.438427\n0.438427\nL_tp1[1,100]\n\n\nPlant, Al Sr. 76\nD\n1995-01-01\n-6.321320\n-6.321320\n-6.321320\nL_tp1[1,101]\n\n\nNA\nNA\nNA\n-5.642890\n-5.642890\n-5.642890\nL_tp1[1,102]\n\n\nNA\nNA\nNA\n-0.110448\n-0.110448\n-0.110448\nL_tp1[1,103]\n\n\nNA\nNA\nNA\n-0.433422\n-0.433422\n-0.433422\nL_tp1[1,104]\n\n\nNA\nNA\nNA\n-0.524573\n-0.524573\n-0.524573\nL_tp1[1,105]",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "vignettes/Time_Series.html#group-level-time-varying-ideal-points",
    "href": "vignettes/Time_Series.html#group-level-time-varying-ideal-points",
    "title": "Time-Varying Ideal Points",
    "section": "Group-level Time-varying Ideal Points",
    "text": "Group-level Time-varying Ideal Points\nFinally, we can also change the model’s parameters to look at group-level, i.e. party-level, ideal points. To do so we need to specify the use_groups=T option in the id_estimate function, and we change the restricted parameters to parties:\n\ndel_est_rw3 &lt;- id_estimate(delaware_data,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,use_groups = T,\n                ncores=8,use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n                vary_ideal_pts='random_walk',\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  175.6 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (21) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  243.9 seconds.\n\nid_plot_legis_dyn(del_est_rw3,\n                  include=c('D','R')) + scale_colour_manual(values=c(R='red',\n                                                          D='blue',\n                                                          I='green'),\n                                                 name=\"Parties\")\n\n\n\n\n\n\n\n\nWe can also overlay a bill/item midpoint to see where the line of indifference in voting is relative to party positions. In a dynamic ideal point model, the bill/item midpoint will be a straight line as the bill-item midpoint was only voted on in one time point, and hence has only one parameter:\n\nid_plot_legis_dyn(del_est_rw3,item_plot='342',\n                  text_size_label = 5,\n                  include=c('D','R')) + scale_colour_manual(values=c(R='red',\n                                                          D='blue',\n                                                          I='green'),\n                                                 name=\"Parties\") +\n  ggtitle('Time-Varying Party-level Ideal Points for the Delaware State Legislature',\n          subtitle = 'Midpoint (Line of Indifference to Voting) for 342nd Roll-call Vote as Dotted Line') +\n  guides(color='none') +\n  annotate(geom='text',\n           x = ymd('2016-01-01'),\n           y=-1,\n           label='Confirmation Vote for Wilhelmina Wright as U.S. District Judge')\n\n\n\n\n\n\n\n\nAs this plot shows, the line of indifference is very close to the Republican party, implying that the vote split the Republican party while Democrats voted as a bloc. Empirically that is very close to the observed votes; all 27 Democrats voted to confirm the judge while 7 out of 6 Republicans did so.\nI will now estimate an additional Gaussian process model to use as comparison points to the random-walk model for parties:\n\ndel_est_gp1 &lt;- id_estimate(delaware_data,\n                fixtype='prefix',const_type=\"items\",\n                nchains=2,use_groups=T,\n                ncores=8,use_vb=TRUE,\n                 restrict_ind_high = 305,\n                 restrict_ind_low=276,\n                vary_ideal_pts='GP',\n            seed=84520)\n\n[1] \"Running pathfinder to find starting values\"\nFinished in  119.5 seconds.\n[1] \"Estimating model with Pathfinder for inference (approximation of true posterior).\"\n\n\nPareto k value (14) is greater than 0.7. Importance resampling was not able to improve the approximation, which may indicate that the approximation itself is poor. \nFinished in  171.5 seconds.\n\n\nWe can then examine the distributions for both models as plots:\n\nid_plot_legis_dyn(del_est_rw3,include=c('D','R'))\n\n\n\n\n\n\n\nid_plot_legis_dyn(del_est_gp1,include=c('D','R'))\n\n\n\n\n\n\n\n\nThis plot shows that are substantial divergences between the different models (each plot is faceted by group_id). The GP model shows a lot more bounce over time relative to the random walk model, which is implausible given the latent trait we are trying to estimate is legislator ideology. In this case, we should prefer simpler models, such as random walks or splines, to estimate a more slowly-changing latent variable. Estimation with HMC rather than the variational approximation could also help.\nWe could also consider adjusting GP-specific parameters to force a more restrictive fit, though that type of prior adjustment depends on the particular dataset and context. These parameters are given defaults that restrict movement in the ideal points to help ensure identification. As such, they tend to be fairly conservative, but they can be made even more so when necessary. The table below shows these parameters’ values.\n\nParameters in the Gaussian Process Time-Series Model\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\ngp_sd_par\nThis parameter represents residual variation in the series that the GP does not account for. As such, its default is a very low value, as increasing it will generally increase oscillation in the series.\n\n\ngp_num_diff\nThis parameter is a multiplier that is used to set the prior for the length-scale of the GP. Loosely speaking, the length-scale determines the number of times that the time-series can cross zero, and so lowering this parameter will decrease the length-scale and subsequently increase the number of times the series can cross zero. The length-scale is given a prior equal to the difference between the maximum and minimum length of the time series in whatever units it is recorded in (days, weeks, etc) times the parameter gp_num_diff. The second numeric value of this parameter represents the standard deviation of the log-normal prior of the length scale. Increasing the standard deviation will put more weight on the data in determining the amount of flexibility in the time series.\n\n\ngp_m_sd_par\nThis parameter has two values that set the GP’s marginal standard deviation. This parameter loosely represents the amount of time-series variation in the series. The first numeric value represents the hard upper limit for this parameter to prevent the series oscillating. The second numeric value is equal to the shape of an inverse-gamma prior defined over the interval between 0 and the first numeric value (the hard upper limit). It is a weakly informative prior that pulls values away from zero to prevent divergences. Increasing the first numeric value (the upper limit) will increase marginal standard deviation, while the second numeric value can increase marginal standard deviation by decreasing its value, resulting in a flatter inverse-gamma prior.",
    "crumbs": [
      "Articles",
      "Time-Varying Ideal Points"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "idealstan",
    "section": "",
    "text": "GNU GENERAL PUBLIC LICENSE\n                   Version 2, June 1991\nCopyright (C) 1989, 1991 Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n                        Preamble\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software–to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation’s software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Lesser General Public License instead.) You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nWe protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the software.\nAlso, for each author’s protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors’ reputations.\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone’s free use or not licensed at all.\nThe precise terms and conditions for copying, distribution and modification follow.\n                GNU GENERAL PUBLIC LICENSE\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\nThis License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The “Program”, below, refers to any such program or work, and a “work based on the Program” means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term “modification”.) Each licensee is addressed as “you”.\n\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does.\n\nYou may copy and distribute verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\n\nYou may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\n\na) You must cause the modified files to carry prominent notices\nstating that you changed the files and the date of any change.\n\nb) You must cause any work that you distribute or publish, that in\nwhole or in part contains or is derived from the Program or any\npart thereof, to be licensed as a whole at no charge to all third\nparties under the terms of this License.\n\nc) If the modified program normally reads commands interactively\nwhen run, you must cause it, when started running for such\ninteractive use in the most ordinary way, to print or display an\nannouncement including an appropriate copyright notice and a\nnotice that there is no warranty (or else, saying that you provide\na warranty) and that users may redistribute the program under\nthese conditions, and telling the user how to view a copy of this\nLicense.  (Exception: if the Program itself is interactive but\ndoes not normally print such an announcement, your work based on\nthe Program is not required to print an announcement.)\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program.\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\n\nYou may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following:\n\na) Accompany it with the complete corresponding machine-readable\nsource code, which must be distributed under the terms of Sections\n1 and 2 above on a medium customarily used for software interchange; or,\n\nb) Accompany it with a written offer, valid for at least three\nyears, to give any third party, for a charge no more than your\ncost of physically performing source distribution, a complete\nmachine-readable copy of the corresponding source code, to be\ndistributed under the terms of Sections 1 and 2 above on a medium\ncustomarily used for software interchange; or,\n\nc) Accompany it with the information you received as to the offer\nto distribute corresponding source code.  (This alternative is\nallowed only for noncommercial distribution and only if you\nreceived the program in object code or executable form with such\nan offer, in accord with Subsection b above.)\nThe source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\nIf distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code.\n\nYou may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\nYou are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it.\nEach time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients’ exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License.\nIf, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\n\nIf the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\nThe Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\n\nEach version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and “any later version”, you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation.\n\nIf you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\n                  NO WARRANTY\nBECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n           END OF TERMS AND CONDITIONS\n\n  How to Apply These Terms to Your New Programs\n\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n&lt;one line to give the program's name and a brief idea of what it does.&gt;\nCopyright (C) &lt;year&gt;  &lt;name of author&gt;\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along\nwith this program; if not, write to the Free Software Foundation, Inc.,\n51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\nAlso add information on how to contact you by electronic and paper mail.\nIf the program is interactive, make it output a short notice like this when it starts in an interactive mode:\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions; type `show c' for details.\nThe hypothetical commands show w' andshow c’ should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than show w' andshow c’; they could even be mouse-clicks or menu items–whatever suits your program.\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a “copyright disclaimer” for the program, if necessary. Here is a sample; alter the names:\nYoyodyne, Inc., hereby disclaims all copyright interest in the program `Gnomovision’ (which makes passes at compilers) written by James Hacker.\n, 1 April 1989 Ty Coon, President of Vice\nThis General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "Note: This is a beta release of idealstan v1.0. While most features have been implemented and are stable, there may be bugs that have not been sorted out. To report bugs with the package, please file an issue on the Github page.\nAt present, idealstan is only available on Github as one of its main dependencies, cmdstanr is also not on CRAN. To use my package, cmdstanr must be first be set up with a local installation of cmdstan, which is used for estimation. To see how to install cmdstanr, see this guide. Note that the cmdstanr default installation location should be used when installing cmdstan.\nTo install this package, type the command remotes::install_github('saudiwin/idealstan',build_vignette=TRUE) at the R console prompt (you first must have the remotes package installed from CRAN for this to work). The best way to learn how the package works is to look at the package vignettes, which can be accessed by running the R commands:\n# General introduction to the package\nvignette(\"Package_Introduction\",package=\"idealstan\")\n\n# Focus on dynamic models\nvignette(\"Time_Series\",package=\"idealstan\")\nIf you use this package, please cite the following:\nKubinec, Robert. “Generalized Ideal Point Models for Robust Measurement with Dirty Data in the Social Sciences”. SocArchiv (2024). doi:10.31219/osf.io/8j2bt.\nThe paper is available from this link.\n\n\nThis package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics. Compared to traditional IRT, ideal point models use a similar parameterization (the 2-Pl variant) but without the strong assumption that all items load in the same direction (i.e., higher ability). For more information, I refer you to my paper about IRT and ideal point models, documenting many of the features in the package.\nThe goal of idealstan is to offer both standard IRT/ideal point models and additional models for missing data, time-varying ideal points and diverse responses, such as binary, ordinal, count, continuous and positive-continuous outcomes. In addition, idealstan uses the Stan estimation engine to offer full Bayesian inference (with some options for approximate inference) for all models so that every model is estimated with uncertainty. Models can also have mixed outcomes, such as discrete and continuous responses.\nThe approach to handling missing data in this package is to model directly strategic censoring in observations. While this kind of missing data pattern can be found in many situations in which data is not missing at random, this particular version was developed to account for legislatures in which legislators (persons) are strategically absent for votes on bills (items). This approach to missing data can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point).\nThe package also includes ordinal ideal point models to handle situations in which a ranked outcome is polarizing, such as a legislator who can vote yes, no or to abstain. Because idealstan uses Bayesian inference, it can model any kind of ordinal data even if there aren’t an even distribution of ordinal categories for each item.\nThe package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#about-the-package",
    "href": "index.html#about-the-package",
    "title": "README",
    "section": "",
    "text": "This package implements IRT (item response theory) ideal point models, which are models designed for situations in which actors make strategic choices that correlate with a unidimensional scale, such as the left-right axis in American politics. Compared to traditional IRT, ideal point models use a similar parameterization (the 2-Pl variant) but without the strong assumption that all items load in the same direction (i.e., higher ability). For more information, I refer you to my paper about IRT and ideal point models, documenting many of the features in the package.\nThe goal of idealstan is to offer both standard IRT/ideal point models and additional models for missing data, time-varying ideal points and diverse responses, such as binary, ordinal, count, continuous and positive-continuous outcomes. In addition, idealstan uses the Stan estimation engine to offer full Bayesian inference (with some options for approximate inference) for all models so that every model is estimated with uncertainty. Models can also have mixed outcomes, such as discrete and continuous responses.\nThe approach to handling missing data in this package is to model directly strategic censoring in observations. While this kind of missing data pattern can be found in many situations in which data is not missing at random, this particular version was developed to account for legislatures in which legislators (persons) are strategically absent for votes on bills (items). This approach to missing data can be usefully applied to many contexts in which a missing outcome is a function of the person’s ideal point (i.e., people will tend to be present in the data when the item is far away or very close to their ideal point).\nThe package also includes ordinal ideal point models to handle situations in which a ranked outcome is polarizing, such as a legislator who can vote yes, no or to abstain. Because idealstan uses Bayesian inference, it can model any kind of ordinal data even if there aren’t an even distribution of ordinal categories for each item.\nThe package also has extensive plotting functions via ggplot2 for model parameters, particularly the legislator (person) ideal points (ability parameters).",
    "crumbs": [
      "Home"
    ]
  }
]